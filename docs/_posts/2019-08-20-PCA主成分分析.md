---
layout: post
title: "PCA 主成分分析"
date: 2019-08-20
categories: 数据分析
tags: ["数据降维" , "MachineLearning", "MathTools"]
---
## PCA
### 简要说明
PCA 的全称为**主成分分析**（Principal Component Analysis）。简单的来说，PCA 的本质是将原来的坐标系转变为新的坐标系，而新的坐标系的基的选择为原始数据中方差最大的方向。
<!--more-->

### 原理
1. 基变换的矩阵表示

	之前我们说到 PCA 的本质就是基的变换，而基的变换是可以很清晰的使用矩阵相乘来表示的。

	$$
	\left( 
	\begin{array}{cc} 
	p_1 \\
	p_2 \\
	... \\
	p_r 
	\end{array}
	\right)

	\left(
	\begin{array}{c}
	a_1, a_2, ..., a_M
	\end{array} 
	\right)
	=
	\left(
	\begin{array}{c}
	p_1a_1, p_1a_2, ..., p_1a_M \\ 
	p_2a_1, p_2a_2, ..., p_2a_M \\
	..\\
	p_na_1, p_na_2, ..., p_na_M
	\end{array} 
	\right)
	$$

	其中 $p$ 为新的坐标系的基，为一组正交的 $M$ 维的行向量， $a$ 为原始数据，为 $M$ 维列向量。正样子我们就完成了原始数据的坐标转换。

2. 保证转换后的值尽可能的分散且独立

	这样子我们就应该保证最终数据的方差大且协方差小，这里我们让数据矩阵 $X$ 同自己的转置 $X^T$ 相乘，可以看到只要我们将其化成对角矩阵就满足了方差最大，协方差为 0 的效果。

3. 进行简单的公式推导

	$$
	\begin{split}
	D &= \frac{1}{m}YY^T \\
	&= \frac{1}{m}(PX)(PX)^T\\
	&=P(\frac{1}{m}XX^T)P^T\\
	&=PCP^T
	\end{split}
	$$

	从这个公式我们就可以看出，最终的结果应该对原始数据进行 $\frac{1}{m}XX^T$ 的处理之后，在找一组基能把它画成对角矩阵。

4. 降维

	可以看到最终的数据的维度是和基的数量有关的，而基的数量又和最终的特征值有关，所以当我们只取前 $K$ 大的特征值就完成了，降维到 $K$ 维的目的。

### 实现手法
具体实现的伪代码如下：

```bash
# 将原始数据按列组成 n 行 m 列矩阵 X
# 将 X 的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值）
# 求出协方差矩阵
# 求出协方差矩阵的特征值及对应的特征向量
# 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 k 行组成矩阵 P
# Y=PX即为降维到k维后的数据
```

```matlab
function linear_PCA 

%% PARAMETERS

N = 500;			% number of data points
R = [-.9 .4; .1 .2];	% covariance matrix

%% PROGRAM
tic

X = randn(N,2)*R;	% correlated two-dimensional data

[E,v,Xp] = km_pca(X,1);		% obtain eigenvector matrix E, eigenvalues v and principal components Xp

toc
%% OUTPUT
Y = X*E(:,2);
figure; hold on
plot(X(:,1),X(:,2),'.')
plot(E(1,1)*Xp,E(2,1)*Xp,'.r')
plot(E(1,2)*Y,E(2,2)*Y,'.b')
plot([0 E(1,1)],[0 E(2,1)],'g','LineWidth',4)
plot([0 E(1,2)],[0 E(2,2)],'k','LineWidth',4)
axis equal
legend('data','first principal components','second principal components','first principal direction','second principal direction')
title('linear PCA demo')

function [E,v,Xp] = km_pca(X,m)
N = size(X,1);
[E,V] = eig(X'*X/N);

v = diag(V);
[v,ind] = sort(v,'descend');
E = E(:,ind);

Xp = X*E(:,1:m);
```

### 优秀的文章
- [PCA的数学原理(转) - 知乎](https://zhuanlan.zhihu.com/p/21580949)
