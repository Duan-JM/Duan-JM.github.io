---
layout: post
title: "贝叶斯算法"
date: 2018-08-19
categories: 机器学习
tags: [MachineLearning]
---
<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>贝叶斯算法</title>
	</head>
<body>
<h2>知识前置</h2>
<p>这个章节的机器学习，其实更像是一种概率论的学习，同时这也是机器学习和数据分析中非常重要的一环。如果学习遇到了困难非常推荐参考张宇考研概率论部分的内容。同时这一章的算法，也是在文本分类中使用的比较多的。</p>
<p><strong>名词解释：</strong></p>

<ul>
	<li>先验概率：$P(A)$</li>
	<li>条件概率：$P(A|B)$</li>
	<li>后验概率：$P(B|A)$</li>
	<li>全概率：$P(B) = \sum_{i=1}^n P(A_i)*P(B|A_i)$</li>
	<li>贝叶斯公式：$P(A|B) = \frac{P(A)*P(B|A)}{\sum_{i=1}^n P(B|A_i)*P(A_i)}$</li>
</ul>

<p><strong>概率分布：</strong></p>

<ul>
	<li>高斯分布：简单的来说它的分布呈现的是正态分布的样子。<a href="https://blog.csdn.net/renwudao24/article/details/44463489">参考链接</a></li>
	<li>伯努利分布：伯努利分布是0-1分布，简单的来说就是那种仍硬币的概率分布。<a href="https://zh.wikipedia.org/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83">参考链接</a></li>
	<li>多项式分布：是伯努利分布的推广，不再是只有两种情况，有多种情况的概率分布。<a href="https://baike.baidu.com/item/%E5%A4%9A%E9%A1%B9%E5%88%86%E5%B8%83">参考链接</a></li>
</ul>

<p>贝叶斯核心思想：</p>

<p><strong>找出在特征出现时，各个标签出现的概率，选择概率最大的作为其分类。</strong></p>

<h2>朴素贝叶斯</h2>

<p>我们来“望文生义”的理解这个算法，贝叶斯指的就是上面的贝叶斯公式，而朴素则指的是“<strong>特征之间是独立的</strong>”这个朴素假设。</p>

<p>假设有给定样本X，其特征向量为$(x_1,x_2,...,x_m)$，同时类别为$y$。算法中使用公式2.1表达在当前特征下将类别y预测正确的概率。由于特征属性之间是假定独立的，所以$P(x_1,x_2,...x_m)$是可以直接拆开的，故根据这个特性优化，得到公式2.2。由于样本给定的情况下，$P(x_1,x_2,...,x_m)$的值不变，故研究概率最大的问题只需要研究公式2.2等号右侧上面的部分，最终写出预测函数公式2.3。</p>

$$
P(y|x_1,x_2,...,x_m) = \frac{P(y)P(x_1,x_2,...,x_m|y)}{P(x_1,x_2,...,x_m)}\ \ \ 公式2.1  
$$
$$
P(y|x_1,x_2,...,x_m) = \frac{P(y)\prod_{i=1}^m P(x_i|y)}{P(x_1,x_2,...,x_m)}\ \ \ 公式2.2
$$
$$
\hat{y} = arg\ max_y P(y) \prod_{i=1}^m P(x_i|y) \ \ \ 公式2.3
$$
<p>到这里，算法的流程就很显而易见了，和softmax算法类似，让预测正确的概率最大即可，具体计算流程如下：</p>

<p>设$x = {a_1,a_2,...a_m}$为带分类项，其中a为x的一个特征属性，类别集合$C={y_1,y_2,...y_n}$</p>

<ul>
	<li>分别计算所有的$P(y_i|x)$，使用上述公式2.3</li>
	<li>选择$P(y_i|x)$最大的$y_i$作为x的类型</li>
</ul>

<h2>其他朴素贝叶斯</h2>

<h3>高斯朴素贝叶斯</h3>

<p>在上述贝叶斯算法中的特征是离散的，那么考虑特征属虚连续值时，且分布服从高斯分布的情况下。用高斯公式（公式3.1）代替原来计算概率的公式。那么根据训练集中，对应的类别下的属性的均值和标准差，对比待分类数据中的特征项划分的各个均值和标准差，即可得到预测类型。</p>

$$
p(x_k|y_k) = g(x_k,\eta_{y_k},\sigma_{y_k}) = \frac{1}{\sqrt{2 \pi}\sigma}e^{-\frac{(x-\eta_{y_k})^2}{2\sigma_{y_k}^2}}\ \ \ 公式3.1
$$
<h3>伯努利朴素贝叶斯</h3>

<p>特征值的取值是布尔型的，是有true和false，符合伯努利分布，那么其$P（x_i|y_k）$的表达式如下公式3.3。</p>

$$
P（x_i|y_k）= P(x_i = 1 | y_k)*x_i + (1-P(x_i=1|y_k))(1-x_k)\ \ \ 公式3.2
$$
<p><em>注：这意味着没有某个特征也可以是一个特征，其中公式3.2其实是把两个不同条件的概率公式融合在一起了，这种方法也在逻辑回归中使用过</em></p>

<h3>多项式朴素贝叶斯</h3>

<p>特征属性分布服从多项分布时，得到如下公式3.3，公式的来源简单的来说就是已知盒子中红球和所有球的总个数，求从盒中摸到红球的概率差不多。</p>

<p>其中$N_{y_k x_i} $为类别$y_k$下，特征$x_i$出现的次数，$N_{y_k}$ 指的是类别 $y_k$ 下，所有特征出现的次数。</p>

$$
P(x_i|y_k) = \frac{N_{y_k x_i} + \alpha}{N_{y_k} + \alpha n}  
$$
<p><em>注：待预测样本中的特征xi在训练时可能没有出现，如果没有出现，则$N_{y_k x_i} $ 值为0，如果直接拿来计算该样本属于某个分类的概率，结果都将是0。所以在分子中加入α，在分母中加入αn可以解决这个问题。</em></p>

<h2>贝叶斯网络</h2>

<p>由于之前朴素贝叶斯，前提条件是假定特征值之间没有关系，这显然是不现实的而贝叶斯网络正是解决这个问题的。其<strong>关键方法是图模型</strong>，我们构建一个图模型，把具有因果联系的各个变量联系在一起。贝叶斯网络的有向无换图中的节点表示随机变量，连接节点的箭头表示因果关系。</p>

<p>简单的来说贝叶斯网络就是模拟人的认知思维推理模式的，用一组条件概率以及有向无换图对不确定关系推理关系建模。</p>

<p>而这种方式在深度学习之前是很受欢迎的，它和之后的隐马尔可夫被使用作为提取特征的工具，而现在渐渐的过度到了深度学习。</p>

<h3>贝叶斯网络工作原理</h3>

<p>首先贝叶斯网络的实质就是建立一个有向无环图，其中方向代表因果关系。仔细思考一下，为什么是有向无环图，是因为如果是有环的话，就会有节点是自己依赖于自己，显然这样是有问题的。</p>

<p>具体贝叶斯工作的核心原理可以理解为，根据人已知的经验或者其他手段，规定一些完全没有依赖于其他事件的事件发生的概率，随后根据制作的贝叶斯网络（因果关系图）推算出不同事件发生的概率。这个过程有点像是在做一个概率论的期末考试题，已知A，B，C的概率和ABCD之间转换的关系，问在发生了BC条件下，发生D的概率。大体就是这样一种感觉。</p>

<p>事例如下图：</p>

<figure><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fuiulz6amfj30iy0ge74k.jpg"/></figure>

<p><strong>其中$x_1,x_2,x_3$独立，则$x_6,x_7$独立</strong>，$x_1,x_2,x_3,...,x_7$的联合概率分布如下：</p>

$$
p(x_1,x_2,...,x_7) = p(x_1)p(x_2)p(x_3)p(x_4|x_1,x_2,x_3)p(x_5|x_1,x_3)p(x_6|x_4)p(x_7|x_4,X_5)
$$
<p>实际上这部分的概率计算，其实就是根据初始条件和转移方式，求的目标的概率这样的过程。和之前常用的最大似然估计算法对比，贝叶斯的这一系列算法考虑了先验概率，而最大似然估计算法没有，在最大似然估计算法中其实相当于默认了先验概率是相同的。</p>

<p><em>注：最大后验概率MAP其实可以看作是贝叶斯算法和最大似然估计算法结合的应用</em></p>

<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>

