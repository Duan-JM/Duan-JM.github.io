<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[聚类算法（下）]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/19/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E4%B8%8B/</url>
      <content type="text"><![CDATA[							聚类算法（下）	聚类算法上中讲了大名鼎鼎的K-Means算法及其优化变种，在这篇中几种讲述两位两种不同思路的聚类算法。层聚类算法传统层聚类算法—AGNES和DIANA算法层次聚类和K-Means的思路不太一样，它的思路有点像是决策树，按照层次进行分解，知道满足某种条件为止，传统的层次聚类分为自底而上，和自上而下两类：	凝聚的层次聚类:		这类算法是采用采用自底向上的策略，其中的代表便是AGNES算法(AGglomerative Nesting)，它的核心思想是：最初将每个对象作为一个簇，然后这些簇根据某些准则被一步一步合并，两个簇间的距离可以由这两个不同簇中距离最近的数据点的相似度来确定。聚类的合并过程反复进行直到所有的对象满足簇数目。	分裂的层次聚类：		和凝聚的层次聚类相反，这种是采用自顶向下的策略，代表算法为DIANA算法(DIvisive Analysis)。其核心思想是：首先将所有对象置于一个簇中，然后按照某种既定的规则逐渐细分为越来越小的簇(比如最大的欧式 距离)，直到达到某个终结条件(簇数目或者簇距离达到阈值)。在AGNES算法中都提到了，簇是根据某些原则进行分裂或者合并的，而这个原则就是簇间距离。计算簇间距离的方法有最小距离（SL聚类），最大距离（CL聚类）以及平均距离（AL聚类），具体的说明如下：	最小距离（SL聚类）		选择两个聚簇中最近的两个样本之间的距离（Single/Word-Linkage）		注：得到的模型容易形成链式结构	最大距离（CL聚类）		选择两个聚簇中最圆的两个眼本的距离（Complete-Linkage）		注：如果出现了异常值的话，那他们的构建很容易受这个异常值的影响。	平均距离（AL聚类）		选择两个聚类中的平均值（Average-Linkage聚类算法）或者中值（Median-Linkage聚类法）AGNES和DIANA算法优缺点如下：	简单，理解容易。	合并点/分裂点选择不太容易。	合并/分类的操作不能进行撤销。	由于执行效率较低$O(t*n^2)$，$t$为迭代次数，$n$为样本点数。层次聚类优化算法之前我们看到了传统的层次聚类算法，由于其执行效率太低，且不能动构建的的特点，显然不适合大数据集。于是我们在此基础上引入了BIRCH算法和CURE算法。BIRCH算法BIRCH (balanced iterative reducing and clustering using hierarchies) 算法，英文的全称翻译过来以后是平衡迭代削减聚类算法，其构成和我们考研数据结构中学过的B+树非常的类似，甚至很多特性都是相同的，具体的说它构建的树叫做CF（Cluster Feature）-Tree。	节点，即簇的结构：		既然是树，那么就不得不提它的节点的结构了。在BIRCH构建CF树的过程中，每个节点等于说是存放了它之下所有节点的特征，于是他在节点中存放了如下的三部分数据。					N，指在这个节点中有多少个样本点。			LS，指的是这个节点中的样本相应特征的和。			LS，指的是这个节点中的样本相应特征的特征的平方和。			节点之间，节点和子节点，以及叶子结点之间的关系		节点和其子节点是包含的关系，也就是父节点中的N，LS以及SS是其所有子节点的和。而相应的样本点的具体信息指包含在底层节点中（叶子结点的子节点），同时叶子结点构成一个单项链表，同时有一个指针指向其表头。这点的特性是同B+树高度一致的。	最多子女个数，以及分裂判定		和B+树一样，对于树构建中的分叉个数是有限制的，这个限制需要提前给出，即分支因子。同时，值得注意的是，一般而言在构建节点簇的中心点的时候，一般选用第一个进入这个节点的样本点作为中心点，然后根据指定的该簇和中心点限定的距离，即类直径，其往往通过LS和SS算出。判断新入的点是否可以划入该簇，而分裂节点的时候，往往以这个初始点进行分割。综上我们可以看出，BIRCH算法的本质其实就是动态的插入样本点，然后动态的根据规则构建一个类B+树。它的优点是动态建树且效率高是线性效率，即每个样本点都是一次性插入的，同时也节省内存，所以非常适合大数据集。不过遗憾的是它也是采用距离作为分类标准，故只适合分布呈凸形或者球形的数据集、且需要给定聚类个数和簇之间的相关参数，而这些对节点CF的限制可能导致簇类结果和真实不太一致。注1：BIRCH不依赖给定的待分类簇数量K，但是给定了K值最好，若不一定K值，最终CF-Tree的叶子结点树木就是最终分类的簇的数目。注2:BIRCH算法在训练大规模数据集的时候，和mini-batch K-Means相比，BIRCH算法更加适合类别数量K比较多的情况。注3：由于类直径是通过LS和SS算出的，所以当特征维度超过20～30左右的时候，不建议使用该算法。CURE算法（使用代表点的聚类法）CURE（Clustering Using REpresentatives），该算法先把每个数据点看成一类，然后合并距离最近的类直至类个数为所要求的个数为止。但是和AGNES算法的区别是：取消了使用所有点，或用中心点+距离来表示一个类，而是从每个类中抽取固定数量、 分布较好的点作为此类的代表点，并将这些代表点乘以一个适当的收缩因子，使它们更加靠近类中心点。代表点的收缩特性可以调整模型可以匹配那些非球形的场景，而且收缩因子的使用可以减少噪音对聚类的影响。CURE算法的优点是能够处理非球形分布的应用场景，同时彩娱乐随机抽样和分区的方式可以提高算法的执行效率。密度聚类算法密度聚类方法的指导思想是：只要样本点的密度大于某个阀值，则将该样本添加到最近的簇中。这类算法可以克服基于距离的算法只能发现凸聚类的缺点，可以发现任意形状的聚类，而且对噪声数据不敏感。不过这种计算的复杂度高，计算量大。密度聚类算法的常用算法有DBSCAN和密度最大值算法。DBSCAN算法DBSCAN（Density-Based Spatial Clustering of Applications with Noise），将簇定义为密度相连的点的最大集合，能够将足够高密度的区域划分为簇，并且在具有噪声的空间数据上能够发现任意形状的簇。其核心思路是用一个点的ε邻域内的邻居点数衡量该点所在空间的密度，该算法可以找出形状不规则的cluster，而且聚类的时候事先不需要给定cluster的数量。DBSCAN算法流程它的算法流程如下：	如果一个点$x$的$\varepsilon$领域内包含m个对象，则创建一个x作为核心对象的新簇。	寻找并合并核心对象直接密度可达的对象	没有新点可以更新簇的时候，算法结束注：1. 每个簇至少包含一个核心对象；2. 非核心对象可以是簇的一部分，构成簇的边缘；3. 包含过少对象的簇被认为是噪声；4. 最大的密度相连对象的集合C为密度聚类中的一个簇，它满足两个属性，Maximality和Connectivity，Maximality指的是若$x$属于C，$y$从$x$密度可达，那么$y$也属于C，Connectivity指的是，若$x$和$y$都属于C，那么$x$和$y$是密度相连的。DBSCAN相关名词解释其中提到的定义有$\varepsilon$领域，密度，MinPts，核心点，边界点，噪音点，直接密度可达，密度可达，密度相连。他们的解释如下：	$\varepsilon$邻域($\varepsilon$ neighborhood）：给定对象在半径$\varepsilon$的区域。	密度(density)：在$\varepsilon$领域中的$x$的密度，是一个整数依赖于半径$\varepsilon$，$N_{\varepsilon}(X) $指的是半径内的点的个数。		$$		p(x) = |N_{\varepsilon}(X)|  		$$	MinPts：指得是判定该点是不是核心点的时候使用的阀值，记为M	核心点（core point）：如果$p(x) \geq M$ ,那么称$x$为$X$的核心点，记由$X$中所有核心点构成的集合为$X_c$，并记$X_nc$ 表示由$X$中所有非核心点构成的集合。通俗的来说， 核心点是密度达到一定阀值的的点。	边界点（border point）：如果非核心点$x$的$\varepsilon$邻域中存在核心点，那么认为$x$为$X$的边界点。通俗来讲就是密度特别稠密的边缘地带，也就是簇的边缘部分。	噪音点（noise point）：集合中除了边界点和核心点之外的点都是噪音点，所有噪音点组成的集合叫做$X_noi$，显然这些点就是对应稀疏区域的点。	直接密度可达：这个是密度聚类中最重要的概念，它指的是给定一个对象集合 $X$，如果$y$是在$x$的$\varepsilon$邻域内，而且$x$是一个核心对象，可以说对象y从对象$x$出发是直接密度可达的	密度可达：如果存在一个对象链$p_1, p_2,...,p_m $ ，如果满足$p_{i+1}$是从$p_i$直接密度可达的，那么称$p_m$是从$p1$密度可达的，简单的来说就像铁链环环相扣差不多。	密度相连：在集合$X$中，如果存在一个对象$o$，使得对象$x$和$y$是从$o$关于$\varepsilon$和$m$密度可达的，那么对象$x$和$y$是关于$\varepsilon$和$m$密度相连的。DBSCAN算法优缺点优点: 	不需要事先给定cluster的数目	可以发现任意形状的cluster	能够找出数据中的噪音，且对噪音不敏感 	算法只需要两个输入参数 	聚类结果几乎不依赖节点的遍历顺序缺点:	DBSCAN算法聚类效果依赖距离公式的选取，最常用的距离公式为欧几里得距离。但是对于高维数据，由于维数太多，距离的度量已变得不是那么重要	DBSCAN算法不适合数据集中密度差异很小的情况MDCA密度最大值聚类算法MDCA(Maximum Density Clustering Application)算法基于密度的思想引入划分聚类中，能够自动确定簇数量并发现任意形状的簇。另外MDCA一般不保留噪声，因此也避免了阈值选择不当情况下造成的对象丢弃情况。注：MDCA的算法和AGNES非常相像，不同的是最初的初始簇确定是通过密度来确定的。MDCA算法思路MDCA算法核心一共分三步，划分、合并簇以及处理剩余节点三部分。	将数据集划分为基本簇：					对数据集X选取最大密度点$P_{max}$ ，形成以最大密度点为核心的新簇$C_i$，按照距离排序计算出序列$S_{p_max}$,对序列的前M个样本数据进行循环判断，如果节点的密度大于等于$density_0$ ，那么将当前节点添加$C_i$中。			循环处理剩下的数据集X，选择最大密度点$P_{max}$，并构建基本簇$C_{i+1}$，直到X中剩余的样本数据的密度均小于$deansity_0$。			使用凝聚层次聚类的思想，合并较近的基本簇，得到最终的簇划分：					在所有簇中选择距离最近的两个簇进行合并，合并要求是：簇间距小于等于$dist_0$，如果所有簇中没有簇间距小于$dist_0$的时候，结束合并操作			处理剩余节点，归入最近的簇					最常用、最简单的方式是：将剩余样本对象归入到最近的簇。		MDCA算法名词解释最大密度点：如字面意思，就是密度最大的点，密度计算公式一般取DBSCAN算法中的密度计算公式。有序序列$S_{p_{max}}$：根据所有对象与最大密度点的距离进行排序。密度阈值$density_0$：当节点的密度值大于密度阈值的时候，认为该节点属于一个 比较固定的簇，在第一次构建基本簇的时候，就将这些节点添加到对应簇中，如果小于这个值的时候，暂时认为该节点为噪声节点。簇间距离：对于两个簇C1和C2之间的距离，采用两个簇中最近两个节点之间的距离作为簇间距离。M值：初始簇中最多数据样本个数]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[聚类算法（上）]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/19/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E4%B8%8A/</url>
      <content type="text"><![CDATA[							聚类算法（上）	聚类算法很多，所以和讲回归算法一样，分成了上下，上中主要讲了传统的K-Means算法以及其相应的优化算法入K-Means++，K-Means||和Canopy等。下中主要讲了另外两种的思路的聚类算法，即层次聚类和密度聚类。什么是聚类聚类算就是怼大量未知标注的数据集，按照数据内部存在的数据特征将数据集划分为多个不同的类别，使类别内的数据比较相似，类别之间的数据相似度比较小，属于无监督学习。从定义就可以看出，聚类算法的关键在于计算样本之间的相似度，也称为样本间的距离。相似度/距离计算公式说到聚类算法，那肯定核心就是计算距离的公式了，目前常用的有以下几种。闵可夫斯基距离（Minkowski）：公式2.1	当p为1的时候是曼哈顿距离（Manhattan）：公式2.2	当p为2的时候是欧式距离（Euclidean）：公式2.3					标准化欧式距离：				这个距离的计算方式如同其字面意思，标准化欧式距离就是对欧式距离的标准化。标准化的正常定义为，$X^* = \frac{X - \overline X}{s}$，这个$s$指的就是方差，而方差的计算公式为$s = \sqrt{\frac{\sum_{i=1}^n(x_i - \overline X)^2}{n}}$，所以其标准化公式如下公式2.5。			当p为无穷大的以后是切比雪夫距离（Chebyshev）：公式2.4$$dist(X,Y)= \sqrt[p]{\sum_{i=1}^{n} |x_i - y_i|^p}\ \ \ 公式2.1$$$$M\_dist=\sum_{i=1}^n|x_i-y_i| \ \ \ 公式2.2$$$$E\_dist = \sqrt{\sum_{i=1}^n|x_i-y_i|^2} \ \ \ 公式2.3$$$$C\_dist = max_i(|x_i-y_i|)\ \ \ 公式2.4$$$$S\_E\_D = \sqrt{\sum_{i=1}^n(\frac{x_i-y_i}{s_i})^2}\ \ \ 公式2.5 $$夹角余弦相似度（Cosine）：使用这个公式的时候，需要注意的是，这里的相似之的是同一个方向上的，而同一个方向上的两个点可能距离是非常远的。比如一个吻张灏总分别出现单词A 10次，单词B 20次，另一个文章中出现单词A 100次，单词B 200次，这时候如果使用欧几里得距离的话，这两个文章是不相似的，然而显然这两个单词的比例相似很能说明这两个文章其实是有关系的，所以在文章的相似度的判别中使用夹角余弦相似度比较合适，公式如下2.6。个人理解为，其是从距离以外的衡量相似度的另一个维度的指标。$$\cos(\theta)  = \frac{\sum_{k=1}^n x_{1k}x_{2k}}{\sqrt{\sum_{k=1}^n x_{1k}^2} * \sqrt{\sum_{k=1}^n x_{2k}^2}} = \frac{a^T · b}{|a||b|}\ \ \ 公式2.6$$KL距离（相对熵）：思考下条件熵的定义，简单的来说就是在放生一件事情的时候，发生另一件事的概率。公式如下公式2.7.注：这里书的概率不是实指概率，而是熵表达的含义。这个公式其实就是条件熵的公式。$$D(P|Q)=\sum_x P(x)\log(\frac{P(x)}{Q(x)})\ \ \ 公式2.7$$杰卡德相似系数(Jaccard)：这个很好理解，它的核心就是使用两个集合的交集和并集的比率来代表两者的相似度，也就是说重合的越多越相似。公式如下，公式2.8.$$J(A,B) = \frac{|A\bigcap B|}{|A \bigcup B|}  $$$$dist(A,B) = 1-J(A,B) \ \ \ 公式2.8 $$Pearson相关系数：这个就是考研数学中的相关系数，表达就是两者之间的想关系，所以直接拿来用就好了，公式如下公式2.9。$$\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)} \sqrt{D(Y)}} = \frac{E[(X-E(X))(Y-E(Y))]}{\sqrt{D(X)}\sqrt{D(Y)}} = \frac{\sum_{i=1}^n(X_i - \mu_x)(Y_i - \mu_Y)}{\sqrt{\sum_{i=1}^n(X_i - \mu_X)^2}*\sqrt{\sum_{i=1}^n(Y_i - \mu_Y)^2}}  $$$$dist(X,Y) = 1 - \rho_{XY}\ \ \ 公式2.9$$聚类的思想给定一个有M个对象的数据集，构建一个具有k个簇的模型，其中k&lt;=M。满足 以下条件:	每个簇至少包含一个对象	每个对象属于且仅属于一个簇 	将满足上述条件的k个簇成为一个合理的聚类划分基本思想:对于给定的类别数目k，首先给定初始划分，通过迭代改变样本和簇的隶属关系，使的每次处理后得到的划分方式比上一次的好，即总的数据集之间的距离和变小了K-Means 系列K-Means算法K-means的核心算法如下：# 假设输入样本T为x1,x2,x3,...,xm初始化k个类别的中心点a1,a2,a3,...,akwhile not EndCondition :	1.根据每个样本和中心点的欧几里得距离，选择最近的中心点作为自己的类别	2.更新每个类别的中心点aj，为隶属该类别的所有的样本的均值# EndCondition有迭代次数，最小平方误差MSE，簇中心点变化率。再循环中的第二步，我们移动了中心点的位置，把中心点移到了隶属于该中心点类别的所有样本的中间，并使用样本的均值作为位置。这样子看似是拍脑袋想的移动策略，其实是可以推导出来的。正如聚类算法思想所指出的，我们要让所有的点到自己的分类的中心点的欧几里得距离最小，所以我们设置目标放称为公式4.1，公式中的1/2是为了之后求导运算方便。我们为了让目标函数尽可能的小，所以使用了之前一直在使用的思考方式，对其使用梯度下降算法，求导后得到公式4.2，之后令其等于0，就得到了公式4.3。$$J(a_1,a_2,a_3,...,a_k) = \frac{1}{2}\sum_{j=1}^K \sum_{i=1}^n (x_i - a_j)^2 \ \ \ 公式4.1$$$$\frac{\partial J}{\partial a_j} = \sum_{i=1}^{N_j}(x_i-a_j)\ \ \ 公式4.2$$$$a_j = \frac{1}{N}\sum_{i=1}^{N_j} x_i \ \ \ 公式4.3 $$最后这个看似不错的算法，其实有着不小的缺点，那就是初值敏感。我们来仔细想一想，如果两个不小心随机生成的初值落到了一个类别中，两者的距离还特别近，这中情况下就很难正确分类了。除此之外，由于移动策略中使用的是均值，也就是说如果集合中含有非常大的误差点的话，这样子会是中心点的设置偏离正确点很远，所以很多时候我们改用中值来更新中心点，这就是我们说的K-Mediods聚类，即K中值聚类。总结下K-means算法优点：	理解容易，聚类效果不错	处理大数据集的时候，该算法可以保证较好的伸缩性和高效率	当簇近似高斯分布的时候，效果非常不错缺点：	 K值是用户给定的，在进行数据处理前，K值是未知的，不同的K值得到的结果也不一样	对初始簇中心点是敏感的 	不适合发现非凸形状的簇或者大小差别较大的簇 	特殊值(离群值)对模型的影响比较大二分K-Means算法由于K-Means对初始中心点非常敏感，我们这里就尝试着通过二分法弱化初始中心点。这种算法的具体步骤如下：# 把所有样本数据作为一个簇放到队列中while not EndCondition:	1.从队列中选择一个簇，使用K-means划分为两个簇	2.将划分好的两个簇放回队列# EndCondition 为簇的数量，最小平方误差，迭代次数等# 选择簇的手段有两种1.使用SSE 2.选择数据量最多的簇我们在这个算法中提到了SSE，这个可以是簇内所有样本点，到其中心点的距离的总和，代表着簇内的点是不是高度相关。计算公式如下公式4.4。$$SSE = \sum_{i=1}^n w_i(y_i - \hat y_i)^2\ \ \ 公式4.4$$可以看出在这种算法下，很好的避开了，两个中心点都在一起的情况。K-Means++和K-Means||K-Means++做的改善，是直接对初始点的生成位置的选择进行优化的，他的初始点生成策略如下：	从数据集中任选一个节点作为第一个聚类中心	对数据集中的每个点x，计算x到所有已有聚类中心点的距离和D(X)，基于D(X)采用线性概 率选择出下一个聚类中心点(距离较远的一个点成为新增的一个聚类中心点)	重复步骤2直到找到k个聚类中心点可以看出，K-Means++企图生成相聚距离较远的几个中心点。但是缺点也是显而易见的，由于聚类中心点选择过程中的内在有序性，在扩展方面存在着性能方面的问题，即第k个聚类中心点的选择依赖前k-1个聚类中心点的值。而K-Means||就是针对K-Means++缺点作出了的优化，主要思路是改变每次遍历时候的取样规则，并非按照K-Means++算法每次遍历只获取一个样本，而是每次获取 K个样本，重复该取样操作$O(\log{n}w	z)$ 次，然后再将这些抽样出来的样本聚类出K个点，最后使用这K个点作为K-Means算法的初始聚簇中心点。注：一般5次重复采用就可以保证一个比较好的聚簇中心点。Canopy算法Canopy属于一种“粗略地”聚类算法，简单的来说就是，不那么追求自动获得最优解，而是引入了一种人为规定的先验值进行聚类，具体步骤如下：# 给定样本列表L=x1,x,2...,xm以及先验值r1和r2(r1 &gt; r2)for P in L:	计算P到所有聚簇中心点的距离(如果不存在聚簇中心，那么此时点P形成一个新的聚簇)，并选择出最小距离D(P,aj)	if D &lt; r1:		# 表示该节点属于该聚簇		添加到该聚簇列表中	if D &lt; r2:		# 表示该节点不仅仅属于该聚簇，还表示和当前聚簇中心点非常近，		将该聚簇的中心点设置为P，并将P从列表L中删除	if D &gt; r1:		节点P形成一个新的聚簇	if EndCondition:		# 结束条件为直到列表L中的元素数据不再有变化或者元素数量为0的时候		break		注：Canopy算法得到的最终结果的值，聚簇之间是可能存在重叠的，但是不会存在 某个对象不属于任何聚簇的情况显然，这种算法虽然快，但是很难生成满足我们应用的模型，所以通常我们将它作为解决K-Means初值敏感的方案，他们合在一起就是Canopy+K-Means算法。顺序就是先使用Canopy算法获得K个聚类中心，然后用这K个聚类中心作为K-Means算法。这样子就很好的解决了K-Means初值敏感的问题。Mini Batch K-Means算法Mini Batch K-Means算法是K-Means算法的一种优化变种，采用小规模的数据子集，来减少计算时间。其中采用小规模的数据子集指的是每次训练使用的数据集是在训练算法的时候随机抽取的数据子集。Mini Batch K-Means算法可以减少K-Means算法的收敛时间，而且产生的结果效果只是略差于标准K-Means算法。它的算法步骤如下：# 首先抽取部分数据集，使用K-Means算法构建出K个聚簇点的模型while not EndCondition:	1.抽取训练数据集中的部分数据集样本数据，并将其添加到模型中，分配给距离最近的聚簇中心点	2.更新聚簇的中心点值# EndCondtion同K-Means一样，可以理解为不停的进行K-Means算法。聚类算法衡量标准聚类算法的衡量标准有很多，包括均一性、完整性、V-measure、调整兰德系数（ARI ，Adjusted Rnd Index）、调整互信息(AMI，Adjusted Mutual Information)以及轮廓系数等等。均一性、完整性以及V-measure均一性：一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率，即每个聚簇中正确分类的样本数占该聚簇总样本数的比例和。其公式如下公式5.1。$$p = \frac{1}{k}\sum_{i=1}^k \frac{N(C_i == K_i)}{N(K_i)}\ \ \ 公式5.1  $$完整性：同类别样本被归类到相同簇中，则满足完整性。每个聚簇中正确分类的样本数占该类型的总样本数比例的和，通俗的来说就是，我们已分类类别中，分类正确的个数。其公式如下，公式5.2：$$r = \frac{1}{k}\sum_{i=1}^k \frac{N(C_i == K_i)}{N(C_i)}\ \ \ 公式5.2 $$在实际的情况中，均一性和完整性是往往不能兼得的，就好像抓特务时的矛盾一样，到底是保证每个抓的人都是特务，还是宁可错抓也不放过一个特务，之间的取舍很难把握。所以再一次贯彻，鱼和熊掌不可兼得，我们就加权，于是得到的就是V-measure，其公式如下公式5.3：$$V_\beta = \frac{(1+\beta^2)·pr}{\beta^2·p + r}\ \ \ 公式5.3  $$调整蓝德系数ARI兰德系数（RI，Rand index），我用中文看了不少讲兰德系数的博客，其中的文字说明几乎都是相同的，对个人的理解帮助不是特别大，于是用英文查的。最终理解了这个系数的参数的意思，想看英文说明的，个人觉得还挺好懂的参考这里。以下是我个人的讲解。首先，将原数据集中的元素进行两两配对形成一个新的数据集，我们称之为S数据集。这时候，我们将原数据集，根据两种不同的策略分别划分成r份和s份，并对这两个数据集命名为X和Y。在这里我们可以看出，X和Y的元素是相同的，只是他们的划分方式不同。接下来我们来思考，S数据集中，每个元素中的两个样本，在X和Y中只有两种可能，就是两个样本都在一个子集中，或者不在一个子集中，那么对于S中的一个元素，只有四种可能性。	两个样本都在X的一个子集中，也同时在Y的一个子集中，这些元素的个数是a	两个样本横跨X的不同子集，也同时在Y中横跨Y的不同子集，这些元素的个数是b	两个样本都在X的一个子集中，但在Y中横跨Y的不同子集，同理数量为c	两个样本横跨X的不同子集，但在Y的的一个子集中，同理数量为d有了上述的理解，我们再看蓝得系数公式，公式5.4，我们就不难理解了。RI的取值在$[0,1]$之间，越靠近1代表越相似。$$RI = \frac{a+b}{a+b+c+d} = \frac{a+b}{C_2^n} \ \ \ 公式5.4  $$接下来引入，调整兰德系数(ARI，Adjusted Rnd Index)，ARI取值范围$[-1,1]$，值越大，表示聚类结果和真实情况越吻合。从广义的角度来将，ARI是衡量两个数据分布的吻合程度的，公式5.5如下：$$ARI = \frac{RI - E[RI]}{max(RI) - E[RI]}\ \ \ 公式5.5$$调整互信息(AMI，Adjusted Mutual Information)调整互信息，整体的流程很像ARI，AMI则是对MI进行调整。而MI是使用信息熵来描述的。那么互信息表示了什么呢，首先先看下维基百科的定义：独立的(H(X),H(Y)), 联合的(H(X,Y)), 以及一对带有互信息 I(X; Y) 的相互关联的子系统 X,Y 的条件熵。在概率论和信息论中，两个随机变量的互信息（Mutual Information，简称MI）或转移信息（transinformation）是变量间相互依赖性的量度。不同于相关系数，互信息并不局限于实值随机变量，它更加一般且决定着联合分布p(X,Y) 和分解的边缘分布的乘积 p(X)p(Y) 的相似程度。互信息是点间互信息（PMI）的期望值。互信息最常用的单位是bit。简单的来说，这个公式代表着两个子系统X和Y的相似度，但是这里的相似度是从信息熵的角度出发的，它越大代表着两者的差异越大，其计算公式以及相关的公式如下公式5.6，公式5.7所示。$$MI(X;Y) = \sum_{y \in Y}\sum_{x \in X}p(x,y)\log{\frac{p(x,y)}{p(x)p(y)}}\ \ \ 公式5.6$$$$\begin{split}MI(X;Y) &= H(X) - H(X|Y)\\&=H(Y) - H(Y|X)\\&=H(X) + H(Y) - H(X,Y)\\&=H(X,Y) - H(X|Y) - H(Y|X) \ \ \ 公式5.7\end{split}$$轮廓系数之前我们说到的衡量指标都是有标签的，这里的轮廓系数则是不包含标签的评价指标。	簇内不相似度：		计算样本i到同簇其它样本的平均距离为$a_i$ 。$a_i$越小，表示样本$i$越应该被聚类到该簇，而簇C中的所有样本的$a_i$的均值被称为簇C的簇不相似度。	簇间不相似度：		计算样本i到其它簇$C_j$ 的所有样本的平均距离bij， $b_i=min{bi1,bi2,...,bik}$ ，$b_i$ 越大，表示该样本$i$越不属于其它簇。	轮廓系数：		$s_i$值越接近1表示样本i聚类越合理，越接近-1，表示样本i应该分类到另外的簇中，近似为0，表示样本i应该在边界上。所有样本的si的均值被成为聚类结果的轮廓系数。		$$		s_i = \frac{b_i - a_i}{max\{a_i,b_i\}}		$$]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[BaiduPCS-Go的使用]]></title>
      <url>/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/2018/08/17/BaiduPCS-Go%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      <content type="text"><![CDATA[Why BaiduPCS-GoBaiduPCS-Go是一个用Go语言编的命令行版的百度网盘，我们可以类比mas和Appstore的关系。那么为什么要用这样一个安装比较麻烦，还要记命令行的百度网盘的替代品，直接用百度网盘客户端不好么？这还真的是不好，百度网盘在mac下是一个十足的阉割版，最常用的功能中，Mac版缺失了以下几种功能：  没有分享功能：mac下的客户端的分享功能居然是需要通过浏览器打开，太不优雅了。  没有离线下载任务：直接导致不能下载磁力链接。如果你和我一样平时一样习惯终端操作，这个工具的学习成本超级低，同时它还有一定的提升下载速度的功效。使用指南安装Mac一般是预装了go的，如果没有的话，使用brew install go来安装。除了go我们还需要安装git，同样使用brew install git。在拥有了git和go以后，执行下面的指令即可。go get -u -v github.com/iikira/BaiduPCS-Go注：在安装途中，有提示说其安装到了一个~/go/bin的目录，也就是说这个工具的执行文件在~/go/bin这个目录。为了之后我们能够全局使用这个指令，于是我们将export PATH="/Users/deamov/go/bin:$PATH"添加到配置环境变量的文件中，如果没有使用zsh的话在~/.bashrc中，如果用的是zsh的话在~/.zshrc中。注：deamov是我的电脑的用户名，至此安装便结束了。常用操作说明登陆BaiduPCS-Go简单一行指令就可以登录了，如果之前已经登陆过账号的话，现在就已经可以开始进行下载等操作了，如下效果图。 第一次使用需要有登陆的操作，输入login即可登陆，尊许提示依次输入账户和密码即可，如果需要验证码，则会输出一个链接，打开就可以看到验证码了。基本操作基本的移动目录的方式和linux的操作一样，ls是现实当前目录的文件，rm是删除命令，cd是切换目录，创建目录是mkdir，拷贝是cp，值得一提的是它支持Tab补全。和平时使用的终端命令不同的有如下几个指令。  搜索：平时我们使用的grep在这里是不能使用的，我们用search关键词来搜索。      search 关键字 # 搜索当前工作目录的文件  search -path=/ 关键字 # 搜索根目录的文件  search -r 关键字	# 递归搜索当前工作目录的文件         下载：记住是download就好啦      BaiduPCS-Go download &lt;网盘文件或目录的路径1&gt;   BaiduPCS-Go d &lt;网盘文件或目录的路径1&gt; &lt;文件或目录2&gt; &lt;文件或目录3&gt; ...  # 当然支持多文件下载咯，下载目录默认在~/Download文件夹中        离线下载: 支持http/https/ftp/电驴/磁力链协议      # 将百度和腾讯主页, 离线下载到根目录 /  offlinedl add -path=/ http://baidu.com http://qq.com  # 添加磁力链接任务  offlinedl add magnet:?xt=urn:btih:xxx  # 查询任务ID为 12345 的离线下载任务状态  offlinedl query 12345  # 取消任务ID为 12345 的离线下载任务  offlinedl cancel 12345         分享share    查看分享内容      share list  share l        取消分享      share cancel &lt;shareid_1&gt;  share c &lt;shareid_1&gt;  # 遗憾的是只能支持通过shareid来取消分享        上传：同名文件会被覆盖    注：需要退出BaiduPCS-Go使用，否则本地文件目录不能自动补全    $BaiduPCS-Go upload &lt;本地文件/目录的路径1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;$BaiduPCS-Go u &lt;本地文件/目录的路径1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;# Example$BaiduPCS-Go upload ~/Downloads/1.mp4 /Video        其他    这个工具很强大，还可以通过设置下载线程数等等操作来提升下载速度，更多详细的操作请参考它的官网。  ]]></content>
      <categories>
        
          <category> 软件使用 </category>
        
      </categories>
      <tags>
        
          <tag> 百度网盘 </tag>
        
          <tag> 下载 </tag>
        
          <tag> 教程 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Tobias的小粉丝在此]]></title>
      <url>/%E6%9D%82%E9%A1%B9/2018/08/16/Tobias%E5%B0%8F%E8%BF%B7%E5%BC%9F%E5%9C%A8%E6%AD%A4/</url>
      <content type="text"><![CDATA[									Tobias的小粉丝在此	序言最近迷上了吉他，当然不是指那种一周速成的把妹弹唱啦。为了防止大家对吉他有一种特别简单，把妹专用道具的奇怪印象。特别提一个小知识，古典吉他在世界公认的十大难学的乐器中排第三，顺便一提，钢琴排第五。正文不过，非常遗憾最近喜欢上的是并不是尼龙弦的古典吉他，而是它的另一个兄弟指弹吉他中的Percussive Fingerstyle。Percussive FingerStyle起源于80到90年代，它通过快速击打琴弦，琴身，以及琴的边缘制造装饰音。现在比较有名的几个这个风格的吉他手有Andy McKee和Tommy Emmanuel，而Tobias Rauscher也是这个领域的新秀，也是目前我最喜欢的吉他手之一。值得一提的是，他是14岁开始自学的吉他，开始的时候主要弹奏摇滚和重金属，知道2010年终于开始了Solo Acoustic Guitar的道路。和相似的同时用多个吉他，甚至奇怪形状吉他的Luca Stricagnoli不同，他只使用一把吉他，视觉效果上没有了那份笨重，同时Tobias的笑容也能让人感受到他对于吉他的热爱。有兴趣的小伙伴可以在网易云搜他的曲子。惭愧的说，第一次听他的曲子也是在网易云里面听到了，结果整整单曲循环了好几天（笑。其他Tobias的官网在此]]></content>
      <categories>
        
          <category> 杂项 </category>
        
      </categories>
      <tags>
        
          <tag> FingerStyle </tag>
        
          <tag> Guitar </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[支持向量机SVM]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/13/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/</url>
      <content type="text"><![CDATA[									支持向量机（Support Vector Machine）	SVM的优点和缺点	优点：泛化错误率低，计算开销不大，结果易解释	缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二类问题。	数据类型：数值型和标称型数据。SVM算法原理首先我们都知道，为了划分二维的数据需要一根线，划分三维数据需要一个面。这里线是一维，面是二维，同理继续推出对N维的数据需要使用N-1维的对象进行分割，线性回归和SVM本质都是通过找这个超平面来达到分类的效果。具体的来说SVM是在优化线性回归中的$kx+b$模型。在线性回归中只需要考虑有一个分割超平面能进行分类即可，而SVM则想找出所有能分类的分割超平面中最优的超平面，即所有点都到分割超平面的距离最大，而支持向量指的就是离超平面最近的那些点。超平面的公式为公式2.1。所以点A到分割超平面的距离为公式2.2。这里我们为了方便计算引入类别标签为-1和+1。所以保证所有的最小间隔的点最大化的公式为公式2.3。注1：-1和+1是为了保证预测正确的时候，$y(x_i)*label_i$都是一个很大的正值。注2：$arg\ max_{w,b}$的含义是，得到w和b使得后面式子取最大值$$y(x) = w^TX+b\ \ \ 公式2.1$$$$\frac{|w^TX+b|}{||w||}\ \ \ 公式2.2$$$$arg\ max_{w,b}\{min_i(label_i*(w^Tx_i+b)*\frac{1}{||w||})\}\ \ \ 公式2.3$$显然我们不能直接求解上面的式子。需要化简下它。由于公式2.1在正确预测时，同$label$的乘积大于1。所以我们可以拆分公式2.3为公式2.4，约束条件为公式2.5。注：这里的约束条件公式2.5中，要对每一个式子前都要加系数，即拉格朗日数乘子$\alpha_i$。$$arg\ min_{w,b}\ ||w||\ \ \ 公式2.4$$$$st.\ \ label_i*(w^Tx_i+b) \geq 1 \ \ \ 公式2.5$$对为了方便求导计算在公式2.4前加上$\frac{1}{2}$这个系数。之后使用拉格朗日乘子法得到公式2.6，并进行计算。根据KKT条件中的偏导数等于0得到公式2.7和公式2.8。祝：这里需要注意的是拉格朗日数乘子的正负号，这个同不等式的符号有关$$L(w,b,\alpha)= \frac{1}{2}||w||^2-\sum_{i=1}^n\alpha_i*[label_i*(w^Tx_i+b)-1]\ \ \ 公式2.6$$$$\sum_{i=1}^{n}\alpha_i label_i x_i = w\ \ \ 公式2.7$$$$\sum_{i=1}^{n}\alpha_i label_i = 0\ \ \ 公式2.8$$将公式2.7，公式2.8代入公式2.6化简，再根据对偶问题得到最终公式2.9，根据KKT，其约束条件为公式2.10。注1：KKT条件在SMO算法中统一进行讲解。注2：b是由公式2.8消掉的。注3：在拉格朗日乘子法应用在这里，我们可以把$||w||$，写作$max_\alpha\ L(w,b,\alpha)$，所以原式可以写作$min_{w,b}\ max_\alpha\ L(w,b,\alpha)$，根据对偶问题，就可以变成$max_\alpha\ min_{w,b}\ L(w,b,\alpha)$，这也是能把公式2.7和公式2.8代入公式2.6的原因，也是公式2.9种是$max_\alpha$的原因。具体证明在KKT中的附上的博客中。$$max_\alpha\ \sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i,j=1}^{m}label_i*label_j*a_i*a_j\langle x_i·x_j\rangle\ \ \ 公式2.9$$$$\alpha_i \geq 0\ \  且\ \sum_{i=1}^{m}\alpha_i*label_i = 0\ \ \ 公式2.10$$注：这里$\langle x_i·x_j\rangle$是两者向量积的运算，是从$x_i^T*x_j$得到的。这么看来我们算出了$\alpha$就能算出超平面，所以SVM的工作就是算出这些$\alpha$，而SMO算法就是求$\alpha$的典型算法。对SVM引入线性不可分由于数据都不那么干净，所以我们不应该假设数据能够100%的线性可分。我们通过对判定的公式，公式2.5，引入松弛变量$\xi_i\geq 0$，得到其引入了松弛因子的形式，如下公式3.1。$$y_i(w*x_i+b)\geq1-\xi_i\ \ \ 公式3.1$$同时对于目标函数公式2.4也需要调整，我们将$\xi$引入目标函数并对其设置权值，得到公式3.2，也因此其约束条件变为公式3.1，公式3.2。$$min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^N\xi_i\ \ \ 公式3.2$$$$\begin{split}st.\ \ \ &y_i(w*x_i+b)\geq 1 - \xi_i\\&\xi \geq 0\end{split}$$故拉格朗日函数$L(w,b,\xi,\alpha,\mu)$为如下公式3.3，其中$\alpha$，$\mu$为拉格朗日数乘子。$$L(w,b,\xi,\alpha,\mu)=\frac{1}{2}||w||^2+C\sum_{i=1}^N\xi_i-\sum_{i=1}^n\alpha_i*[label_i*(w^Tx_i+b)-1+\xi_i]-\sum_{i=1}^n\mu_i\xi_i\ \ \ 公式3.3$$和之前的操作一样，对其进行求偏导操作后，类似的得到了相同的公式2.7，公式2.8，不同的是这里对$\xi$的求到后对$\alpha$有了限制，得到了公式3.4，由于$\mu\geq0$所以有$\alpha_i$的取值范围$0 \leq \alpha_i \leq C$。注：注意这里的$\alpha$取值，之后SMO会用$$C-\alpha_i-\mu_i = 0\ \ \ 公式3.4  $$最终目标函数还是同之前推到的相同，即公式2.9，约束条件中只有$\alpha$的取值变为了，$0 \leq \alpha_i \leq C$。这样有了目标函数了以后，之后可以根据梯度下降算法求得最终的$\alpha$SMO（Sequential Minimal Optimization）KKT条件 求$f(x)$ 极值的时候我们这里讨论三种情况。	没有约束条件：	有一个等式$h(x)$的约束条件：		使用拉格朗日乘子法（Lagrange Multiplier），也就是我们在高数中求极值常用的。设置一个拉格朗日系数$\alpha_1$，得到如下公式，之后对$x$和$\alpha_1$用求导的方式求极值即可。		$$		L(x, \alpha) = f(x) + \alpha*h(x)		$$	含有不等式的约束条件：		当约束条件中有不等式时，就需要用到KKT条件。同样地，把所有的不等式约束$g(x)\leq0$、等式约束$h(x)=0$和目标函数$f(x)$全部写为一个式子如下公式。		$$		L(x,\alpha_1, \alpha_2)= f(x) + \alpha_1*g(x)+\alpha_2*h(x)		$$		KKT条件是说最优值必须满足以下条件：					$L(x, \alpha) = f(x) + \alpha(x)$ 对$x$，$\alpha_1$，$\alpha_2$求导为零。			$h(x)=0$ 。			$g(x)*\alpha_1=0$。				其中第三个式子非常有趣，因为$g(x)\leq$ 0 ，如果要满足这个等式，必须有$a = 0$或者$g(x) = 0$。这是SVM的很多重要性质的来源。同时$f(x)$也可以写作$max_{\alpha_1,\alpha_2}\ L(x,\alpha_1,\alpha_2)$，这个则是SMO求解中的一个关键性质。详细的论述参考这篇博客。SMO算法细节SMO算法综述由于原来直接通过梯度下降进行求解速度太慢，所以1996年，John Platt依靠KKT的特性，将大优化问题变成了多个小优化问题来求解，成为了SVM中最常用的求解思路。其思路如下：	Loop：					选取一对 $\alpha_i$，$\alpha_j$作为变量，其余看为常数			如果这对$\alpha$满足以下两个条件，使用梯度下降算法改变他们的值。									两者都在间隔边界外					两者都没有在进行过区间化处理，或者不在边界上							当满足了KKT条件，即$\sum_{i=1}^N\alpha_iy_i=0$和$0\leq \alpha_i \leq C$。		注：这里可以这么理解，$\alpha_i$从之前的公式中我们可以大致理解为是每一个样本的权值，我们这些操作可以理解为通过操作$\alpha$把所有的样本点尽量的放在间隔边界上。算法推导我们接下来要做的是，通过类似梯度下降的方式来求的最优的$\alpha$值。正如上一节所说的，SMO的本质是大优化问题画小优化问题。所以从目标函数公式2.9中，随意取出两个$\alpha$，为了表达方便，不妨直接取$\alpha_1$和$\alpha_2$，同时对公式2.9前加负号取反之后，化简如下式4.1，其中$\kappa_{ij}$代表$\langle x_i·x_j\rangle$。$$\begin{split}min_{\alpha_1, \alpha_2}W(\alpha_1,\alpha_2) &=\frac{1}{2}\kappa_{11}\alpha_1^2+\frac{1}{2}\kappa_{22}\alpha_2^2+y_1y_2\alpha_1\alpha_2\kappa_{12}-(\alpha_1+\alpha_2)\\&+y_1\alpha_1\sum_{i=3}^Ny_i\alpha_i\kappa_{i1}+y_2\alpha_2\sum_{i=3}^Ny_i\alpha_i\kappa_{i2}\ \ \ 公式4.1\\\end{split} $$$$\begin{split}st. \ \ &\alpha_1y_1+\alpha_2y_2=-\sum_{i=3}^Ny_i\alpha_i\\&0\leq\alpha_i\leq C\end{split}$$由于我们已经把不是$\alpha_1$和$\alpha_2$的参数看作常量，所以在进行求偏导进行梯度下降算法的时候就不需要考虑公式4.1中第二行的式子。通过这个式子中约束条件的等式就可以得到仅含$\alpha_j$的式子，对其进行梯度下降算法，得到如下公式4.2：$$g(x)=\sum_{i=1}^Ny_i\alpha_i\kappa(x_i,x)+b  $$$$\eta = \kappa_{11}+\kappa_{22}-2\kappa_{12} = ||x_1-x2||^2$$$$E_i = g(x_i)-y_i = (\sum_{j=1}^Ny_j\alpha_j\kappa_{ji}+b)-y_i$$$$\alpha_i = \frac{\xi-\alpha_j y_j}{y_i}$$$$\alpha_j^{new}=\alpha_j^{old}+\frac{y_j(E_i-E_j)}{\eta}\ \ \ 公式4.2$$这时候我们已经找到了两个的$alpha$的新值了，不过我们不能确定这两个新值是否还满足KKT条件。所以我们根据KKT条件中$\alpha$的取值，设置了L和H来防止新值不满足KKT，即$L\leq\alpha_i,\alpha_j \leq H$，其中L，H的公式如下公式4.3和公式4.4得到：$$if\ y_i \neq  y_j\ \ \ L=max(0,\alpha_j-\alpha_i),\ H=min(C,C+\alpha_j-\alpha_i)$$$$if\ y_i = y_j\ \ \ L=max(0,\alpha_j+\alpha_i-C),\ H=min(C,\alpha_j+\alpha_i)$$LH的细节推到，在这个博客中详细的说明了LH是怎么推出来的。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[使用Github创建自己的小博客]]></title>
      <url>/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/2018/08/12/%E4%BD%BF%E7%94%A8Github%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%B0%8F%E5%8D%9A%E5%AE%A2/</url>
      <content type="text"><![CDATA[							使用Github创建自己的小博客	懒人攻略只有四步：	找到自己喜欢的别人的博客的Github地址，一般为username.github.io结尾。	Fork一份对方的源码，之后把仓库名改为YourGithubName.github.io	在_config.yaml中更改个人信息，同时把_posts中的文章都删了，注意别人的文章格式，之后仿照对方的格式写即可。	给你Fork的原作者写封邮件表达感谢！说不定就这么勾搭了一个大佬也不一定呢。完成了四步后，浏览器输入YourGithubName.github.io就能在晚上看到自己的博客啦。折腾攻略本这不重新造轮子的原则，附上我参考的大佬们的文章。	搭建篇：		简书上chaosinmotion 的 Github Pages + Jekyll 独立博客一小时快速搭建&amp;上线指南 	添加评论系统：		Github上knightcai的 为博客添加 Gitalk 评论插件 		特别一提，如果出现Validation Error是因为博客标题的名字编码后太长了，参考这个Issue中mr-wind的使用 id: decodeURI(location.pathname) 解决方案。		注：md5的方案可能更好，偷懒起见我没有用。	阅读量统计：		wanghao的 为NexT主题添加文章阅读量统计功能 ，这个文章用的是leandCloud。	搜索服务：		使用Algolia，不过自带的LocalSearch比较简单。文章有配置说明。	主题：		Next系列。官网有安装手册。	CopyRight:		在目录下搜索copyright，找到那个html文件进行修改就好了。效果是文章下面的红竖杠中的内容。	小彩蛋：		史蒂芬小恐龙，他的js文件在这里！之后就任君发挥啦，Happy Coding。	最后题外话		所有的配置基本上都可以在_config.yaml中设置，同时在博客中\代表的就是根目录，这样子你自己在配置其他的功能的时候就可以轻松愉悦的配置。值得一提的是css文件和js文件都在assets文件夹中，自己DIY的时候最好不要打乱目录结构。]]></content>
      <categories>
        
          <category> 软件使用 </category>
        
      </categories>
      <tags>
        
          <tag> GithubPage </tag>
        
          <tag> 博客 </tag>
        
          <tag> 教程 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[决策树优化策略]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/10/%E5%86%B3%E7%AD%96%E6%A0%91%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/</url>
      <content type="text"><![CDATA[							决策树优化策略	剪枝优化决策树的剪枝是决策树算法中最基本、最有用的一种优化方案，分为以下两类：	前置剪枝：在构建决策树的过程中，提前停止。这种策略无法得到比较好的结果	后置剪枝：在决策树构建好后，然后开始剪裁，一般使用两种方案。a）用单一叶子结点代替整个子树，也节点的分类采用子树中最主要的分类。b）将一个子树完全替代另一个子树。后置剪枝的主要问题是存在计算效率问题，存在一定的浪费情况。后置剪枝后置剪枝的核心思想其实就是交叉验证，其通过对完全树进行剪枝，一直剪到只剩下树根，这样子便得到许多树，然后通过使用数据集分别对他们验证，然后根据结果选择最优树。决策树剪枝过程while 生成的决策树不为1个节点:	计算所有内部非叶子节点的剪枝系数;	选择最小剪枝系数的节点:		if 有多个最小剪枝系数节点:			选择包含数据项多的节点删除		else:			删除节点		将剪枝后的树存入之后用的决策树集for 决策树 in 决策树集:	用数据集验证决策树，得到最优剪枝后的决策树	其最后用于验证决策树的损失函数如下公式1.1：$$loss = \sum_{t=1}^{leaf} \frac{D_t}{D}H(t)\ \ \  公式1.1$$剪枝系数的引入：剪枝系数的目的为，平衡准确度和树的节点数量之间的关系。所以很自然的想到我们常用的处理手法，在损失函数中引入叶子结点的变量，得到公式1.2。$$loss_{\alpha} = loss + \alpha*leaf\ \ \ \ 公式1.2$$设剪枝前的损失函数为$loss(R)$，剪枝后的损失函数为$loss(r)$，由于我们是想让剪枝前后的准确率尽量不变，所以让剪枝前后的损失函数相等，化简得公式1.3，即剪枝系数。注：剪枝后为根节点，所以$r=1$。$$\alpha = \frac{loss(r)-loss(R)}{R_{leaf}-1}\ \ \ \ 	公式1.3$$最后，由于我们想尽量减去的叶子结点多点，又同时保持准确度，故剪枝系数越小越好。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[决策树]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/09/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      <content type="text"><![CDATA[							决策树	信息熵信息量:指的是一个样本/事件所蕴含的信息，如果一个事件的概率越大，那么就 可以认为该事件所蕴含的信息越少。信息熵:一个系统越是有序， 信息熵就越低，一个系统越是混乱，信息熵就越高，所以 信息熵被认为是一个系统有序程度的度量。信息熵就是用来描述系统信息量的不确定度。$$H(x) = - \sum_{i=1}^m p_i log_2(p_i)$$条件熵： 给定条件X的情况下，所有不同x值情况下Y的信息熵的平均值叫做条件熵。$$H(Y|X) = \sum_{j=1}P(X = v_j)H(Y|X = v_j)$$$$H(Y|X) = H(X,Y)-H(X)$$决策树定义决策树(Decision Tree)是在已知各种情况发生概率的基础上，通过构建决策树来 进行分析的一种方式，是一种直观应用概率分析的一种图解法。决策树是一种预测模型，代表的是对象属性与对象值之间的映射关系。决策树是一种树形结构， 其中每个内部节点表示一个属性的测试，每个分支表示一个测试输出，每个叶节 点代表一种类别;决策树是一种非常常用的有监督的分类算法。构建过程构建步骤如下:	将所有的特征看成一个一个的节点;	遍历每个特征的每一种分割方式，找到最好的分割点;将数据划分为不同的子节点，eg: N1、 N2....Nm;计算划分之后所有子节点的&#39;纯度&#39;信息;	对第二步产生的分割，选择出最优的特征以及最优的划分方式;得出最终的子节点: N1、N2....Nm 4. 对子节点N1、N2....Nm分别继续执行2-3步，直到每个最终的子节点都足够&#39;纯&#39;。特征属性类型根据特征属性的类型不同，在构建决策树的时候，采用不同的方式，具体如下: 	 属性是离散值，而且不要求生成的是二叉决策树，此时一个属性就是一个分支	 属性是离散值，而且要求生成的是二叉决策树，此时使用属性划分的子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支	属性是连续值，可以确定一个值作为分裂点split_point，按照&gt;split_point和&lt;=split_point生成两个分支决策树分割属性选择	决策树算法是一种“贪心”算法策略，只考虑在当前数据特征情况下的最好分割方式，不能进行回溯操作。	对于整体的数据集而言，按照所有的特征属性进行划分操作，对所有划分操作的结果集的“纯度”进行比较，选择“纯度”越高的特征属性作为当前需要分割的数据集进行分割操作，持续迭代，直到得到最终结果。决策树是通过“纯度”来选择分割特征属性点的。量化纯度基尼系数：$Gini = 1 - \sum_{i=1}^nP(i)^2$信息熵：$-\sum_{i=1}^n P(i)log_2(P(i))$误差率：$Error = 1 - max_{i=1}^n \{P(i)\}$上面是基础的一些系数，在剪枝和判断的时候需要一个种体现变化的系数。$$Gain = \Delta = H(D)-H(D|A)$$可以这么理解，是否决策树以A为节点划分后，信息量增加了。也可以间接体现决策树越往下发生该事件的概率越小信息量越大。停止条件决策树构建的过程是以恶递归的过程，以下是两个停止条件。	每个字节点只有一种类型时停止条件。（容易过拟合）	节点中记录数小于某个阀值的时候，或者迭代次数达到给定值的时候停止构建。决策树的评估$$loss = \sum_{t=1}^{leaf} \frac{|D_t|}{D}H(t)$$其中$H(t)$前的参数$\frac{D_t}{d}$主要的目的其实是给信息熵加权值。算法对比ID3算法优缺点ID3算法是决策树的一个经典的构造算法，内部使用信息熵以及信息增益来进行 构建;每次迭代选择信息增益最大的特征属性作为分割属性。优点：	决策树构建速度快，实现简单。缺点：	计算依赖于特征数目较多的特征，而属性值最多的属性并不一定最优	ID3算法不是递增算法 ID3算法是单变量决策树，对于特征属性之间的关系不会考虑 抗噪性差	只适合小规模数据集，需要将数据放到内存中C4.5在ID3算法的基础上，进行算法优化提出的一种算法(C4.5)。其使用信息增益率来取代ID3算法中的信息增益，在树的构造过程中会进行剪枝操作进行优化。能够自动完成对连续属性的离散化处理。C4.5算法在选中分割属性的时候选择信息增益率最大的属性。信息增益率公式如下：$$Gain\_ratio(A) = \frac{Gain(A)}{H(A)}$$优点：	产生的规则易于理解	准确率较高实现简单缺点：	对数据集需要进行多次顺序扫描和排序，所以效率较低 	只适合小规模数据集，需要将数据放到内存中CART使用基尼系数作为数据纯度的量化指标来构建的决策树算法就叫做 CART(Classification And Regression Tree，分类回归树)算法。CART算法使用GINI增益作为分割属性选择的标准，选择GINI增益最大的作为当前数据集的分割属性。可用于分类和回归两类问题。注意的是：CART构建是二叉树，同时GINI系数的计算不牵扯对数运算比较快GINI增益公式如下：$$Gain = \Delta = Gini(D) - Gini(D|A)$$总结	ID3和C4.5算法均只适合在小规模数据集上使用	ID3和C4.5算法都是单变量决策树	当属性值取值比较多的时候，最好考虑C4.5算法，ID3得出的效果会比较差	决策树分类一般情况只适合小数据量的情况(数据可以放内存)	CART算法是三种算法中最常用的一种决策树构建算法。	CART算法构建的一定是二叉树，ID3和C4.5构建的不一定是二叉树。三种算法的区别仅仅只是对于当前树的评价标准不同而已，ID3使用信息增益、 C4.5使用信息增益率、CART使用基尼系数。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[《滚雪球》- 爱丽丝·查理芒格]]></title>
      <url>/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/2018/08/08/%E6%BB%9A%E9%9B%AA%E7%90%83-%E7%88%B1%E4%B8%BD%E4%B8%9D-%E6%9F%A5%E7%90%86%E8%8A%92%E6%A0%BC/</url>
      <content type="text"><![CDATA[							《滚雪球》 - 爱丽丝·查理芒格	读书笔记在巴菲特看来，真正富有的人生应该是这样的：做一份自己喜欢的工作，找到兴趣相投的朋友。只要能做到这些，你的人生也一样是成功的。正如巴菲特的总结，做一个自己能感到自己价值的工作，找到能互相认可的人也许才是人生的最大意义。在努力的做自己的喜欢的工作的时候才能更容因进入”专注“的境界。而兴趣相投的朋友则会让你的生活变得丰富，人说到底还是群居的动物，社交是必要的也是维持正常心理所必须要的要素。同时他们之间也是互通的，一个好的社交保持了好的积极的心态，保持了良好的且多元的信息社区，促进了工作的进步，工作的进步获得了回报，在财力和心理上形成正向激励，达成”飞轮效应“，进步越来越开实现复利增长。巴菲特有三宝，“内部积分卡”，“专注”，“复利”内部积分卡指的是，自己的行为有自己的评价标准，自己来定义自己是什么样的人，而不是由外部来定义自己，这样做到之后就会达到一种非常好的内心自洽。正如熊太行老师讲的那样，其实有时候内心自洽是一个强大者的开端，能让我们不去盲目的做一些违背自我的决定。“异于常人”的专注，其实很多时候是别人不能复制你成功的最大的壁垒。有着异于常人的专注的巴菲特能够通过专注找到“地上的烟蒂”，而缺了专注的行业其他人即便知道了方法也不能发现“烟蒂”。复利，在滚雪球中，复利的魅力用于体现在投资上，每次都能在之前的基础上以一个固定的比例进行增长，之后会越涨越快一发不可收拾。这点在吴军的《Google方法论》和《硅谷来信》，以及吴伯凡老师也多次提及，不过名词略有不同，吴军老师称之为指数增长，吴伯凡老师称之为飞轮效应。都在强调可叠加的魅力。如果放在生活中，我们应该常常反思，我们现在做的工作是不是可以叠加的，是不是在以大利益行动，是不是能成为未来的自己工作学习的基础。人生就像滚雪球，最重要的就是发现湿雪和长长的山坡这句话特别经典，也被很多人视为人生格言。我的感悟是，湿雪不难找到，但是有耐心和勇气去用人生这一个有限的时间，去选择一个长而不急的山坡不是每个人都能做到的。很多人看到别人在急坡中一时的成功，便忍不住放弃自己的计划，跟随别人，最终摔得人仰马翻。随后重复上述过程，直到到达山底最终一无所获。最佳的策略也许是认准一个“湿雪”较多的路径，随着不陡不缓的山坡，不急不躁，把自己的雪球越滚越大。个人总结今年开始，随着读的书越来越多，发现很多时候抛开大佬们成功的表象背后，总有一些惊人的相似的地方。首先是兴趣和专注，吴军说“努力只能让你成为行业的前20%，而兴趣决定了你是否能走完最后的10%”，自己不知道从什么时候起养成了一种选择困难症，虽然确定了计算机机器学习这个大方向，但是却没有一个具体的目标，导致近一个月来学习重心的摇摆不定，在机器学习，爬虫和区块链中摇摆不定。虽然他们学习的进度都还不错，爬虫接了北京高教所得项目，区块链得到了Hackathon竞赛的奖，机器学习算是初步入门正在踏入深度学习的领域，但是真真切切的感受到了自己能力的天花板，即“我没有能力去同时专精所有的方向”，方向仍需做减法。其次是“复利”，可叠加性的增长最有意思的是，往往这种复利型的进步开始的时候很困难，很累很苦，需要一个很强的内心去坚持，但随着飞轮开始转动一切就会变得理所当然。这点有一点小小的体会吧，这点体现在VIM的配置上面，开始的时候很艰难，各种快捷键都不知道是什么，觉得无比难用。不过，在了解到真的很多大佬是真的使用VIM或者类似的我认为超级难用的编辑器作为生产工具的时候，觉得也许应该坚持下来，不过没想到真的VIM在日后成为了我主要的生产工具。开始的时候只是配置了代码高亮，后来渐渐加入了代码补全，再后来补充了各种各样插件并学习了更多的快捷键，最后甚至自己能编一些脚本来实现自己想要的功能。那么它给我带来了什么“复利增长呢”，减少了不必要的分心，所有的学习需要的工具大多都能通过统一的途径获得，操作上不需要太多的改动，从论文的书写到代码的规范，同时由于打开很快的特性，能让我在有想法的时候就快速的写代码来测试，这些收获让我觉得之前的小努力都是值得的。同样的，我也相信算法，统计学和离散数学，包括博弈论，这些很多难啃又不会有立竿见影成效的东西最终会成为自己职业生涯复利增长的第一步。最后是内心自洽，个人自身的感受是，如果内心不能够自洽的话，很多精力都在花费在平复情绪上进行了没必要的经历开支，甚至“因为别人都这么做所以我也要这么做的”作出欠思考的行动，或者因为“情谊”做出了完全违背自己大利益的行动。行事内心要一把尺子，这把尺子要拿稳了。气场和魄力的起点便是内心自洽，如果自己都不能坚信自己的决定，又谈何让别人相信你的决定呢？]]></content>
      <categories>
        
          <category> 读书笔记 </category>
        
      </categories>
      <tags>
        
          <tag> Reading </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[回归算法下]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8B/</url>
      <content type="text"><![CDATA[							回归算法下	序言 在机器学习02（回归算法上）中我们介绍了普通最小二乘线性回归算法，并进行了较为详细的推导，并通过分析其过拟合的问题，推导出了另外三个算法，Ridge回归算法，LASSO回归算法，以及弹性网络。并简要的分析了他们的优缺点。今天我们来接着介绍算法。为什么说是算法而不是回归算法呢，是因为在研究了逻辑回归和Softmax回归算法以后，惊讶的发现这两个算法是分类算法，所以这个回归算法下的说法就不是很严谨了。Logistic回归在回归算法上中我们介绍了，线性回归算法。我个人是这么拆分的，线性-回归-算法，回归指的整体的算法是回归算法而不是分类算法，线性指的是在算法回归中，假定输入输出之间关系函数是$y = kx + b$这个线性方程。那么再看看Logistic回归，显然这里肯定就是换了另一个种类的方程咯。对的，不过在逻辑回归中这里有一点不太一样，它的输出只有0和1，它假定输出 $y = 1$的概率$P$，自然 $y = 0$的概率就是 $1-P$，而逻辑回归中假定的方程就是这个$P$。现在我们来看看这个方程是什么，如下公式1.1所示。这个公式没有接触过的朋友可能不太好想这是一个什么函数，但是结合着我们高数的极限知识，我们肯定知道这个函数在$+\infty $的时候去趋近于1，在$-\infty$的时候趋近于0，而且是快速收敛的。建议百度sigmoid函数看看这个函数的图（Logistic函数就是sigmoid函数）。	$p=h_\theta(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}} $		公式1.1之前在线性回归算法中我们知道了求最佳$\theta$的流程就是先写出他的似然函数（这个公式表示了预测正确的概率），然后求最大似然估计（想办法让这个预测正确的概率最大），最终通过求最大似然估计的结果，得到一种调整$\theta$的最佳方案。这个逻辑回归的似然函数为公式1.3(由公式1.2易得)。	$L(y|x;\theta)=(h_\theta(x))^y(1-h_\theta(x))^{1-y}$	公式1.2	$L(\vec y|x;\theta)=\prod_{i=1}^{m}(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}$					公式1.3之后对这个似然函数进行求导，我们都学过导数，在学导数的时候都知道，导数代表着值变化的趋势和速度。这里我们通过公式1.3对求对数，然后再对 $\theta_j $求导得到导数（公式1.4），这个导数就代表了针对$\theta_j $的正确预测的概率的变化趋势。如果让 $\theta$加上这个导数就可以保证让这个公式变大，直至最大为止。所以逻辑回归的调参如公式1.5，公式1.6所示，那么为什么是两个，在调参章节中会说明。	$\frac{\partial \ell(\theta)} {\partial \theta_j} = \sum_{i=1}^m(y^{(i)} - h_\theta(x^{(i)}))x_j$ 公式1.4	$\theta_j = \theta_j + \alpha \sum_{i=1}^m(y^{(i)} - h_\theta(x^{(i)}))x_j$	公式1.5		$\theta_j = \theta_j + \alpha (y^{(i)} - h_\theta(x^{(i)}))x_j $公式1.6好的，到这里逻辑回归的调参我们就知道了，特别的说明的是，这里的 $alpha$就是传说中的学习速率，而这个参数我们要注意的是，它不能太大（会错过最大值而不能收敛），也不能太小（会收敛到局部最小值）。那么我们有了调参，这里肯定也有一个损失函数来表示现在预测的怎么样吧，这里的思路很简单，你不是似然函数是越大越好么，那么我把你来个倒数不就好了么，最简单的做法就是给求对数之后的公式1.3，添加一个负号。所以它的损失函数如公式1.7。$loss(y^{(i)},\hat y^{(i)}) = -\ell(\theta) = \sum_{i=1}^m ln(1+e^{(1-2y^{(i)})\theta^T x^{(i)}}) $	公式1.7最后，想说从那个 只能为1或者0就可以看出逻辑回归虽然名字带了回归两个字，但是其实是一个分类算法。而接下来的SoftMax回归算法则是逻辑回归算法的一种拓展，这个在下一节里说。SoftMax回归在逻辑回归中，最终的分类结果，只有两类。这显然不是适用于很多其他的情况。所以SoftMax对逻辑回归进行了一般化，适用于K分类的问题。针对K分类的问题，我们的小伙伴 $\theta$参数就不在是一个向量了，我们设第K类的参数为向量$\theta_k$， 则有n个属性的参数就成了一个二维矩阵$\theta_{k*n}$。在Softmax回归中，我们设预测对第k类的概率为公式2.1。$p(y=k|x;\theta)=\frac{e^{\theta_k^T x}}{\sum_{i=1}^K e^{\theta_i^T x}} $, $k=1,2 ...,K $公式2.1剩下的分析同逻辑回归一样就不赘述了。机器学习调参我们在之前的学习中，了解到机器学习在迭代的过程就是不断的调整$/theta$参数的过程。有些是算法自己就调整了，有些是需要我们的人工的来调整的，这里就要引入超参这个概念了。什么事超参呢，超参就是不能通过算法自动调整的参数，比如Ridige回归和LASSO回归的 $\lambda$，弹性网络中的 $\alpha$。除了这些，在Logistic回归这一章节中，我们发现了调参函数有两个，但是并没有说明为什么。在这里将进行详细介绍。在Logistic和Softmax回归中我们用到的调参方式，只要你稍微了解过深度学习就一定听过，这种调参方式就是大名鼎鼎的梯度下降算法。而这两个公式，公式1.5是批量梯度下降算法（BGD），公式1.6是随机梯度下降算法（SGD）。通过公式1.6我们可以看出，每次迭代SGD调整一个$\theta_j$只需要和其中一条属性的比，而BGD每次迭代每调整一个$\theta_j$需要和所有属性的比较，所以SGD迭代速度快。那么SGD每次迭代考虑的属性少会不会没有BGD准呢，这是不一定的。梯度下降算法就像大雾天气下山，我们只能看清眼前的一小部分，并以此为依据下山，我们很有可能最后在山的上的一个小坑里出不来，陷入局部最优解的问题。SGD在全局餐在多个相对最优解的情况下，SGD很有可能跳出某些局部最优解，所以不一定会比BGD坏。而BGD一定能够得到一个局部最优解（在线性回归中一定是得到一个全局最优解）。不过由于SGD少考虑一些情况，所以有随机性，因而最终结果可能会比BGD差，一般情况下我们会优先使用SGD。注：个人的简单理解是，SGD每次只会往某一个坐标轴方向走一步，而BGD则是结合所有坐标轴的情况，往一个空间内的一个方向走一步。所以理论上BGD很“理性”。SGD和BGD出现的优缺点的情况是不是很熟悉，是不是很像Ridge回归和LASSSO回归的抉择，最终出现了弹性网络。那么是不是也有一个类似梯度下降算法的“弹性网络”呢，答案显然是有的，那就是MBGD，我不全不考虑完不就好了嘛。MBGD中每次拿b个样本的平均梯度作为更新方向，这里的b一般为10。这样子就既保证了速度，也一定程度上保证了准确度。模型效果判断最后，我们模型也训练好了，那么怎么来判定我的模型是不是合乎标准的，就像吴军老师在Google方法论说的一样，在工程中不是只有对错，只有相对的好和相对的不好，这个模型是否符合项目的需要也是有几个标准的，在训练的时候需要注意最终目标需要达到的标准是什么。常用的有MSE（公式4.1）、RMSE（公式4.2）、$R^2$（公式4.3）。在看公式前先说明TSS和RSS的概念，用在算$R^2$上。TSS(Total SUm of Squares)：总平方和TTS，样本之间的差异性。是伪方差的m倍。RSS：是预测值和样本值之间的差异，是MSE的m倍。$$MSE=\frac{1}{m}\sum_{i=1}^m(y_i - \hat y_i)^2\ \ \ 公式4.1$$$$RMSE=\sqrt{MSE} \ \ \ 公式4.2$$$$R^2 = 1 - \frac{RSS}{TSS} = 1-\frac{\sum_{i=1}^m(y_i-\hat y_i)^2}{\sum_{i=1}^m(y_i-\overline y)^2}\ \ \ 公式4.3$$				通过看公式我们可以得到以下的结论。MSE：误差平方和，越趋近于0越拟合。RMSE：就是对MSE开根号，所以和MSE的判别一样。$R^2$：值域为，最优解是1，若预测值恒为样本期望则为0除了这些，还有一个叫做混淆矩阵的东西，也是评价模型的一种手段，可以之后搜索看看。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[回归算法上]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8A/</url>
      <content type="text"><![CDATA[							回归算法上	​在序章中我们提到了，机器学习的本质就是一个分类器，对给出的数据进行有价值的分类。​具体的机器学习算法的分类分为，监督学习和无监督学习两种。而在监督渡学习中，我们以分类的类别是否是离散的，分为两种分类方式，分别是分类和回归。即，分类后是有一定的，像水果的分类，苹果，梨，橘子等等这样确定的分类的是分类，而分类后的预测结果是一个连续的数值则是回归。在这篇文章中，我们说的回归算法便是监督算法中的回归算法。最小二乘参数&amp;损失函数​还记得我们最开始说的，机器学习的实质就是分类么，即得到输入$x$后，通过一个训练好的关系$f(x)$，输出一个$\hat y$ ，如果你的模型好的话，$\hat y$ 和真实值$y$会非常接近，有着非常好的预测结果。在这一个章节中，将会从数学层面来讲一讲这个是如何做到的。首先我们用大白话，整体的了解下这是一个什么样子过程。首先，我们需要先确定个目标，打比方说我要做一锅好吃的菜，我刚开始拿到一个方子，买来了菜切好了菜，按照方子做了，即选了算法，拿到训练数据后，机器学习第一次迭代。之后，尝了一尝，觉得这个菜不和我胃口，即和已有数据标签对比，然后调整盐量，菜的切法之后，即发现结果不理想，以某种方式调整参数，再做一次，做完之后再尝，再调整，即再次迭代，最终研究出了自己喜欢的菜适合自己的配方，即符合要求的准确率停止训练。​看这个过程是不是简单的说就是，不断的调整方法，直到完成目标任务，就和小婴儿学习一样。那么过程现在知道了，那如何让我们的小婴儿计算机来学习呢。首先，我们想，最简单的方程是什么呢，很小我们就知道了$y = kx + b$ 这个直线公式，我们现在就用它来作为输入$x$和输出$y$之间的关系，所以引入下面的公式2.1。我是这么理解的，每一个输入 $x$ 都对输出 $y$ 有不同的作用效果，所以我们给输入 $x$ 前面写一个系数来代表它的作用强度，这个系数就是$k$ ，也就是下面公式中的 $\theta$ ， 那么后面的$\epsilon$ 是什么呢。我的理解是，你看，我们现在是做一个$y$ 的预测，从实际出发，我们很难找到完美的$\hat y$ 可以完全等于训练集中$x$ 所对应的 $y$ ，这时候误差是必定存在的，所以引入误差$\epsilon$，为我们通过模型预测的值$\hat y$ 和已知值$y$的差，如公式2.2所示。除此之外，我们可以把$\epsilon$ 看作现实中众多随机现象引起的误差，而这个误差一般符合高斯分布（参考中心极限定理），这个在之后的推导中也会用到。实际问题中，很多随机现象可以看做众多因素的独立影响的综合反应，往往服从正态分布。​$$y^{(i)} = \theta^T*x^{(i)}\ \ \ 公式2.1$$$$y^{(i)}- \theta^T*x^{(i)}= \epsilon^{(i)}\ \ \ 公式2.2$$​误差、误差，顾名思义，我们要让误差最小，由于$\epsilon$符合高斯分布（最大似然估计），所以$\epsilon$ 的概率应该符合公式2.3。然后用公式2.2进行等式代换得到公式2.4。那么这个公式2.4怎么理解呢，这里输入$x$是固定的，我们只能调整$\theta$来使输出$\hat y$来接近样本给出的$y$。而公式2.4的意思就是，在输入$x$的情况下，输出正确$y$的概率。$$p(\epsilon^{(i)}) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(\epsilon)^2}{2 \sigma^2}}\ \ \ 公式2.3$$$$p(y^{(i)}|x^{(i)};\theta) =\frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(y^{(i)}- \theta^T*x^{(i)})^2}{2 \sigma^2}}\ \ \ 公式2.4$$	​接下来我们要引入最大似然估计，小伙伴你们没有听错，就是考研数学中概率论的那个最大似然估计（居然真的用上了）。由于每个输入都是相互独立的，所以整体预测对的概率密度，可以通过每个样本预测对的概率密度相乘得到。于是我们得到了下面的公式2.5。是不是很熟悉，我们现在做的是改变$theta$使得概率最大，就和考研的时候学的一样，我们对公式2.5先求对数，然后求导就可以算出来我们要的$theta$的。$$L(\theta) = \prod_{i = 1}^mp(y^{(i)}|x^{(i)};\theta)\ \ \ 公式2.5$$​在这里有一点小小的变化，为了方便计算，我们对公式2.5求对数以后，我们得到了公式2.6。观察公式2.6我们很快的发现。$m \log \frac{1}{\sigma \sqrt{2\pi}}$和$m \log \frac{1}{\sigma \sqrt{2\pi}}$都是常数，和$\theta$相关的只有后面那部分。所以我们求导光求导后面的那块就好了。然后就可以得到一个$\theta$和输入和输出的关系公式2.7，机器就是这么求出最优解的，但是矩阵的求逆是很复杂的，这里会耗费大量的计算量。$$\ell(\theta) = m \log \frac{1}{\sigma \sqrt{2\pi}} - \frac{1}{\sigma^2}*\frac{1}{2}\sum^m_{i =1}(y^{(i)}-\theta ^{T}x^{(i)})^2 \ \ \ 公式2.6$$$$\theta = (X^TX)^{-1}X^TY \ \ \ 公式2.7$$​最后，我们在公式2.6中看到一个很有意思的公式，这个只要是了解过损失函数的人都是眼熟的。这个公式就是$-\frac{1}{2}\sum^m_{i =1}(y^{(i)}-\theta ^{T}x^{(i)})^2$，回想下损失函数的作用是什么，是一个求$\theta$的一个关键函数，它代表着预测的是不是准确，然后根据这个函数来调整我们通过输入$x$生成$y$的函数$h(x)$。所以我们可以写出如下公式2.8，而这个正是常用损失函数中的平方和损失函数。$$loss = J(\theta) = \frac{1}{2}\sum^m_{i =1}(h_{\theta}(x^{(i)})-y^{(i)})^2 \ \ \ 公式2.8$$​实际中我们有很多损失函数，如0-1损失函数，感知损失函数，平方和损失函数，绝对值损失函数，对数损失函数。3、多项式扩展​现在我们对整体的流程也有了了解，这里讨论下，在之前讨论中输入输出关系$f(x)$的一些遗留问题。之前我们说我们的目的就是找到这么一个$f(x)$，但是这个关系不会凭空出现，所以我们预测了一个关系$h(x)$，在预测的时候我们给每个样本属性$x$前都乘上了一个系数$\theta$，但是这么做有一个前提就是，这些属性之间是相互没有关联的，而这恰恰与实际完全不符。解决这个问题的正是，对函数$h(x)$进行多项式扩展，多项式扩展后出现了属性之间相乘的形式，自然就表示了属性间的相关性，预测的准确率也就大大提升了。4、什么是过拟合&amp;过拟合问题的解决​在我的理解中，即便是机器学习也是按照人指的方向进行数学问题的求解操作。在这个机器学习中，我们一定会找到一个通过样本来看预测效果非常非常好的结果，但是这个效果真的好么。如下图，我们可以看到，每一个样本都是符合的，但是很显然这个曲线是不对的。​这是什么原因导致的呢，在通过输出$\theta​$值，我们发现，这是由于某些$\theta​$值过大导致的。所以我们由此可以想到解决方案就是，用一个添加项来迫使$theta​$不至于过大。在这里我们引入正则项（norm），即L1-norm，L2-norm。通过公式我们可以看出，我们要让损失函数很小，加入了正则想项后，势必$\theta​$不会变得太大。​L2-norm：$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i}) - y^{(i)})^2 + \lambda\sum^n_{j=1} \theta_j^2 $$\ \ \ \lambda > 0$L1-norm：$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i}) - y^{(i)})^2 + \lambda\sum^n_{j=1} |\theta_j| \ \ \ \lambda > 0$​当我们使用L2-norm的线性回归模型就是Ridge回归（岭回归模型），而我们使用了L1-norm 的模型则是LASSO回归。接下来我们分析下这两个的性能问题。​L2-norm中，由于对于各个维度的参数缩放是在一个圆内缩放的，几乎不可能导致有维度参数变为0的情况，那么也就不会产生稀疏解；而L1-norm是在一个方形内的，则很容易产生稀疏解。实际应用中，数据的维度中是存在噪音和冗余的，稀疏的解可以找到有用的维度并且减少冗余，提高回归预测的准确性和鲁棒性（减少了过度拟合），而L1-norm则可以达到最终解的稀疏性的要求。​所以，Ridge模型有较高的准确性和鲁棒性，而LASSO模型更快，更能晒出稀疏解。那么如果我们两个属性都要兼备怎么办呢。接下来就引入了弹性网络ElasitcNet算法。其实就是很暴力的同时引入了L1-norm和L2-norm，然后用$p$来代表哪个多点，具体公式如下。$$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i} - y^{(i)}))^2 + \lambda(p\sum^n_{j=1} \theta_j^2 +(1-p)\sum^n_{j=1} |\theta_j| )\ \ \ \lambda > 0 \&\& p \in [0,1]$$]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[机器学习序章]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%8F%E7%AB%A0/</url>
      <content type="text"><![CDATA[							机器学习系列（序章）	序言机器学习&amp;人工智能&amp;深度学习，这三个是现在经常听到的词语。一旦提到了这些都会给人一种高大上的感觉，感觉会是一种很难学会的技术。表示在下血本（突然脑抽）的情况下，剁手买了1w多的数据挖掘的网课，目前正在学习它，希望能在学习完成后揭开机器学习的面纱，争取让每个读我的博客的人都能对机器学习有一个较为全面的概念。目前的更新顺序为课程的顺序，在整体学完之后，会按自己的理解进行一个汇总。什么是机器学习首先先上官方的卡内基梅隆大学的教授TomMitchell的定义。A program can be said to learn from experience E with respect to some class of tasks T and performance measure P , If its performance at tasks in T, as measured by P, improves with experience E.对于某给定的任务T，在合理的性能度量方案P的前提下，某计算机程序可以自主学习任务T的经验E；随着提供合适、优质、大量的经验E，该程序对于任务T的性能逐步提高。看起来很官方的说法对吧，接下来粗略的说明是怎么回事。一句话版本：抓了一把混着豆子的米（数据），根据你对豆子和米的特征的认识（已有经验），把豆子和米分开分别装在两个袋子里（分类），随后验收的人看你是否真的把米和豆子分开了（性能度量）。数学版本：X*P=Y，Y是分类的类别，X是一个数据，我们找的是矩阵P能使所有的数据X都能对应到相迎的分类Y。简单来说，机器学习就是分类器，通过学习已有的数据，得到一个数据和类别的关系，再用这个关系来对未来未分类的数据进行预测，这就是我理解的机器学习。 机器学习&amp;人工智能&amp;深度学习有什么区别说到这里，有些学过深度学习的人肯定就会疑惑这个和机器学习好像一样啊，深度学习也是把图片分类啊。是的，深度学习准确的来说算是机器学习的一部分，而机器学习和深度学习又可以被人工智能所包含。只不过深度学习在图像识别和语音识别的方便有着突出的优势，而机器学习在数据挖掘，统计学习和自然语言处理方面已经有了很大的发展。它的工作流程是什么样子数据收集=&gt;数据预处理(数据清洗)=&gt;特征提取=&gt;模型构建=&gt;模型测试评估=&gt;上线=&gt;迭代数据收集和数据清洗：可以理解为，做饭前的买菜（为模型提供训练用的有效数据，去除显而易见的无效数据）特征提取：可以理解为，炒菜前的切菜，切的越好，炒完越好吃（即从数据中选出可能能代表数据特征的属性）模型构建：可以理解为炒菜，用切好的菜，以一定的顺序进行翻炒（选择合适的算法来训练模型）。模型测试评估：试吃，如果不好吃，则反思是不是切的不好，菜买的不对，或者炒的顺序不对（测试用例看是否符合标准，如果不对责重复前面的步骤）。特别的说，训练的部分，其实就是以当前的权值运算出来的结果和已知结果对比，然后根据差距来修改权值，如此往复，使预测结果和已知结果无限接近。算法的分类和选择机器学习分为如下几个分类：	有监督学习：也就是训练用的数据是有标签的，在训练前是人工分好类的。再用训练过后的模型，对未来收到的数据进行分类，来达到预测的目的。	无监督学习：和有监督学习相比，训练的数据是没有分类的，在无监督学习中，就是通过学习，把这些为分类的数据进行分类，来推断出数据的一些内在结构。	半监督学习：训练的数据包含少量的含有标签的数据，通过这些数据来训练和分类。顾名思义就是无监督和有监督的结合。然后从算法的角度来看，又可以分为如下三种：	分类：标签是整形的，是一个一个独立的离散的。分类标识的时候使用int型。	回归：标签是浮点型，分类是连续的而不是离散的。分类表示用float的型。	聚类：1，2都是有监督学习，而3则是无监督学习。最后附上一个算法的选择图：（图很清楚只需要一点的英文水平就能看懂）classification:分类 regression:回归 clustering:聚类 dimensionality reduction：降维度公开数据获取渠道	UCI Machine Learning Repository （新手推荐这个，有标签）	Amazon Public-datasets	Kaggle	KDnuggets	Sougou语料库	天池	DC竞赛]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
