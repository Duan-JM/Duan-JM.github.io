<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[关于设置YouCompleteMe Python3语法支持]]></title>
      <url>/troubleshoot/2018/09/16/%E5%85%B3%E4%BA%8E%E8%AE%BE%E7%BD%AEYouCompleteMe-Python3%E8%AF%AD%E6%B3%95%E6%94%AF%E6%8C%81/</url>
      <content type="text"><![CDATA[关于设置YouCompleteMe Python3语法支持问题描述YouCompleteMe 只能支持 Python2 的补全，不支持 Python3 库的补全。解决  重新去 YouCompleteMe 用 git pull 一下。  使用 pip 安装 jedi     pip3 install jedi        重新用 python3 编译（非常重要）     python3 ./install.py --all        在 vimrc 中添加支持     let g:ycm_server_python_interpreter='/usr/bin/python3' let g:ycm_python_binary_path = '/usr/local/bin/python3'      参考YouCompleteMe Issue 2876 How do I complete Python3 with YouCompleteMe? ]]></content>
      <categories>
        
          <category> TroubleShoot </category>
        
      </categories>
      <tags>
        
          <tag> YouCompleteMe </tag>
        
          <tag> Vim </tag>
        
          <tag> TroubleShoot </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Python交互模式下自动补全]]></title>
      <url>/python/2018/09/15/Python%E4%BA%A4%E4%BA%92%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8/</url>
      <content type="text"><![CDATA[前言有时候我们需要测试一个小功能，懒人如我完全不愿意新建一个python文件去测试，但是默认的python交互模式下没有代码补全就很恼火，今天就把它解决了。步骤首先在 HOME 目录下新建一个叫做 pythonstartup 的文件。touch ~/.pythonstartup接下来在里面输入如下内容：&lt;pre name="code" class="python"&gt;import rlcompleterimport readlineimport atexitimport os # http://stackoverflow.com/questions/7116038/python-tab-completion-mac-osx-10-7-lionif 'libedit' in readline.__doc__:	readline.parse_and_bind('bind ^I rl_complete')else:	readline.parse_and_bind('tab: complete') histfile = os.path.join(os.environ['HOME'], '.pyhist')try:	readline.read_history_file(histfile)except IOError:	passatexit.register(readline.write_history_file, histfile) del readline, rlcompleter, histfile, os最后把它添加到环境变量中，zsh 在  zshrc 中，bash 在 bash_profile 中。echo 'export PYTHONSTARTUP=~/.pythonstartup' &gt;&gt; ~/.zshrc# for oh my zshecho 'export PYTHONSTARTUP=~/.pythonstartup' &gt;&gt; ~/.bash_profile# for bash参考文献CSDN中 jorrell 博主的 交互模式下python自动补全 ]]></content>
      <categories>
        
          <category> Python </category>
        
      </categories>
      <tags>
        
          <tag> Python </tag>
        
          <tag> 技巧 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[EM算法]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/09/15/EM%E7%AE%97%E6%B3%95/</url>
      <content type="text"><![CDATA[							EM算法	1、必要的前置知识	最大似然估计（MLE）：找出一组参数(模型中的 参数)，使得模型产出观察数据的概率最大。	贝叶斯算法估计：从先验概率和样本分布情况来计算后验概率的一种方式。	最大后验概率估计（MAP）：另一种MLE的感觉，求 $\theta$ 使 $P(x|\theta)P(\theta)$ 的值最大，这也就是要求 $\theta$ 值不仅仅是让似然函数最大，同时要求 $\theta$ 本身出现的先验概率也得比较大。	Jensen不等式：如果函数 $f$ 为凸函数，那么存在公式$f(\theta x + (1-\theta)y) \leq \theta f(x) + (1-\theta) f(y)$，进一步推论得到若 $\theta_1,...\theta_k \geq 0$ 且$\theta_1+\theta_2+...+\theta_k = 1 $，则有 $f(\theta_1 x_1 + ... + \theta_k x_k) \leq \theta_1 f(x_1) + ... + \theta_k f(x_k)$。2、EM算法EM算法（Expectation Maximization Algorithm）最大期望算法，是一种较为常用的算法思路，像之前的 SoftMax 算法就算是 EM 算法的一种，这种算法主要分为以下两个循环操作：	E步骤：估计隐藏变量的概率分布期望函数	M步骤：根据期望函数重新估计分布参数简单的来说就是写出带参数的表达预测正确的概率公式，然后用一种方法使得这个预测正确的概率最大。其整体的流程如下：注：这个使预测概率最大化的过程往往会得到一些关键的参数，有时候这个参数就是我们要求得某个事件发生的概率。	初始化分布参数	重复下列操作直至收敛					E步骤：估计隐藏变量的概率分布期望函数			M步骤：根据期望函数重新估计分布参数（用的是MAP），即重新调整模型参数$\theta$，公式如下				设数据集中包含着我们不能观测到的隐含数据$z = {z_1, z_2, ...,z_m}$				$$				\begin{split}				\theta &= arg\ max_\theta\sum_{i=1}^m log(P(x_i;\theta)) \\				&arg\ max_\theta\sum_{i=1}^m log(\sum_{z_i}P(z_i)P(x_i|z_i;\theta)) \\				&arg\ max_\theta\sum_{i=1}^m log（\sum_{z_i}(P(x_i,z_i;\theta))				\end{split}				$$		3、EM算法求解原理根据上一章中的EM算法总述看来，现在我们整体要做的就是根据对数似然函数，调整参数 $\theta$ 使得对数似然函数向变大的方向前进。按照以往的惯例，我们直接进行求导就好了。然而在这里则行不通，我们可以看到中间存在隐藏数据。为什么说是隐藏的呢，那是因为这个数据是不可观测的，也就是说我们不能在每一步中直接测量到这些数据。不过好消息是我们可以得到这个隐藏函数的分布。于是进行的曲线救国过程的第一步如下：\begin{split}l(\theta) &= \sum_{i=1}^m log\sum_z p(x,z;\theta) \\&= \sum_{i=1}^m log \sum_z Q(z;\theta) * \frac{p(x_i,z;\theta)}{Q(z;\theta)}\ \ \ 步骤1 \\&= \sum_{i=1}^m log(E_Q(\frac{p(x_i,z;\theta)}{Q(z;\theta)})\ \ \ 步骤2 \\&\geq \sum_{i=1}^m E_Q(log(\frac{p(x_i,z;\theta)}{Q(z;\theta)})\ \ \ 步骤3 \\&= \sum_{i=1}^m \sum_z Q(z;\theta) log (\frac{p(x_i,z;\theta)}{Q(z;\theta)})\ \ \ 步骤3\end{split}首先，我们明确的目标是得到最佳参数 $\theta$ 也就是说，我们企图得到一种可以把似然函数写成纯 $\theta$ 的公式，之后进行通过求偏导的方式来得到我们要求的最佳参数 $\theta$。步骤一中，我们引入了隐藏数据的分布 $Q(z;\theta) $ , 根据分布函数的性质$\sum_z Q(z;\theta)=1 $ ，所以我们加入这个参数是不会改变原函数的数值，之后根据数学期望的定义将右边式子写成了数学期望的形式，于是得到了步骤二。在步骤三中，根据根据Jensen不等式，我们可以得到$f(E(x)) \leq E(f(x))$，所以我们将$log$塞到期望函数里面，最终得到了步骤四。好了到现在为止，我们只是得到了另一个看似依旧不能计算的式子，貌似多此一举的引入了一个叫做 Jensen 不等式的东西，但是这一步是很关键。在未引入Jensen不等式之前，我们只是单纯的添加了一个叫做隐含数据的变量，但是它在式子中并未和别的参数相关，而引入了Jensen不等式之后，这个式子中的隐含数据将和数据集关联就变得可以测量得到了。所以曲线救国的第二步就是，根据Jensen不等式的取等条件得到 $\frac{p(x,z;\theta)}{Q(z;\theta)} = c$ 的时候等号成立，于是根据如下推导得到当等号成立的时候，得到的关系公式 3.1 。$$Q(z,\theta) = \frac{p(x,z;\theta)}{c} = \frac{p(x,z;\theta)}{c*\sum_{z_i}p(x,z_i;\theta)} = \frac{p(x,z;\theta)}{p(x;\theta)} = p(z|x;\theta)\ \ \ 公式3.1$$之后将公式 3.1 带入之前步骤三的公式中，得到如下公式3.2$$\sum_{i=1}^m \sum_z p(z|x_i;\theta) log (\frac{p(x_i,z;\theta)}{p(z|x_i;\theta)})\ \ 公式3.2$$又由于给定数据集之后 $p(z|x_i;\theta)$ 的值是固定的，所以可以去掉，而保留前方的 $p(z|x_i;\theta)$ 的原因类似 MAP 模型，要求先验概率也要大。之后便是传统的求能使公式3.2最大的模型参数 $\theta$ 。至此，我们公式已经推完了，简单的整体分析一下，式子中含有两个变量$z$ 和 $\theta$ ，我们先假定了 $\theta$ 的初始值，显然根据求导等于0能得到 $z$ 的值，之后再根据 $z$ 的值可以反求 $\theta$ 的变化方向。如此往复就是 EM 算法的求解过程。4、结语整体而言 EM 算法相比之前的算法引入了一个叫做隐含数据的变量，这个变量我们认为是会对结果发生影响的。整个算法都是在讨论一种，如何将这种我们不清楚的变量和我们预测手法联系在一起，其中用到了 Jensen 不等式来让他们联系在一起，变得可以被计算。以后有时间的话还会补充 GMM 在EM算法中的应用。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[支持向量机的补充之核函数]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/09/13/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E8%A1%A5%E5%85%85%E4%B9%8B%E6%A0%B8%E5%87%BD%E6%95%B0/</url>
      <content type="text"><![CDATA[							支持向量机的补充之核函数	支持向量机的补充之核函数在之前的SVM章节中我们介绍了其具体的原理和大致推导过程，但是由于SVM只能应用于线性可分的数据，那么如果出现了线性不可分的情况怎么办呢，这就要引入今天的重点核函数。这种思想将在未来的深度学习中也会出现。为什么要使用核函数	之前我们在线性回归算法中讲到的，使用多项式扩展来考虑属性间有相关性的问题。	将非线性问题变成线性问题。核函数的核心思想与优势什么是核函数呢？核函数就是两个向量在隐式映射过后的高纬空间中的内积的函数。它的价值在于它虽然也是将特征进行从低维到高维的转换，但核函数它事先在低维上进行计算，而将实质上的分类效果表现在了高维上，也就说它避免了直接在高维空间中的复杂计算。简单的来说，就是原本我们将低维的特征值映射到高维度的空间的时候，我们需要先将需要进行内积的两个向量映射到高维度的空间，之后进行内积操作。而使用核函数的价值在于，先对两个向量进行内积操作，之后再进行高维度的映射，而这个结果可以和之前先对向量进行映射的操作的方法大致相同。众所周知，在低维度进行内积操作的话，其运算的复杂度显然比高维度好很多，所以采用核函数的思想被广泛的应用。常用的核函数那么常用的核函数有以下三种	多项式核：$\kappa(x_1, x_2)=(\langle x_1, x_2 \rangle + R)^d$	高斯核函数RBF：$\kappa(x_1, x_2) = exp (-\frac{||x_1 - x_2||}{2\sigma^2})$	线性核函数：$\kappa(x_1,x_2) = \langle x_1, x_2 \rangle$结语使用核函数的时候其实就把原来的目标函数中的内积换成核函数就好了，不过其实在Sklearn中这些是可以在调用函数的过程中选择的，个人觉得知道这个概念和思想就好了。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Vim作者对高效使用编辑器的建议]]></title>
      <url>/vim/2018/09/02/Vim%E4%BD%9C%E8%80%85%E5%AF%B9%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E5%BB%BA%E8%AE%AE/</url>
      <content type="text"><![CDATA[							Vim作者对高效使用编辑器的建议（附原文地址）	原文链接：《Seven Habits of Effective Text Editing》前言本文摘自Vim主要作者Bram Moolennar的2000年11月在其个人网站发布的提高文本编辑效率的7个方法，个人认为从工具作者那里学习如何使用工具是最好的学习方式。本篇文章重点介绍了，达到高效使用编辑器的方法。第一部分、编辑文本1、快速在文本间移动	通过搜索的方式快速定位					使用\pattern的方式搜索			使用*直接对所在单词搜索			%在匹配括号间移动，[{返回之前的{，gd本地变量定义的位置。				注：应对搜索结果配置高亮	同样的内容不要打2遍					使用宏来记录你的重复性的操作（之后的文章会介绍）			活用.来重复上一步的文本操作。			自动纠错		对于经常犯的拼写错误，我们使用以下几种方式来避免。					自动补全：使用自动补全而不是自己手动输入变量名			自动纠错：对于自己经常犯的拼写错误可以使用如下配置来让vim自动纠错。:abbr Lunix Linux:abbr pn penguin # 当然也可以实现快速输入		第二部分、多文本操作	使用grep，ack，ag来对工程中所有的文件进行搜索		注：我们使用了ctrlp，CtrlSF来进行辅助	在一个终端窗口中进行分割来方便编辑：如:sp，:vs	让VIM和其他工具整合在一起使用：如:sh能进入bash模式等。第三部分、迭代优化自己的编辑器这部分个人觉得是最重要的，很多都认为使用VIM是先背快捷键然后熟练使用VIM，但是实际上和键盘盲打相似，是在使用中慢慢的逐渐提高使用VIM技巧，这里大佬给出了如下3个步骤：Step 1While you are editing, keep an eye out for actions you repeat and/or spend quite a bit of time on.观察自己在哪些步骤进行了很多的重复性输入工作。Step 2Find out if there is an editor command that will do this action quicker. Read the documentation, ask a friend, or look at how others do this.查找文档，询问朋友看有没有能让这些操作变得更快的方案。（去VIM的Wiki或者看我的专栏（笑））或者自己写一个宏或者脚本来自动化这些输入。Step3Train using the command. Do this until your fingers type it without thinking.不断的使用快捷命令，直到你的指头形成肌肉记忆。大佬的建议这里大佬说了一个很有意思的事情，就是希望让我们能养成一个习惯。首先，我们不需要去记住一个编辑器的所有的命令，这是完全浪费时间的 ( a complete waste of time )，每个人只需要知道其中 20% 左右的命令就够用了。其次，不要去优化只用一到两次的操作，把时间花在大量重复的操作上，写一个宏或者去互联网上查看别人的即决方案。最后，也是最重要的，将自己的解决方案和查到的命令记录下来。很多指令，在一段时间内经常使用，我们会熟记于心，但是随着一些原因停止了使用，之后再想回忆起来就需要花更多的时间。简单的来说，就是不做无用功，让我们的每一次努力达到可叠加的效果。最后的话关于为什么使用VIM，大佬给出了如下的话：Learning to drive a car takes effort. Is that a reason to keep driving your bicycle? No, you realize you need to invest time to learn a skill. Text editing isn&#39;t different. You need to learn new commands and turn them into a habit.好的编辑器是值得我们花时间学的，最后感谢大家订阅我的专栏。]]></content>
      <categories>
        
          <category> Vim </category>
        
      </categories>
      <tags>
        
          <tag> Vim </tag>
        
          <tag> 软件使用经验 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[赫拉利三部曲]]></title>
      <url>/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/2018/08/30/%E8%B5%AB%E6%8B%89%E5%88%A9%E4%B8%89%E9%83%A8%E6%9B%B2/</url>
      <content type="text"><![CDATA[							赫拉利三部曲	1、作者简介尤瓦尔·赫拉利是以色列历史学家，出生于1976年，牛津大学历史学博士，耶路撒冷希伯来大学历史系教授，代表作为《人类简史》和《未来简史》。尤瓦尔·赫拉利擅长世界历史和宏观历史进程研究，是学界公认的“青年怪才”。2、主要内容这三步曲中，赫拉利分别讨论了三个话题，人的过去是什么，现在的人处在发展的什么位置，以及人的未来的发展方向是什么样子的。在人类简史中，赫拉利说明我们人类的有三次决定性的“发明”让我们变成现在的样子。第一次是出现了谈论抽象的能力，这使的我们拓展了表达的能力，使人类的合作范围扩大了许多。第二次则是出现了通过想象力来构建一种虚拟的政治秩序，来继续扩大可合作的范围。最终，通过金钱秩序，帝国秩序和信仰秩序这三种秩序，让全球人类进行合作成为了可能。但是这前两种秩序依旧有它的天花板，于是就带来了一种特殊的革命，“科技革命”。在这场革命中，人类首先承认了自己的无知，立根与观察和数学，这种科学是可以运用已有理论取得新能力，即进步是可以叠加的，就好比我们的瓷器曾今是世界最优秀的技术，但是由于仅仅是口口相传，没有留下准确的实验记录导致了烧制瓷器的技术不断的被“再发明”，最终被日本和欧洲超过。而在未来简史中，赫拉利讨论的是我们一直以来促进社会变革的到底是什么？他提出了一个非常惊世骇俗的观点：推动社会变革的不是我们对真实现实的认识，而是我们头脑中虚构的现实，也就是宗教的力量。他认为人文主义也是一种宗教，而如今这种宗教遇到了它的瓶颈。人文三件套，自我不可分割，我有自由意志，我最了解自己。如今分别通过“左右脑实验”，“老鼠实验”，“算法预测”得到了否定。他认为，人文这个宗教触碰到了上限急需变革，而接下来他认为的宗教是“数据教”，算法是数据驱动的，它的宗教三定义则是，价值观为信息要流动。需要遵守的戒律为不断生产和消化信息，最大化自己的信息流。当你遵守了戒律之后得到的许诺是，如果你允许信息自由流动，让万物之网越来越完善，它就能造福每一个人。好了我们知道了赫拉利说的我们未来可能的样子，过去我们是怎么发展的，现在再来说下《今日简史》中我们正在进行什么变革。总体有如下几个：	AI正在蚕食我们的很多岗位，被替代的岗位后，新创造的岗位出现在相对高层级的位置。被替代工作的人很难获得这些新出现的工作，而变成了无用之人。	教育方面，上百年来我们社会的教育都是阶段性的教育模式，现在随着社会的快速变革，我们不得不成为终身学习者已不被淘汰。	自由和平等将会受到前所未有的冲击。自由和平等本身就是一对相互对立的概念，鱼和熊掌不可兼得，你在追求平等的时候自然会有一部分失去自由，当追求自由的时候也必然会导致部分不平等的现象。而这次的技术革命很有可能进一步的撕裂这种不平等，甚至突破生物的边界，即有钱人可以通过技术改造自己，用技术让自己远超普通人。	恐怖主义横行。恐怖主义其实在当今社会造成的伤亡并不多，甚至没有每年车祸去世的人多。但是它造成的恐慌由于互联网的扩大变得具有非常大的恐慌效应。赫拉利做了这样一个比方，恐怖分子就像一只想摧毁瓷器店的苍蝇，但它自身没那么大的力量，于是它就钻进公牛的耳朵里，让公牛发疯，然后冲进瓷器店。	警惕战争。虽然目前的世界和平的原因，赫拉利认为是战争带来的收益已经远远小于战争带来的损耗，所以再次爆发大规模战争的可能性不高，不过凡事有例外。因为宗教的冲突带来的发动战争的动机依旧充分，同时由于武器的进步下一次的战争很可能是毁灭性的，所以我们要谨慎对待他。3、个人理解这三本书读完之后，和隔壁KK的《必然》这本书相比，有一种头皮发麻的感觉，内容甚至更像带着严密推理逻辑的恐怖片。但是个人整体还是乐观的，首先正如赫拉利所说，整个推进的过程是缓慢的，我们在中途是有大量的机会可以调整历史前进的方向。对于三本书中提到的大部分观点我是持赞同的态度，对于《人类简史》，我认同科技革命特殊的原因在于它的可叠加的特性，也认同人类相比其他物种，包括其他人科物种优秀的部分在于能够合作完成个体不能完成的大型工程这种看法。甚至部分赞同，每次革命都会有部分个体陷入更加悲惨的境地这种结论。对于《未来简史》，我也接受人文主义，带有一定的宗教的色彩，是科学和宗教互相作用的结果。也认同我们发展的未来是“数据教”这种方向。但是这种未来真的是一个“危机”么？我是不认同的，首先在三本书中多次提到的，革命之后带来的个体的苦难。这个逻辑看似很合理，像农业革命之后，人的脑容量没有之前采集时期的人类的脑容量大。法老奴役着个体去修建毫无意义的金字塔，现在我们看来这些都是一些少数人奴役集体的暴行。但是这种偏见是否是因为我们站在上帝视角才会这么觉得呢，在当时的历史条件下，这种社会结构完全是一种创举，而且也因为有这种社会结构他们才能在文明的碰撞中幸存下来。而雅典这种超前的民主体制，却因为自身的局限性，（沟通技术手段不够发达）无法扩张，并被罗马取代。也许我们穿越回古代，去询问这些古人，可能他们的幸福指数并不比现代低，因为每个人都有着信仰，有着自己人生的意义。同时，如果一个文明获得了进步，比如获得了人文主义，人类的生活质量得到了提高，你再希望它再退回到之前相对落后的制度中是不会成功的，这是一种必然的规矩，像楚门的世界中，走出了那个精心设计的小天地之后，再想回去就不那么容易了，这是一种不可逆的变化。而我们现在正在经历这种不可逆的变化，即人工智能的发展。历史上，人类的进步均是，朝着能让更多的人进行合作的方向进展的。尤其是互联网的出现，地球上的所有人都能轻易的进行沟通，交流，科技的思想从欧洲开始遍布全球。而人类也开始意识到自身的局限性，好比人对大数不敏感，在很多机械性的劳动中容易出错，人由于生理的原因不能进行24小时连轴的工作等等。这些是可以交给人工智能的，就像当年工业革命一样，人应该做自己擅长的事情，而不是全部都想雨露均沾，我们应该要做减法，而这是趋势。是的，不可否认，它会带来很多负面的事情，很多人失业不得不继续学习，也许会造成更大的贫富差距，造成许多不平等。但是整个过程是缓慢的，当今时代下的我们有充足的时间去学习新的知识，以让我们赶上新的科技发展的浪潮。而对于人工智能替代人类的这件事上，我的看法是，人工智能会成为我们的好帮手，但不会替代我们，至少短期内不会。总结一下，我个人是不太追求绝对的平等或者绝对的自由的，只要社会是像着规范化的发展，不同的阶级间仍保留充足的上升通道，我觉得便是一个非常nice的未来。至于人工智能，物联网Iot等新技术的出现，个人觉得是一种非常棒的未来，机会和风险并存，相比我们的父辈生活在这个时代是非常幸运的。至于特别的危机，就个体而言，我们只需做好自己手头的事情，顺浪潮而行，少一些抱怨和怨天忧人，多一份好奇的探索。]]></content>
      <categories>
        
          <category> 读书笔记 </category>
        
      </categories>
      <tags>
        
          <tag> Reading </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[LaunchBar小插件]]></title>
      <url>/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/2018/08/26/LaunchBar%E5%B0%8F%E6%8F%92%E4%BB%B6/</url>
      <content type="text"><![CDATA[WeChatHelper简介—-WeCharHelper是基于Tkkk-iOSer的WeChatPlugin-MacOS微信插件的LaunchBar第三方插件支持。主要功能有以下两个：  在不打开微信的情况下，通过搜索快速定位到要聊天的对象，并打开相应的聊天窗口  通过搜索快速定位到聊天对象，并发送信息。全程不打开微信窗口。补充说明：支持使用拼音进行汉字的模糊搜索。依赖库—–  python &gt;= 3.6  requests  TKkk-iOSer/WeChatPlugin-MacOS（支持防撤回，微信免扫码认证，微信多开，自动回复）安装指南  HomeBrew安装 在终端中执行如下指令即可：      /usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"        通过HomeBrew安装python3      brew install python3        安装python3的Requests库      pip3 install requests            安装WeChatPlugin-MacOS WeChatPlugin-MacOS的Github地址，这里有详细的下载说明。    下载目录中的WeChatHelper.lbaction，双击即可安装使用说明  呼出WeChatHelper通过LaunchBar搜索WeChatHelper叫出WeChatHelper之后键入空格进入输入模式  发送模式 输入内容格式为“要搜索的微信名/发送的内容”时，下方会出现下拉菜单，选择你要发送的对象发送信息。  打开聊天窗口模式输入内容格式为“要搜索的微信名”，在下拉菜单中选择要打开窗口的对象即可注：由于launchBar的自身原因，在发送内容的时候，以下拉菜单中显示的消息为准，有时会延迟大约2ms左右。]]></content>
      <categories>
        
          <category> 软件使用 </category>
        
      </categories>
      <tags>
        
          <tag> LaunchBar </tag>
        
          <tag> Mac插件开发 </tag>
        
          <tag> python </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[集成学习]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/24/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</url>
      <content type="text"><![CDATA[									集成学习	集成学习一句话版本集成学习的思想是将若干个学习器（分类器&amp;回归器）组合之后产生新的学习器。在学习这一章节中，老师提到了这个说法，我觉得非常言简意赅就直接引用了过来。集成学习算法的成功在于保证若分类器（错误率略小于0.5，即勉强比瞎猜好一点）的多样性，且集成不稳定的算法也能得到一种比较明显的提升。注：深度学习其实也可以看作是一种集成学习集成学习的作用采用集成学习的原因有以下四点：	分类器间存在一定的差异性，这会导致分类的边界不同，也就是说分类器是一个比较专精的专家，它有它自己一定的适用范围和特长。那么通过一定的策略将多个弱分类器合并后，就可以拓展模型的适用范围，减少整体的错误率，实现更好的效果。		注：不严谨的类比的话，就像弹性网络模型就可以看作是由LASSO回归和Ridge回归组成的集成学习。	对于数据集过大或者过小，过大会导致训练一个模型太慢，过小则会导致训练不充分，在这种情况下可以分别对数据集进行划分和有放回的操作产生不同的数据子集，然后使用数据子集训练不同的分类器，最终再将不同的分类器合并成为一个大的分类器。		注：这种方案的优势就在于，提高了准确度和训练速度，使得之前很难利用的数据得到了充分的利用	如果数据的划分边界过于复杂，使用线性模型很难描述情况，那么可以训练多个模型，然后再进行模型的融合。		注：这种特性就好比当初素描老师教我们画圆一样，画一个正方形，再用一堆小直线一点一点切成圆形。	对于多个异构的特征集的时候，很难进行融合，那么可以考虑每个数据集构建一个分类模型，然后将多个模型融合。		注：简单的来说就是公司有两个人都很厉害，但是偏偏不凑巧两个人打架，就不能把他们放一个部门里，得放不同部门一样。集成学习的三种思想BaggingBagging算法思想Bagging，这个名字就是从袋子里取的意思，本身便很形象的说明了这个算法的核心思想，即在原始数据集上通过有放回的抽样的方式，重新选择出S个新数据集来分别训练S个分类器，随后在预测的时候采用多数投票或者求均值的方式来判断预测结果。Bagging适用弱学习器的范围基本的弱学习器都能用，如Linear、Ridge、Lasso、 Logistic、Softmax、ID3、C4.5、CART、SVM、KNN。BoostingBoosting算法思想提升学习（Boosting），这个名字也很形象，在赛车游戏中氮气加速有时候界面就描述是boost，也就是越加越快，每次都比上一次更快，也就是说同Bagging是不一样的，Boosting是会根据其他的弱分类器的结果来更改数据集再喂给下一个弱分类器。准确的描述为，Boosting算法每一步产生弱预测模型(如决策树)，并加权累加到总模型中。它的意义在于如果一个问题存在弱预测模型，那么可以通过提升技术的办法得到一个强预测模型。注1: 如果每一步的弱预测模型的生成都是依据损失函数的梯度方式的，那么就称为梯度提升(Gradient boosting)注2：Boosting这个集成学习的思想就有点深度网络的意思了。Boosting适用范围提升学习适用于回归和分类的问题。Stacking之前提到了Bagging是把训练集拆成不同的子集训练多个学习器投票，而Boosting是根据学习器学习的结果来改动数据集，经过多层改动后试图获得一个更好的预测效果。Bagging和Boosting这两个集成学习其实并没有通过训练结果来改变弱分类器的参数。相对比而言，Stacking就激进许多，当然也复杂和困难许多，它首先训练出多个不同的模型，然后再以之前训练的各个模型的输出作为输入来新训练一个新的模型，换句话说，Stacking算法根据模型的输出是允许改其他分类器的参数甚至结构的，也正是因为这点sklearn中很少有stacking的内置的算法。1、Bagging算法随机森林(Random Forest)随机森林的思路很简单如下：	从样本集中用Bootstrap采样选出n个样本;	从所有属性中随机选择K个属性，选择出最佳分割属性作为节点创建决策树	重复以上两步m次，即建立m棵决策树	这m个决策树形成随机森林，通过投票表决结果决定数据属于那一类注：RF算法在实际应用中具有比较好的特性，应用也比较广泛，主要应用在分类、 回归、特征转换、异常点检测等。RF算法分析RF的主要优点：	训练可以并行化，对于大规模样本的训练具有速度的优势。	由于进行随机选择决策树划分特征列表，这样在样本维度比较高的时候，仍然具有比较高的训练性能。	给以给出各个特征的重要性列表。	由于存在随机抽样，训练出来的模型方差小，泛化能力强;。	RF实现简单。	对于部分特征的缺失不敏感。RF的主要缺点：	在某些噪音比较大的特征上，RF模型容易陷入过拟合。	取值比较多的划分特征对RF的决策会产生更大的影响，从而有可能影响模型的效果。RF的变种Extra TreeExtra Tree是RF的一个相当激进的变种，原理基本和RF一样，区别如下:	RF会随机采样来作为子决策树的训练集，而Extra Tree每个子决策树采用原始数据集训练;	RF在选择划分特征点的时候会和传统决策树一样，会基于信息增益、信息增益率、 基尼系数、均方差等原则来选择最优特征值。而Extra Tree会随机的选择一个特征值来划分决策树。Extra Tree因为是随机选择特征值的划分点，这样会导致决策树的规模一般大于RF所生成的决策树。也就是说Extra Tree模型的方差相对于RF进一步减少。在某些情况下，Extra Tree的泛化能力比RF的强。Totally Random Trees EmbeddingTRTE算法主要进行了两部分操作，第一部分是对数据进行操作，第二部分是对生成的决策树的位置信息转换成向量信息以供之后构建特征编码使用。抛开数据集上的操作，TRTE算法对RF的变种在于如何参考最终生成的多个决策树来给出预测结果。RF是采用投票的方式，而TRTE算法中，每个决策树会生成一个编码来对应叶子结点的位置信息，那么把所有的决策树对应相同的分类的编码合并起来，就可以用这一合并后的编码来代表它的特征了，预测时待预测样本经过这些决策树的预测也会得到这样一个合并后的编码，通过同训练好的类别的编码之间的差距的大小来预测这个样本应该属于哪一个类别。详细的说明说下：	TRTE是一种非监督的数据转化方式。将低维的数据集映射到高维，从而让映射 到高维的数据更好的应用于分类回归模型。	TRTE算法的转换过程类似RF算法的方法，建立T个决策树来拟合数据。当决策树构建完成后，数据集里的每个数据在T个决策树中叶子节点的位置就定下来了， 将位置信息转换为向量就完成了特征转换操作，这个转换过程有点像霍夫曼编码的过程。Isolation Forest这个算法是用来异常点检测的，正如isolation这个名字，是找出非正常的点，而这些非正常的点显然是特征比较明确的，故不需要太多的数据，也不需要太大规模的决策树。它和RF算法有以下几个差别：	在随机采样的过程中，一般只需要少量数据即可。	在进行决策树构建过程中，IForest算法会随机选择一个划分特征，并对划分特征随机选择一个划分阈值。	IForest算法构建的决策树一般深度max_depth是比较小的。算法思路如下：对于异常点的判断，则是将测试样本x拟合到T棵决策树上。计算在每棵树上该样本的叶子节点的深度$h_t(x)$ 。从而计算出平均深度 $h(x) $ 。然后就可以使用下列公式计算样本点x的异常概率值，$p(x,m)$的取值范围为$[0,1]$ ，越接近于1，则是异常点的概率越大。$$p(x,m) = 2^{-\frac{h(x)}{c(m)}}  $$$$c(m) = 2\ln(m-1)+\xi - 2\frac{m-1}{m}\ \ \ \ m为样本个数，\xi为欧拉常数$$注：这个公式可以简单的理解为越是出现在越深的层数，这个事件越不可能发生，足够深的情况基本上就可以判断为不可能发生是异常点2、Boosting算法Adaboost总览Adaboost全名为Adaptive Boosting，每轮迭代中会在训练集上产生一个新的学习器，然后使用该学习器对所有样本进行预测，以评估每个样本的重要性 (Informative)。换句话来讲就是，算法会为每个样本赋予一个权重，每次用训练好的学习器标注/预测各个样本，如果某个样本点被预测的越正确，则将其权重降低，否则提高样本的权重。权重越高的样本在下一个迭代训练中所占的比重就越大，也就是说越难区分的样本在训练过程中会变得越重要。整个算法的迭代的结束条件就是错误率足够小或者达到一定的迭代次数为止。注：整体的过程很像，分豆子，先把我们直接能看出来的区别的豆子分开，留下不太能区分开来的豆子，然后交给母上大人帮忙再分这种感觉。细节描述首先再重新强调下，从线性回归开始的两种思想，第一种是，设计出一个损失函数来代表预测结果，之后根据其应该为极小值和凸函数的特性，求原公式中的参数，一般是用导数等于0这种方式。第二种思想则是，当有多个变量共同作用结果的时候，我们给每个变量前加参数，也就是权值来控制变量的影响结果的能力。这两种贯穿了几乎所有机器学习的思想，当然在Adaboost中也不会例外，整体的步骤分两部分：	每次迭代都为新的弱学习器加权重，并根据损失函数计算得到这个权重。	根据这个新的学习器的预测结果，对每个样本特征的权重进行调整。算法构建之权重系数假设我们打算用的最终分类器为$G(x)$，第m次迭代用的弱分类器为$G_m(x)$，并给分类器前加权重$\alpha_m$已保证分类准的分类器得到足够的重视。于是得到下面公式3.1，公式3.2。$$f(x) = \sum_{m=1}^M \alpha_m G_m(x)\ \ \ 公式3.1 $$$$G(x) = sign(f(x)) = sign[\sum_{m=1}^M \alpha_m G_m(x)]\ \ \ 公式3.2$$有了一个对算法整体的数学表达以后，我们就可以根据它写出AdaBoost的损失函数如下公式3.3：注：到现在为止大家应该对$e^{(-y_i f(x))}$这种公式的函数图不陌生了，就不赘述了$$loss = \frac{1}{n}\sum_{i=1}^n I(G(x_i) \neq y_i) \leq \frac{1}{n}\sum_{i=1}^n e^{(-y_i f(x_i))}\ \ \ 公式3.3 $$有了损失函数了，那么$\alpha$在哪里呢，是要像SVM一样找个算法一起求么，显然不是了，如果那样子的话估计就不是集成算法了，它是一步一步求的，它只关心当前最好结果，类比算法中的贪心算法。于是，我们讨论第k-1轮和第k论迭代的关系：$$f_{k-1}(x) = \ sum_{j=1}^{k-1}\alpha_j G_j(x) \ \ \ 第k-1轮的函数  $$$$f_k(x) = \sum_{j=1}^k \alpha_j G_j(x) = f_{k-1}(x) + \alpha_k G_k(x) \ \ \ 第k轮函数$$根据loss函数的构成方法，我们很容易写出第k轮含有$\alpha_k$的公式如下公式3.4，之后对其进行求导就可以得到$\alpha_k$的公式3.5：$$loss(\alpha_k,G_k(x)) = \frac{1}{n} \sum_{i=1}^n e^{(-y_i(f_{m-1}(x)+\alpha_k G_k(x)))} \ \ \ 公式3.4$$$$\begin{split}&\alpha_k^* = \frac{1}{x}\ln(\frac{1-\varepsilon_k}{\varepsilon_k})\ \ \ 公式3.5 \\&\overline w_{ki} = e^{(-y_i f_{k-1}(x))} \\&\varepsilon_k = \frac{1}{n}\sum_{i=1}^n \overline w_{ki}I(y_i \neq G_m(x_i))\end{split}$$于是至此，我们就将弱分类器简单的连接在一起了，做好了下一步对数据样本特征值的权重调整的准备。算法构建之样本特征权重调整首先我们设定第k轮的数据集的权重分布为$D_k = (w_{k,1}, w_{k,2},... ,w_{k,n},)$。同时每次的$D_k$都是由$D_{k-1}$通过某种规律计算得到的，这种计算公式如下公式3.6：$$\begin{split} &w_k = \frac{w_{k-1,i}}{Z_{k-1}}e^{-\alpha_{k-1}y_i G_{k-1}(x_i)}\ \ \ 公式3.6 \\&Z_k = \sum_{i=1}^n w_{k,i}e^{-\alpha_k y_i G_k(x_i)} \end{split}$$可以看到这种第k次迭代开始前的数据的权重的调整是在根据第k-1次迭代中预测结果来进行调整的，换句话说，第k次迭代的数据集被第k-1次的训练修正了。算法构建之总览我们现在知道了每个弱分类器的权值是怎么够建的，也知道了Boosting算法中调整数据的部分是怎么调整的，算法的零件已经齐全，现在拼接起来如下：	初始化数据集权重为$\frac{1}{n}$，n为特征的个数。	加入弱分类器，并根据数据集feed进模型确定这个新加入的弱分类的权重。	根据最终训练的结果，调整数据集中不同特征的权值	重复2，3步骤直到符合结束条件，一般为达到预计准确度，或者为达到规定迭代次数。Gradient Boosting首先值得注意的是，GBDT算法，它有很多别名如GBT，GTB，BGRT，GBDT，MART，初学者很容易把它们当作是多个算法，比如我（笑。言归正传GBDT全名为Gradient Boosting Decision Tree。它也是Boosting算法的一种，它的算法推导相比之前算法的较为复杂，详细公式推导参考这篇文章，这里就不赘述了。算法大体的步骤如下：	算法每次迭代生成一颗新的决策树 		注：GBDT的核心其实是找出一堆决策树，然后让他们的结果累加得到最终的预测值	在每次迭代开始之前，计算损失函数在每个训练样本点的一阶导数和二阶导数	通过贪心策略生成新的决策树，通过等式计算每个叶节点对应的预测值		注：这步是通过目标函数求导得到的，需要利用第二步中的二阶导数和一阶导数，同时等式的推导中用到了泰勒公式	把新生成的决策树 $f_t(x) $ 添加到模型中：$\widehat{y}_i^{t} = \widehat{y}_i^{t-1}+f_t(x_i)$		注：这里我们会将模型替换为$\widehat{y}_i^{t} = \widehat{y}_i^{t-1}+\xi f_t(x_i)$，这里的$\xi$ 称之为步长或者学习率。增加ϵ因子的目的是为了避免模型过拟合。*		GBDT总结GBDT优点如下：	可以处理连续值和离散值	在相对少的调参情况下，模型的预测效果也会不错	模型的鲁棒性比较强。缺点如下：	由于弱学习器之间存在关联关系，难以并行训练模型Bagging和Boosting的总结	样本选择：					Bagging算法是有放回的随机采样			Boosting算法是每一轮训练集不变，只是训练集中的每个样例在分类器中的权重发生变化，而权重根据上一轮的分类结果进行调整			样例权重：					Bagging使用随机抽样，样例的权重			Boosting根据错误率不断的调整样例的权重值， 错误率越大则权重越大			预测函数：					Bagging所有预测模型的权重相等			Boosting算法对于误差小的分类器具有更大的权重			并行计算：					Bagging算法可以并行生成各个基模型			Boosting理论上只能顺序生产，因为后一个模型需要前一个模型的结果			Bagging是减少模型的variance(方差)，Boosting是减少模型的Bias(偏度)。	Bagging里每个分类模型都是强分类器，因为降低的是方差，方差过高需要降低是过拟合。Boosting里每个分类模型都是弱分类器，因为降低的是偏度，偏度过高是欠拟合。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[贝叶斯算法]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/19/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/</url>
      <content type="text"><![CDATA[									贝叶斯算法	知识前置这个章节的机器学习，其实更像是一种概率论的学习，同时这也是机器学习和数据分析中非常重要的一环。如果学习遇到了困难非常推荐参考张宇考研概率论部分的内容。同时这一章的算法，也是在文本分类中使用的比较多的。名词解释：	先验概率：$P(A)$	条件概率：$P(A|B)$	后验概率：$P(B|A)$	全概率：$P(B) = \sum_{i=1}^n P(A_i)*P(B|A_i)$	贝叶斯公式：$P(A|B) = \frac{P(A)*P(B|A)}{\sum_{i=1}^n P(B|A_i)*P(A_i)}$概率分布：	高斯分布：简单的来说它的分布呈现的是正态分布的样子。参考链接	伯努利分布：伯努利分布是0-1分布，简单的来说就是那种仍硬币的概率分布。参考链接	多项式分布：是伯努利分布的推广，不再是只有两种情况，有多种情况的概率分布。参考链接贝叶斯核心思想：找出在特征出现时，各个标签出现的概率，选择概率最大的作为其分类。朴素贝叶斯我们来“望文生义”的理解这个算法，贝叶斯指的就是上面的贝叶斯公式，而朴素则指的是“特征之间是独立的”这个朴素假设。假设有给定样本X，其特征向量为$(x_1,x_2,...,x_m)$，同时类别为$y$。算法中使用公式2.1表达在当前特征下将类别y预测正确的概率。由于特征属性之间是假定独立的，所以$P(x_1,x_2,...x_m)$是可以直接拆开的，故根据这个特性优化，得到公式2.2。由于样本给定的情况下，$P(x_1,x_2,...,x_m)$的值不变，故研究概率最大的问题只需要研究公式2.2等号右侧上面的部分，最终写出预测函数公式2.3。$$P(y|x_1,x_2,...,x_m) = \frac{P(y)P(x_1,x_2,...,x_m|y)}{P(x_1,x_2,...,x_m)}\ \ \ 公式2.1  $$$$P(y|x_1,x_2,...,x_m) = \frac{P(y)\prod_{i=1}^m P(x_i|y)}{P(x_1,x_2,...,x_m)}\ \ \ 公式2.2$$$$\hat{y} = arg\ max_y P(y) \prod_{i=1}^m P(x_i|y) \ \ \ 公式2.3$$到这里，算法的流程就很显而易见了，和softmax算法类似，让预测正确的概率最大即可，具体计算流程如下：设$x = {a_1,a_2,...a_m}$为带分类项，其中a为x的一个特征属性，类别集合$C={y_1,y_2,...y_n}$	分别计算所有的$P(y_i|x)$，使用上述公式2.3	选择$P(y_i|x)$最大的$y_i$作为x的类型其他朴素贝叶斯高斯朴素贝叶斯在上述贝叶斯算法中的特征是离散的，那么考虑特征属虚连续值时，且分布服从高斯分布的情况下。用高斯公式（公式3.1）代替原来计算概率的公式。那么根据训练集中，对应的类别下的属性的均值和标准差，对比待分类数据中的特征项划分的各个均值和标准差，即可得到预测类型。$$p(x_k|y_k) = g(x_k,\eta_{y_k},\sigma_{y_k}) = \frac{1}{\sqrt{2 \pi}\sigma}e^{-\frac{(x-\eta_{y_k})^2}{2\sigma_{y_k}^2}}\ \ \ 公式3.1$$伯努利朴素贝叶斯特征值的取值是布尔型的，是有true和false，符合伯努利分布，那么其$P（x_i|y_k）$的表达式如下公式3.3。$$P（x_i|y_k）= P(x_i = 1 | y_k)*x_i + (1-P(x_i=1|y_k))(1-x_k)\ \ \ 公式3.2$$注：这意味着没有某个特征也可以是一个特征，其中公式3.2其实是把两个不同条件的概率公式融合在一起了，这种方法也在逻辑回归中使用过多项式朴素贝叶斯特征属性分布服从多项分布时，得到如下公式3.3，公式的来源简单的来说就是已知盒子中红球和所有球的总个数，求从盒中摸到红球的概率差不多。其中$N_{y_k x_i} $为类别$y_k$下，特征$x_i$出现的次数，$N_{y_k}$ 指的是类别 $y_k$ 下，所有特征出现的次数。$$P(x_i|y_k) = \frac{N_{y_k x_i} + \alpha}{N_{y_k} + \alpha n}  $$注：待预测样本中的特征xi在训练时可能没有出现，如果没有出现，则$N_{y_k x_i} $ 值为0，如果直接拿来计算该样本属于某个分类的概率，结果都将是0。所以在分子中加入α，在分母中加入αn可以解决这个问题。贝叶斯网络由于之前朴素贝叶斯，前提条件是假定特征值之间没有关系，这显然是不现实的而贝叶斯网络正是解决这个问题的。其关键方法是图模型，我们构建一个图模型，把具有因果联系的各个变量联系在一起。贝叶斯网络的有向无换图中的节点表示随机变量，连接节点的箭头表示因果关系。简单的来说贝叶斯网络就是模拟人的认知思维推理模式的，用一组条件概率以及有向无换图对不确定关系推理关系建模。而这种方式在深度学习之前是很受欢迎的，它和之后的隐马尔可夫被使用作为提取特征的工具，而现在渐渐的过度到了深度学习。贝叶斯网络工作原理首先贝叶斯网络的实质就是建立一个有向无环图，其中方向代表因果关系。仔细思考一下，为什么是有向无环图，是因为如果是有环的话，就会有节点是自己依赖于自己，显然这样是有问题的。具体贝叶斯工作的核心原理可以理解为，根据人已知的经验或者其他手段，规定一些完全没有依赖于其他事件的事件发生的概率，随后根据制作的贝叶斯网络（因果关系图）推算出不同事件发生的概率。这个过程有点像是在做一个概率论的期末考试题，已知A，B，C的概率和ABCD之间转换的关系，问在发生了BC条件下，发生D的概率。大体就是这样一种感觉。事例如下图：其中$x_1,x_2,x_3$独立，则$x_6,x_7$独立，$x_1,x_2,x_3,...,x_7$的联合概率分布如下：$$p(x_1,x_2,...,x_7) = p(x_1)p(x_2)p(x_3)p(x_4|x_1,x_2,x_3)p(x_5|x_1,x_3)p(x_6|x_4)p(x_7|x_4,X_5)$$实际上这部分的概率计算，其实就是根据初始条件和转移方式，求的目标的概率这样的过程。和之前常用的最大似然估计算法对比，贝叶斯的这一系列算法考虑了先验概率，而最大似然估计算法没有，在最大似然估计算法中其实相当于默认了先验概率是相同的。注：最大后验概率MAP其实可以看作是贝叶斯算法和最大似然估计算法结合的应用]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[聚类算法（下）]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/19/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E4%B8%8B/</url>
      <content type="text"><![CDATA[							聚类算法（下）	聚类算法上中讲了大名鼎鼎的K-Means算法及其优化变种，在这篇中几种讲述两位两种不同思路的聚类算法。层聚类算法传统层聚类算法—AGNES和DIANA算法层次聚类和K-Means的思路不太一样，它的思路有点像是决策树，按照层次进行分解，知道满足某种条件为止，传统的层次聚类分为自底而上，和自上而下两类：	凝聚的层次聚类:		这类算法是采用采用自底向上的策略，其中的代表便是AGNES算法(AGglomerative Nesting)，它的核心思想是：最初将每个对象作为一个簇，然后这些簇根据某些准则被一步一步合并，两个簇间的距离可以由这两个不同簇中距离最近的数据点的相似度来确定。聚类的合并过程反复进行直到所有的对象满足簇数目。	分裂的层次聚类：		和凝聚的层次聚类相反，这种是采用自顶向下的策略，代表算法为DIANA算法(DIvisive Analysis)。其核心思想是：首先将所有对象置于一个簇中，然后按照某种既定的规则逐渐细分为越来越小的簇(比如最大的欧式 距离)，直到达到某个终结条件(簇数目或者簇距离达到阈值)。在AGNES算法中都提到了，簇是根据某些原则进行分裂或者合并的，而这个原则就是簇间距离。计算簇间距离的方法有最小距离（SL聚类），最大距离（CL聚类）以及平均距离（AL聚类），具体的说明如下：	最小距离（SL聚类）		选择两个聚簇中最近的两个样本之间的距离（Single/Word-Linkage）		注：得到的模型容易形成链式结构	最大距离（CL聚类）		选择两个聚簇中最圆的两个眼本的距离（Complete-Linkage）		注：如果出现了异常值的话，那他们的构建很容易受这个异常值的影响。	平均距离（AL聚类）		选择两个聚类中的平均值（Average-Linkage聚类算法）或者中值（Median-Linkage聚类法）AGNES和DIANA算法优缺点如下：	简单，理解容易。	合并点/分裂点选择不太容易。	合并/分类的操作不能进行撤销。	由于执行效率较低$O(t*n^2)$，$t$为迭代次数，$n$为样本点数。层次聚类优化算法之前我们看到了传统的层次聚类算法，由于其执行效率太低，且不能动构建的的特点，显然不适合大数据集。于是我们在此基础上引入了BIRCH算法和CURE算法。BIRCH算法BIRCH (balanced iterative reducing and clustering using hierarchies) 算法，英文的全称翻译过来以后是平衡迭代削减聚类算法，其构成和我们考研数据结构中学过的B+树非常的类似，甚至很多特性都是相同的，具体的说它构建的树叫做CF（Cluster Feature）-Tree。	节点，即簇的结构：		既然是树，那么就不得不提它的节点的结构了。在BIRCH构建CF树的过程中，每个节点等于说是存放了它之下所有节点的特征，于是他在节点中存放了如下的三部分数据。					N，指在这个节点中有多少个样本点。			LS，指的是这个节点中的样本相应特征的和。			LS，指的是这个节点中的样本相应特征的特征的平方和。			节点之间，节点和子节点，以及叶子结点之间的关系		节点和其子节点是包含的关系，也就是父节点中的N，LS以及SS是其所有子节点的和。而相应的样本点的具体信息指包含在底层节点中（叶子结点的子节点），同时叶子结点构成一个单项链表，同时有一个指针指向其表头。这点的特性是同B+树高度一致的。	最多子女个数，以及分裂判定		和B+树一样，对于树构建中的分叉个数是有限制的，这个限制需要提前给出，即分支因子。同时，值得注意的是，一般而言在构建节点簇的中心点的时候，一般选用第一个进入这个节点的样本点作为中心点，然后根据指定的该簇和中心点限定的距离，即类直径，其往往通过LS和SS算出。判断新入的点是否可以划入该簇，而分裂节点的时候，往往以这个初始点进行分割。综上我们可以看出，BIRCH算法的本质其实就是动态的插入样本点，然后动态的根据规则构建一个类B+树。它的优点是动态建树且效率高是线性效率，即每个样本点都是一次性插入的，同时也节省内存，所以非常适合大数据集。不过遗憾的是它也是采用距离作为分类标准，故只适合分布呈凸形或者球形的数据集、且需要给定聚类个数和簇之间的相关参数，而这些对节点CF的限制可能导致簇类结果和真实不太一致。注1：BIRCH不依赖给定的待分类簇数量K，但是给定了K值最好，若不一定K值，最终CF-Tree的叶子结点树木就是最终分类的簇的数目。注2:BIRCH算法在训练大规模数据集的时候，和mini-batch K-Means相比，BIRCH算法更加适合类别数量K比较多的情况。注3：由于类直径是通过LS和SS算出的，所以当特征维度超过20～30左右的时候，不建议使用该算法。CURE算法（使用代表点的聚类法）CURE（Clustering Using REpresentatives），该算法先把每个数据点看成一类，然后合并距离最近的类直至类个数为所要求的个数为止。但是和AGNES算法的区别是：取消了使用所有点，或用中心点+距离来表示一个类，而是从每个类中抽取固定数量、 分布较好的点作为此类的代表点，并将这些代表点乘以一个适当的收缩因子，使它们更加靠近类中心点。代表点的收缩特性可以调整模型可以匹配那些非球形的场景，而且收缩因子的使用可以减少噪音对聚类的影响。CURE算法的优点是能够处理非球形分布的应用场景，同时彩娱乐随机抽样和分区的方式可以提高算法的执行效率。密度聚类算法密度聚类方法的指导思想是：只要样本点的密度大于某个阀值，则将该样本添加到最近的簇中。这类算法可以克服基于距离的算法只能发现凸聚类的缺点，可以发现任意形状的聚类，而且对噪声数据不敏感。不过这种计算的复杂度高，计算量大。密度聚类算法的常用算法有DBSCAN和密度最大值算法。DBSCAN算法DBSCAN（Density-Based Spatial Clustering of Applications with Noise），将簇定义为密度相连的点的最大集合，能够将足够高密度的区域划分为簇，并且在具有噪声的空间数据上能够发现任意形状的簇。其核心思路是用一个点的ε邻域内的邻居点数衡量该点所在空间的密度，该算法可以找出形状不规则的cluster，而且聚类的时候事先不需要给定cluster的数量。DBSCAN算法流程它的算法流程如下：	如果一个点$x$的$\varepsilon$领域内包含m个对象，则创建一个x作为核心对象的新簇。	寻找并合并核心对象直接密度可达的对象	没有新点可以更新簇的时候，算法结束注：1. 每个簇至少包含一个核心对象；2. 非核心对象可以是簇的一部分，构成簇的边缘；3. 包含过少对象的簇被认为是噪声；4. 最大的密度相连对象的集合C为密度聚类中的一个簇，它满足两个属性，Maximality和Connectivity，Maximality指的是若$x$属于C，$y$从$x$密度可达，那么$y$也属于C，Connectivity指的是，若$x$和$y$都属于C，那么$x$和$y$是密度相连的。DBSCAN相关名词解释其中提到的定义有$\varepsilon$领域，密度，MinPts，核心点，边界点，噪音点，直接密度可达，密度可达，密度相连。他们的解释如下：	$\varepsilon$邻域($\varepsilon$ neighborhood）：给定对象在半径$\varepsilon$的区域。	密度(density)：在$\varepsilon$领域中的$x$的密度，是一个整数依赖于半径$\varepsilon$，$N_{\varepsilon}(X) $指的是半径内的点的个数。		$$		p(x) = |N_{\varepsilon}(X)|  		$$	MinPts：指得是判定该点是不是核心点的时候使用的阀值，记为M	核心点（core point）：如果$p(x) \geq M$ ,那么称$x$为$X$的核心点，记由$X$中所有核心点构成的集合为$X_c$，并记$X_nc$ 表示由$X$中所有非核心点构成的集合。通俗的来说， 核心点是密度达到一定阀值的的点。	边界点（border point）：如果非核心点$x$的$\varepsilon$邻域中存在核心点，那么认为$x$为$X$的边界点。通俗来讲就是密度特别稠密的边缘地带，也就是簇的边缘部分。	噪音点（noise point）：集合中除了边界点和核心点之外的点都是噪音点，所有噪音点组成的集合叫做$X_noi$，显然这些点就是对应稀疏区域的点。	直接密度可达：这个是密度聚类中最重要的概念，它指的是给定一个对象集合 $X$，如果$y$是在$x$的$\varepsilon$邻域内，而且$x$是一个核心对象，可以说对象y从对象$x$出发是直接密度可达的	密度可达：如果存在一个对象链$p_1, p_2,...,p_m $ ，如果满足$p_{i+1}$是从$p_i$直接密度可达的，那么称$p_m$是从$p1$密度可达的，简单的来说就像铁链环环相扣差不多。	密度相连：在集合$X$中，如果存在一个对象$o$，使得对象$x$和$y$是从$o$关于$\varepsilon$和$m$密度可达的，那么对象$x$和$y$是关于$\varepsilon$和$m$密度相连的。DBSCAN算法优缺点优点: 	不需要事先给定cluster的数目	可以发现任意形状的cluster	能够找出数据中的噪音，且对噪音不敏感 	算法只需要两个输入参数 	聚类结果几乎不依赖节点的遍历顺序缺点:	DBSCAN算法聚类效果依赖距离公式的选取，最常用的距离公式为欧几里得距离。但是对于高维数据，由于维数太多，距离的度量已变得不是那么重要	DBSCAN算法不适合数据集中密度差异很小的情况MDCA密度最大值聚类算法MDCA(Maximum Density Clustering Application)算法基于密度的思想引入划分聚类中，能够自动确定簇数量并发现任意形状的簇。另外MDCA一般不保留噪声，因此也避免了阈值选择不当情况下造成的对象丢弃情况。注：MDCA的算法和AGNES非常相像，不同的是最初的初始簇确定是通过密度来确定的。MDCA算法思路MDCA算法核心一共分三步，划分、合并簇以及处理剩余节点三部分。	将数据集划分为基本簇：					对数据集X选取最大密度点$P_{max}$ ，形成以最大密度点为核心的新簇$C_i$，按照距离排序计算出序列$S_{p_max}$,对序列的前M个样本数据进行循环判断，如果节点的密度大于等于$density_0$ ，那么将当前节点添加$C_i$中。			循环处理剩下的数据集X，选择最大密度点$P_{max}$，并构建基本簇$C_{i+1}$，直到X中剩余的样本数据的密度均小于$deansity_0$。			使用凝聚层次聚类的思想，合并较近的基本簇，得到最终的簇划分：					在所有簇中选择距离最近的两个簇进行合并，合并要求是：簇间距小于等于$dist_0$，如果所有簇中没有簇间距小于$dist_0$的时候，结束合并操作			处理剩余节点，归入最近的簇					最常用、最简单的方式是：将剩余样本对象归入到最近的簇。		MDCA算法名词解释最大密度点：如字面意思，就是密度最大的点，密度计算公式一般取DBSCAN算法中的密度计算公式。有序序列$S_{p_{max}}$：根据所有对象与最大密度点的距离进行排序。密度阈值$density_0$：当节点的密度值大于密度阈值的时候，认为该节点属于一个 比较固定的簇，在第一次构建基本簇的时候，就将这些节点添加到对应簇中，如果小于这个值的时候，暂时认为该节点为噪声节点。簇间距离：对于两个簇C1和C2之间的距离，采用两个簇中最近两个节点之间的距离作为簇间距离。M值：初始簇中最多数据样本个数]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[聚类算法（上）]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/19/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-%E4%B8%8A/</url>
      <content type="text"><![CDATA[							聚类算法（上）	聚类算法很多，所以和讲回归算法一样，分成了上下，上中主要讲了传统的K-Means算法以及其相应的优化算法入K-Means++，K-Means||和Canopy等。下中主要讲了另外两种的思路的聚类算法，即层次聚类和密度聚类。什么是聚类聚类算就是怼大量未知标注的数据集，按照数据内部存在的数据特征将数据集划分为多个不同的类别，使类别内的数据比较相似，类别之间的数据相似度比较小，属于无监督学习。从定义就可以看出，聚类算法的关键在于计算样本之间的相似度，也称为样本间的距离。相似度/距离计算公式说到聚类算法，那肯定核心就是计算距离的公式了，目前常用的有以下几种。闵可夫斯基距离（Minkowski）：公式2.1	当p为1的时候是曼哈顿距离（Manhattan）：公式2.2	当p为2的时候是欧式距离（Euclidean）：公式2.3					标准化欧式距离：				这个距离的计算方式如同其字面意思，标准化欧式距离就是对欧式距离的标准化。标准化的正常定义为，$X^* = \frac{X - \overline X}{s}$，这个$s$指的就是方差，而方差的计算公式为$s = \sqrt{\frac{\sum_{i=1}^n(x_i - \overline X)^2}{n}}$，所以其标准化公式如下公式2.5。			当p为无穷大的以后是切比雪夫距离（Chebyshev）：公式2.4$$dist(X,Y)= \sqrt[p]{\sum_{i=1}^{n} |x_i - y_i|^p}\ \ \ 公式2.1$$$$M\_dist=\sum_{i=1}^n|x_i-y_i| \ \ \ 公式2.2$$$$E\_dist = \sqrt{\sum_{i=1}^n|x_i-y_i|^2} \ \ \ 公式2.3$$$$C\_dist = max_i(|x_i-y_i|)\ \ \ 公式2.4$$$$S\_E\_D = \sqrt{\sum_{i=1}^n(\frac{x_i-y_i}{s_i})^2}\ \ \ 公式2.5 $$夹角余弦相似度（Cosine）：使用这个公式的时候，需要注意的是，这里的相似之的是同一个方向上的，而同一个方向上的两个点可能距离是非常远的。比如一个吻张灏总分别出现单词A 10次，单词B 20次，另一个文章中出现单词A 100次，单词B 200次，这时候如果使用欧几里得距离的话，这两个文章是不相似的，然而显然这两个单词的比例相似很能说明这两个文章其实是有关系的，所以在文章的相似度的判别中使用夹角余弦相似度比较合适，公式如下2.6。个人理解为，其是从距离以外的衡量相似度的另一个维度的指标。$$\cos(\theta)  = \frac{\sum_{k=1}^n x_{1k}x_{2k}}{\sqrt{\sum_{k=1}^n x_{1k}^2} * \sqrt{\sum_{k=1}^n x_{2k}^2}} = \frac{a^T · b}{|a||b|}\ \ \ 公式2.6$$KL距离（相对熵）：思考下条件熵的定义，简单的来说就是在放生一件事情的时候，发生另一件事的概率。公式如下公式2.7.注：这里书的概率不是实指概率，而是熵表达的含义。这个公式其实就是条件熵的公式。$$D(P|Q)=\sum_x P(x)\log(\frac{P(x)}{Q(x)})\ \ \ 公式2.7$$杰卡德相似系数(Jaccard)：这个很好理解，它的核心就是使用两个集合的交集和并集的比率来代表两者的相似度，也就是说重合的越多越相似。公式如下，公式2.8.$$J(A,B) = \frac{|A\bigcap B|}{|A \bigcup B|}  $$$$dist(A,B) = 1-J(A,B) \ \ \ 公式2.8 $$Pearson相关系数：这个就是考研数学中的相关系数，表达就是两者之间的想关系，所以直接拿来用就好了，公式如下公式2.9。$$\rho_{XY} = \frac{Cov(X,Y)}{\sqrt{D(X)} \sqrt{D(Y)}} = \frac{E[(X-E(X))(Y-E(Y))]}{\sqrt{D(X)}\sqrt{D(Y)}} = \frac{\sum_{i=1}^n(X_i - \mu_x)(Y_i - \mu_Y)}{\sqrt{\sum_{i=1}^n(X_i - \mu_X)^2}*\sqrt{\sum_{i=1}^n(Y_i - \mu_Y)^2}}  $$$$dist(X,Y) = 1 - \rho_{XY}\ \ \ 公式2.9$$聚类的思想给定一个有M个对象的数据集，构建一个具有k个簇的模型，其中k&lt;=M。满足 以下条件:	每个簇至少包含一个对象	每个对象属于且仅属于一个簇 	将满足上述条件的k个簇成为一个合理的聚类划分基本思想:对于给定的类别数目k，首先给定初始划分，通过迭代改变样本和簇的隶属关系，使的每次处理后得到的划分方式比上一次的好，即总的数据集之间的距离和变小了K-Means 系列K-Means算法K-means的核心算法如下：# 假设输入样本T为x1,x2,x3,...,xm初始化k个类别的中心点a1,a2,a3,...,akwhile not EndCondition :	1.根据每个样本和中心点的欧几里得距离，选择最近的中心点作为自己的类别	2.更新每个类别的中心点aj，为隶属该类别的所有的样本的均值# EndCondition有迭代次数，最小平方误差MSE，簇中心点变化率。再循环中的第二步，我们移动了中心点的位置，把中心点移到了隶属于该中心点类别的所有样本的中间，并使用样本的均值作为位置。这样子看似是拍脑袋想的移动策略，其实是可以推导出来的。正如聚类算法思想所指出的，我们要让所有的点到自己的分类的中心点的欧几里得距离最小，所以我们设置目标放称为公式4.1，公式中的1/2是为了之后求导运算方便。我们为了让目标函数尽可能的小，所以使用了之前一直在使用的思考方式，对其使用梯度下降算法，求导后得到公式4.2，之后令其等于0，就得到了公式4.3。$$J(a_1,a_2,a_3,...,a_k) = \frac{1}{2}\sum_{j=1}^K \sum_{i=1}^n (x_i - a_j)^2 \ \ \ 公式4.1$$$$\frac{\partial J}{\partial a_j} = \sum_{i=1}^{N_j}(x_i-a_j)\ \ \ 公式4.2$$$$a_j = \frac{1}{N}\sum_{i=1}^{N_j} x_i \ \ \ 公式4.3 $$最后这个看似不错的算法，其实有着不小的缺点，那就是初值敏感。我们来仔细想一想，如果两个不小心随机生成的初值落到了一个类别中，两者的距离还特别近，这中情况下就很难正确分类了。除此之外，由于移动策略中使用的是均值，也就是说如果集合中含有非常大的误差点的话，这样子会是中心点的设置偏离正确点很远，所以很多时候我们改用中值来更新中心点，这就是我们说的K-Mediods聚类，即K中值聚类。总结下K-means算法优点：	理解容易，聚类效果不错	处理大数据集的时候，该算法可以保证较好的伸缩性和高效率	当簇近似高斯分布的时候，效果非常不错缺点：	 K值是用户给定的，在进行数据处理前，K值是未知的，不同的K值得到的结果也不一样	对初始簇中心点是敏感的 	不适合发现非凸形状的簇或者大小差别较大的簇 	特殊值(离群值)对模型的影响比较大二分K-Means算法由于K-Means对初始中心点非常敏感，我们这里就尝试着通过二分法弱化初始中心点。这种算法的具体步骤如下：# 把所有样本数据作为一个簇放到队列中while not EndCondition:	1.从队列中选择一个簇，使用K-means划分为两个簇	2.将划分好的两个簇放回队列# EndCondition 为簇的数量，最小平方误差，迭代次数等# 选择簇的手段有两种1.使用SSE 2.选择数据量最多的簇我们在这个算法中提到了SSE，这个可以是簇内所有样本点，到其中心点的距离的总和，代表着簇内的点是不是高度相关。计算公式如下公式4.4。$$SSE = \sum_{i=1}^n w_i(y_i - \hat y_i)^2\ \ \ 公式4.4$$可以看出在这种算法下，很好的避开了，两个中心点都在一起的情况。K-Means++和K-Means||K-Means++做的改善，是直接对初始点的生成位置的选择进行优化的，他的初始点生成策略如下：	从数据集中任选一个节点作为第一个聚类中心	对数据集中的每个点x，计算x到所有已有聚类中心点的距离和D(X)，基于D(X)采用线性概 率选择出下一个聚类中心点(距离较远的一个点成为新增的一个聚类中心点)	重复步骤2直到找到k个聚类中心点可以看出，K-Means++企图生成相聚距离较远的几个中心点。但是缺点也是显而易见的，由于聚类中心点选择过程中的内在有序性，在扩展方面存在着性能方面的问题，即第k个聚类中心点的选择依赖前k-1个聚类中心点的值。而K-Means||就是针对K-Means++缺点作出了的优化，主要思路是改变每次遍历时候的取样规则，并非按照K-Means++算法每次遍历只获取一个样本，而是每次获取 K个样本，重复该取样操作$O(\log{n}w	z)$ 次，然后再将这些抽样出来的样本聚类出K个点，最后使用这K个点作为K-Means算法的初始聚簇中心点。注：一般5次重复采用就可以保证一个比较好的聚簇中心点。Canopy算法Canopy属于一种“粗略地”聚类算法，简单的来说就是，不那么追求自动获得最优解，而是引入了一种人为规定的先验值进行聚类，具体步骤如下：# 给定样本列表L=x1,x,2...,xm以及先验值r1和r2(r1 &gt; r2)for P in L:	计算P到所有聚簇中心点的距离(如果不存在聚簇中心，那么此时点P形成一个新的聚簇)，并选择出最小距离D(P,aj)	if D &lt; r1:		# 表示该节点属于该聚簇		添加到该聚簇列表中	if D &lt; r2:		# 表示该节点不仅仅属于该聚簇，还表示和当前聚簇中心点非常近，		将该聚簇的中心点设置为P，并将P从列表L中删除	if D &gt; r1:		节点P形成一个新的聚簇	if EndCondition:		# 结束条件为直到列表L中的元素数据不再有变化或者元素数量为0的时候		break		注：Canopy算法得到的最终结果的值，聚簇之间是可能存在重叠的，但是不会存在 某个对象不属于任何聚簇的情况显然，这种算法虽然快，但是很难生成满足我们应用的模型，所以通常我们将它作为解决K-Means初值敏感的方案，他们合在一起就是Canopy+K-Means算法。顺序就是先使用Canopy算法获得K个聚类中心，然后用这K个聚类中心作为K-Means算法。这样子就很好的解决了K-Means初值敏感的问题。Mini Batch K-Means算法Mini Batch K-Means算法是K-Means算法的一种优化变种，采用小规模的数据子集，来减少计算时间。其中采用小规模的数据子集指的是每次训练使用的数据集是在训练算法的时候随机抽取的数据子集。Mini Batch K-Means算法可以减少K-Means算法的收敛时间，而且产生的结果效果只是略差于标准K-Means算法。它的算法步骤如下：# 首先抽取部分数据集，使用K-Means算法构建出K个聚簇点的模型while not EndCondition:	1.抽取训练数据集中的部分数据集样本数据，并将其添加到模型中，分配给距离最近的聚簇中心点	2.更新聚簇的中心点值# EndCondtion同K-Means一样，可以理解为不停的进行K-Means算法。聚类算法衡量标准聚类算法的衡量标准有很多，包括均一性、完整性、V-measure、调整兰德系数（ARI ，Adjusted Rnd Index）、调整互信息(AMI，Adjusted Mutual Information)以及轮廓系数等等。均一性、完整性以及V-measure均一性：一个簇中只包含一个类别的样本，则满足均一性。其实也可以认为就是正确率，即每个聚簇中正确分类的样本数占该聚簇总样本数的比例和。其公式如下公式5.1。$$p = \frac{1}{k}\sum_{i=1}^k \frac{N(C_i == K_i)}{N(K_i)}\ \ \ 公式5.1  $$完整性：同类别样本被归类到相同簇中，则满足完整性。每个聚簇中正确分类的样本数占该类型的总样本数比例的和，通俗的来说就是，我们已分类类别中，分类正确的个数。其公式如下，公式5.2：$$r = \frac{1}{k}\sum_{i=1}^k \frac{N(C_i == K_i)}{N(C_i)}\ \ \ 公式5.2 $$在实际的情况中，均一性和完整性是往往不能兼得的，就好像抓特务时的矛盾一样，到底是保证每个抓的人都是特务，还是宁可错抓也不放过一个特务，之间的取舍很难把握。所以再一次贯彻，鱼和熊掌不可兼得，我们就加权，于是得到的就是V-measure，其公式如下公式5.3：$$V_\beta = \frac{(1+\beta^2)·pr}{\beta^2·p + r}\ \ \ 公式5.3  $$调整蓝德系数ARI兰德系数（RI，Rand index），我用中文看了不少讲兰德系数的博客，其中的文字说明几乎都是相同的，对个人的理解帮助不是特别大，于是用英文查的。最终理解了这个系数的参数的意思，想看英文说明的，个人觉得还挺好懂的参考这里。以下是我个人的讲解。首先，将原数据集中的元素进行两两配对形成一个新的数据集，我们称之为S数据集。这时候，我们将原数据集，根据两种不同的策略分别划分成r份和s份，并对这两个数据集命名为X和Y。在这里我们可以看出，X和Y的元素是相同的，只是他们的划分方式不同。接下来我们来思考，S数据集中，每个元素中的两个样本，在X和Y中只有两种可能，就是两个样本都在一个子集中，或者不在一个子集中，那么对于S中的一个元素，只有四种可能性。	两个样本都在X的一个子集中，也同时在Y的一个子集中，这些元素的个数是a	两个样本横跨X的不同子集，也同时在Y中横跨Y的不同子集，这些元素的个数是b	两个样本都在X的一个子集中，但在Y中横跨Y的不同子集，同理数量为c	两个样本横跨X的不同子集，但在Y的的一个子集中，同理数量为d有了上述的理解，我们再看蓝得系数公式，公式5.4，我们就不难理解了。RI的取值在$[0,1]$之间，越靠近1代表越相似。$$RI = \frac{a+b}{a+b+c+d} = \frac{a+b}{C_2^n} \ \ \ 公式5.4  $$接下来引入，调整兰德系数(ARI，Adjusted Rnd Index)，ARI取值范围$[-1,1]$，值越大，表示聚类结果和真实情况越吻合。从广义的角度来将，ARI是衡量两个数据分布的吻合程度的，公式5.5如下：$$ARI = \frac{RI - E[RI]}{max(RI) - E[RI]}\ \ \ 公式5.5$$调整互信息(AMI，Adjusted Mutual Information)调整互信息，整体的流程很像ARI，AMI则是对MI进行调整。而MI是使用信息熵来描述的。那么互信息表示了什么呢，首先先看下维基百科的定义：独立的(H(X),H(Y)), 联合的(H(X,Y)), 以及一对带有互信息 I(X; Y) 的相互关联的子系统 X,Y 的条件熵。在概率论和信息论中，两个随机变量的互信息（Mutual Information，简称MI）或转移信息（transinformation）是变量间相互依赖性的量度。不同于相关系数，互信息并不局限于实值随机变量，它更加一般且决定着联合分布p(X,Y) 和分解的边缘分布的乘积 p(X)p(Y) 的相似程度。互信息是点间互信息（PMI）的期望值。互信息最常用的单位是bit。简单的来说，这个公式代表着两个子系统X和Y的相似度，但是这里的相似度是从信息熵的角度出发的，它越大代表着两者的差异越大，其计算公式以及相关的公式如下公式5.6，公式5.7所示。$$MI(X;Y) = \sum_{y \in Y}\sum_{x \in X}p(x,y)\log{\frac{p(x,y)}{p(x)p(y)}}\ \ \ 公式5.6$$$$\begin{split}MI(X;Y) &= H(X) - H(X|Y)\\&=H(Y) - H(Y|X)\\&=H(X) + H(Y) - H(X,Y)\\&=H(X,Y) - H(X|Y) - H(Y|X) \ \ \ 公式5.7\end{split}$$轮廓系数之前我们说到的衡量指标都是有标签的，这里的轮廓系数则是不包含标签的评价指标。	簇内不相似度：		计算样本i到同簇其它样本的平均距离为$a_i$ 。$a_i$越小，表示样本$i$越应该被聚类到该簇，而簇C中的所有样本的$a_i$的均值被称为簇C的簇不相似度。	簇间不相似度：		计算样本i到其它簇$C_j$ 的所有样本的平均距离bij， $b_i=min{bi1,bi2,...,bik}$ ，$b_i$ 越大，表示该样本$i$越不属于其它簇。	轮廓系数：		$s_i$值越接近1表示样本i聚类越合理，越接近-1，表示样本i应该分类到另外的簇中，近似为0，表示样本i应该在边界上。所有样本的si的均值被成为聚类结果的轮廓系数。		$$		s_i = \frac{b_i - a_i}{max\{a_i,b_i\}}		$$]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[BaiduPCS-Go的使用]]></title>
      <url>/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/2018/08/17/BaiduPCS-Go%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      <content type="text"><![CDATA[Why BaiduPCS-GoBaiduPCS-Go是一个用Go语言编的命令行版的百度网盘，我们可以类比mas和Appstore的关系。那么为什么要用这样一个安装比较麻烦，还要记命令行的百度网盘的替代品，直接用百度网盘客户端不好么？这还真的是不好，百度网盘在mac下是一个十足的阉割版，最常用的功能中，Mac版缺失了以下几种功能：  没有分享功能：mac下的客户端的分享功能居然是需要通过浏览器打开，太不优雅了。  没有离线下载任务：直接导致不能下载磁力链接。如果你和我一样平时一样习惯终端操作，这个工具的学习成本超级低，同时它还有一定的提升下载速度的功效。使用指南安装Mac一般是预装了go的，如果没有的话，使用brew install go来安装。除了go我们还需要安装git，同样使用brew install git。在拥有了git和go以后，执行下面的指令即可。go get -u -v github.com/iikira/BaiduPCS-Go注：在安装途中，有提示说其安装到了一个~/go/bin的目录，也就是说这个工具的执行文件在~/go/bin这个目录。为了之后我们能够全局使用这个指令，于是我们将export PATH="/Users/deamov/go/bin:$PATH"添加到配置环境变量的文件中，如果没有使用zsh的话在~/.bashrc中，如果用的是zsh的话在~/.zshrc中。注：deamov是我的电脑的用户名，至此安装便结束了。常用操作说明登陆BaiduPCS-Go简单一行指令就可以登录了，如果之前已经登陆过账号的话，现在就已经可以开始进行下载等操作了，如下效果图。 第一次使用需要有登陆的操作，输入login即可登陆，尊许提示依次输入账户和密码即可，如果需要验证码，则会输出一个链接，打开就可以看到验证码了。基本操作基本的移动目录的方式和linux的操作一样，ls是现实当前目录的文件，rm是删除命令，cd是切换目录，创建目录是mkdir，拷贝是cp，值得一提的是它支持Tab补全。和平时使用的终端命令不同的有如下几个指令。  搜索：平时我们使用的grep在这里是不能使用的，我们用search关键词来搜索。      search 关键字 # 搜索当前工作目录的文件  search -path=/ 关键字 # 搜索根目录的文件  search -r 关键字	# 递归搜索当前工作目录的文件         下载：记住是download就好啦      BaiduPCS-Go download &lt;网盘文件或目录的路径1&gt;   BaiduPCS-Go d &lt;网盘文件或目录的路径1&gt; &lt;文件或目录2&gt; &lt;文件或目录3&gt; ...  # 当然支持多文件下载咯，下载目录默认在~/Download文件夹中        离线下载: 支持http/https/ftp/电驴/磁力链协议      # 将百度和腾讯主页, 离线下载到根目录 /  offlinedl add -path=/ http://baidu.com http://qq.com  # 添加磁力链接任务  offlinedl add magnet:?xt=urn:btih:xxx  # 查询任务ID为 12345 的离线下载任务状态  offlinedl query 12345  # 取消任务ID为 12345 的离线下载任务  offlinedl cancel 12345         分享share    查看分享内容      share list  share l        取消分享      share cancel &lt;shareid_1&gt;  share c &lt;shareid_1&gt;  # 遗憾的是只能支持通过shareid来取消分享        上传：同名文件会被覆盖    注：需要退出BaiduPCS-Go使用，否则本地文件目录不能自动补全    $BaiduPCS-Go upload &lt;本地文件/目录的路径1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;$BaiduPCS-Go u &lt;本地文件/目录的路径1&gt; &lt;文件/目录2&gt; &lt;文件/目录3&gt; ... &lt;目标目录&gt;# Example$BaiduPCS-Go upload ~/Downloads/1.mp4 /Video        其他    这个工具很强大，还可以通过设置下载线程数等等操作来提升下载速度，更多详细的操作请参考它的官网。  ]]></content>
      <categories>
        
          <category> 软件使用 </category>
        
      </categories>
      <tags>
        
          <tag> 百度网盘 </tag>
        
          <tag> 下载 </tag>
        
          <tag> 教程 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Tobias的小粉丝在此]]></title>
      <url>/%E6%9D%82%E9%A1%B9/2018/08/16/Tobias%E5%B0%8F%E8%BF%B7%E5%BC%9F%E5%9C%A8%E6%AD%A4/</url>
      <content type="text"><![CDATA[									Tobias的小粉丝在此	序言最近迷上了吉他，当然不是指那种一周速成的把妹弹唱啦。为了防止大家对吉他有一种特别简单，把妹专用道具的奇怪印象。特别提一个小知识，古典吉他在世界公认的十大难学的乐器中排第三，顺便一提，钢琴排第五。正文不过，非常遗憾最近喜欢上的是并不是尼龙弦的古典吉他，而是它的另一个兄弟指弹吉他中的Percussive Fingerstyle。Percussive FingerStyle起源于80到90年代，它通过快速击打琴弦，琴身，以及琴的边缘制造装饰音。现在比较有名的几个这个风格的吉他手有Andy McKee和Tommy Emmanuel，而Tobias Rauscher也是这个领域的新秀，也是目前我最喜欢的吉他手之一。值得一提的是，他是14岁开始自学的吉他，开始的时候主要弹奏摇滚和重金属，知道2010年终于开始了Solo Acoustic Guitar的道路。和相似的同时用多个吉他，甚至奇怪形状吉他的Luca Stricagnoli不同，他只使用一把吉他，视觉效果上没有了那份笨重，同时Tobias的笑容也能让人感受到他对于吉他的热爱。有兴趣的小伙伴可以在网易云搜他的曲子。惭愧的说，第一次听他的曲子也是在网易云里面听到了，结果整整单曲循环了好几天（笑。其他Tobias的官网在此]]></content>
      <categories>
        
          <category> 杂项 </category>
        
      </categories>
      <tags>
        
          <tag> FingerStyle </tag>
        
          <tag> Guitar </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[支持向量机SVM]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/13/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/</url>
      <content type="text"><![CDATA[							支持向量机（Support Vector Machine）	支持向量机（Support Vector Machine）1、前言在之前我们介绍了线性回归算法以及其变种，LASSO回归、Ridge回归。他们是从减少过拟合的角度出发而得到的算法，而 SVM（支持向量机）则是优化原本线性回归算法中选择“分割线”，或者说选择分割超平面这样一个过程。TAG：# 拉格朗日数乘子算法 # KKT条件2、SVM的优点和缺点	优点：泛化错误率低，计算开销不大，结果易解释	缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二类问题。	数据类型：数值型和标称型数据。3、SVM算法原理首先我们都知道，为了划分二维的数据需要一根线，划分三维数据需要一个面。这里线是一维，面是二维，同理继续推出对 N 维的数据需要使用 N-1 维的对象进行分割，线性回归和 SVM 本质都是通过找这个超平面来达到分类的效果。具体的来说SVM是在优化线性回归中的 $kx+b$ 模型。在线性回归中只需要考虑有一个分割超平面能进行分类即可，而SVM则想找出所有能分类的分割超平面中最优的超平面，即所有点都到分割超平面的距离最大，而支持向量指的就是离超平面最近的那些点。超平面的公式为公式 2.1。所以点 A 到分割超平面的距离为公式 2.2。这里我们为了方便计算引入类别标签为-1和+1。所以保证所有的最小间隔的点最大化的公式为公式 2.3。注1：-1和+1是为了保证预测正确的时候，$y(x_i)*label_i$都是一个很大的正值。注2：$arg\ max_{w,b}$的含义是，得到w和b使得后面式子取最大值$$y(x) = w^TX+b\ \ \ 公式2.1$$$$\frac{|w^TX+b|}{||w||}\ \ \ 公式2.2$$$$arg\ max_{w,b}\{min_i(label_i*(w^Tx_i+b)*\frac{1}{||w||})\}\ \ \ 公式2.3$$显然我们不能直接求解上面的式子。需要化简下它。首先由于公式2.1在正确预测时，同 $label$ 的乘积大于 1。所以我们可以拆分公式2.3为公式2.4和约束条件公式2.5。注：这里的约束条件公式2.5中，要对每一个式子前都要加系数，即拉格朗日数乘子$\alpha_i$。$$arg\ min_{w,b}\ ||w||\ \ \ 公式2.4$$$$st.\ \ label_i*(w^Tx_i+b) \geq 1 \ \ \ 公式2.5$$对为了方便求导计算在公式 2.4 前加上$\frac{1}{2}$这个系数。之后使用拉格朗日乘子法得到公式2.6，并进行计算。根据KKT条件，让偏导数等于0得到公式2.7和公式2.8。注：这里需要注意的是拉格朗日数乘子的正负号，这个同不等式的符号有关$$L(w,b,\alpha)= \frac{1}{2}||w||^2-\sum_{i=1}^n\alpha_i*[label_i*(w^Tx_i+b)-1]\ \ \ 公式2.6$$$$\sum_{i=1}^{n}\alpha_i label_i x_i = w\ \ \ 公式2.7$$$$\sum_{i=1}^{n}\alpha_i label_i = 0\ \ \ 公式2.8$$将公式2.7，公式2.8代入公式2.6化简，再根据对偶问题得到最终公式2.9，根据KKT，其约束条件为公式2.10。注1：KKT条件在SMO算法中统一进行讲解。注2：b是由公式2.8消掉的。注3：在拉格朗日乘子法应用在这里，我们可以把$||w||$，写作$max_\alpha\ L(w,b,\alpha)$，所以原式可以写作$min_{w,b}\ max_\alpha\ L(w,b,\alpha)$，根据对偶问题，就可以变成$max_\alpha\ min_{w,b}\ L(w,b,\alpha)$，这也是能把公式2.7和公式2.8代入公式2.6的原因，也是公式2.9种是$max_\alpha$的原因。具体证明在KKT中的附上的博客中。$$max_\alpha\ \sum_{i=1}^{n}\alpha_i - \frac{1}{2}\sum_{i,j=1}^{m}label_i*label_j*a_i*a_j\langle x_i·x_j\rangle\ \ \ 公式2.9$$$$\alpha_i \geq 0\ \  且\ \sum_{i=1}^{m}\alpha_i*label_i = 0\ \ \ 公式2.10$$注：这里$\langle x_i·x_j\rangle$是两者向量积的运算，是从$x_i^T*x_j$得到的。这么看来我们算出了$\alpha$就能算出超平面，所以SVM的工作就是算出这些$\alpha$，而SMO算法就是求$\alpha$的典型算法。4、对SVM引入线性不可分由于数据都不那么干净，所以我们不应该假设数据能够100%的线性可分。我们通过对判定的公式，公式2.5，引入松弛变量$\xi_i\geq 0$，得到其引入了松弛因子的形式，如下公式3.1。$$y_i(w*x_i+b)\geq1-\xi_i\ \ \ 公式3.1$$同时对于目标函数公式2.4也需要调整，我们将$\xi$引入目标函数并对其设置权值，得到公式3.2，也因此其约束条件变为公式3.1，公式3.2。$$min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^N\xi_i\ \ \ 公式3.2$$$$\begin{split}st.\ \ \ &y_i(w*x_i+b)\geq 1 - \xi_i\\&\xi \geq 0\end{split}$$故拉格朗日函数$L(w,b,\xi,\alpha,\mu)$为如下公式3.3，其中$\alpha$，$\mu$为拉格朗日数乘子。$$L(w,b,\xi,\alpha,\mu)=\frac{1}{2}||w||^2+C\sum_{i=1}^N\xi_i-\sum_{i=1}^n\alpha_i*[label_i*(w^Tx_i+b)-1+\xi_i]-\sum_{i=1}^n\mu_i\xi_i\ \ \ 公式3.3$$和之前的操作一样，对其进行求偏导操作后，类似的得到了相同的公式2.7，公式2.8，不同的是这里对$\xi$的求到后对$\alpha$有了限制，得到了公式3.4，由于$\mu\geq0$所以有$\alpha_i$的取值范围$0 \leq \alpha_i \leq C$。注：注意这里的$\alpha$取值，之后SMO会用$$C-\alpha_i-\mu_i = 0\ \ \ 公式3.4  $$最终目标函数还是同之前推导的相同，即公式2.9。变化的只有，约束条件中$\alpha$的取值变为了$0 \leq \alpha_i \leq C$。这样有了目标函数了以后，之后可以根据梯度下降算法求得最终的$\alpha$5、SMO（Sequential Minimal Optimization）5.1、KKT条件 由于使用了拉格朗日数乘法，其中KKT条件便是SMO算法的精髓，所以我觉得有必要在这里提到KKT条件。首先我们求$f(x)$ 极值的时候，需要讨论三种情况。	没有约束条件：	有一个等式$h(x)$的约束条件：		使用拉格朗日乘子法（Lagrange Multiplier），也就是我们在高数中求极值常用的。设置一个拉格朗日系数$\alpha_1$，得到如下公式，之后对$x$和$\alpha_1$用求导的方式求极值即可。		$$		L(x, \alpha) = f(x) + \alpha*h(x)		$$	含有不等式的约束条件：		当约束条件中有不等式时，就需要用到KKT条件。同样地，把所有的不等式约束$g(x)\leq0$、等式约束$h(x)=0$和目标函数$f(x)$全部写为一个式子如下公式。		$$		L(x,\alpha_1, \alpha_2)= f(x) + \alpha_1*g(x)+\alpha_2*h(x)		$$		KKT条件是说最优值必须满足以下条件：					$L(x, \alpha) = f(x) + \alpha(x)$ 对$x$，$\alpha_1$，$\alpha_2$求导为零。			$h(x)=0$ 。			$g(x)*\alpha_1=0$。				其中第三个式子非常有趣，因为$g(x)\leq$ 0 ，如果要满足这个等式，必须有$a = 0$或者$g(x) = 0$。这是SVM的很多重要性质的来源。同时$f(x)$也可以写作$max_{\alpha_1,\alpha_2}\ L(x,\alpha_1,\alpha_2)$，这个则是SMO求解中的一个关键性质。详细的论述参考这篇博客。5.2、SMO算法细节SMO算法综述由于原来直接通过梯度下降进行求解速度太慢，所以1996年，John Platt依靠KKT的特性，将大优化问题变成了多个小优化问题来求解，成为了SVM中最常用的求解思路。其思路如下：	Loop：					选取一对 $\alpha_i$，$\alpha_j$作为变量，其余看为常数			如果这对$\alpha$满足以下两个条件，使用梯度下降算法改变他们的值。									两者都在间隔边界外					两者都没有在进行过区间化处理，或者不在边界上							当满足了KKT条件，即$\sum_{i=1}^N\alpha_iy_i=0$和$0\leq \alpha_i \leq C$，退出循环。		注：这里可以这么理解，$\alpha_i$从之前的公式中我们可以大致理解为是每一个样本的权值，我们这些操作可以理解为通过操作$\alpha$把所有的样本点尽量的放在间隔边界上。算法推导我们接下来要做的是，通过类似梯度下降的方式来求的最优的$\alpha$值。正如上一节所说的，SMO的本质是大优化问题画小优化问题。所以从目标函数公式2.9中，随意取出两个$\alpha$，为了表达方便，不妨直接取$\alpha_1$和$\alpha_2$，同时对公式2.9前加负号取反之后，化简如下式4.1，其中$\kappa_{ij}$代表$\langle x_i·x_j\rangle$。$$\begin{split}min_{\alpha_1, \alpha_2}W(\alpha_1,\alpha_2) &=\frac{1}{2}\kappa_{11}\alpha_1^2+\frac{1}{2}\kappa_{22}\alpha_2^2+y_1y_2\alpha_1\alpha_2\kappa_{12}-(\alpha_1+\alpha_2)\\&+y_1\alpha_1\sum_{i=3}^Ny_i\alpha_i\kappa_{i1}+y_2\alpha_2\sum_{i=3}^Ny_i\alpha_i\kappa_{i2}\ \ \ 公式4.1\\\end{split} $$$$\begin{split}st. \ \ &\alpha_1y_1+\alpha_2y_2=-\sum_{i=3}^Ny_i\alpha_i\\&0\leq\alpha_i\leq C\end{split}$$由于我们已经把不是$\alpha_1$和$\alpha_2$的参数看作常量，所以在进行求偏导进行梯度下降算法的时候就不需要考虑公式4.1中第二行的式子。通过这个式子中约束条件的等式就可以得到仅含$\alpha_j$的式子，对其进行梯度下降算法，得到如下公式4.2：$$g(x)=\sum_{i=1}^Ny_i\alpha_i\kappa(x_i,x)+b  $$$$\eta = \kappa_{11}+\kappa_{22}-2\kappa_{12} = ||x_1-x_2||^2$$$$E_i = g(x_i)-y_i = (\sum_{j=1}^Ny_j\alpha_j\kappa_{ji}+b)-y_i$$$$\alpha_i = \frac{\xi-\alpha_j y_j}{y_i}$$$$\alpha_j^{new}=\alpha_j^{old}+\frac{y_j(E_i-E_j)}{\eta}\ \ \ 公式4.2$$这时候我们已经找到了两个的$\alpha$的新值了，不过我们不能确定这两个新值是否还满足KKT条件。所以我们根据KKT条件中$\alpha$的取值，设置了 L 和 H 来防止新值不满足 KKT，即$L\leq\alpha_i,\alpha_j \leq H$，其中L，H的公式如下公式4.3和公式4.4得到：$$if\ y_i \neq  y_j\ \ \ L=max(0,\alpha_j-\alpha_i),\ H=min(C,C+\alpha_j-\alpha_i)$$$$if\ y_i = y_j\ \ \ L=max(0,\alpha_j+\alpha_i-C),\ H=min(C,\alpha_j+\alpha_i)$$L H的细节推导在这个博客中详细的说明了LH是怎么推出来的。简单的来说就是之前提到的由线性不可分中得到的一个 $\alpha$ 的取值范围划定了一个正方形的框，之后公式 4.1 中第一个条件我们可以画一条直线，然后试图得到一个更精确的$alpha$范围，而这个 L 和 H 分别代表的是 High 和 Length（这点没有考证，是我个人的理解）。而为什么要讨论 $y_i$ 和 $y_j$ 是否同号，则是因为他们是否同号决定了画的直线的斜率。至此，SMO算法的整体就讲完了，它最厉害的地方在于把一个很复杂的大的运算量很大的运算变成了一个一个小的优化问题，个人觉得这种以提升效率为目的，化大为小，带点贪心的算法的算法是非常优雅。6、结语这一章节中涉及的算法看似很复杂，但是实际的推导当你理解了拉格朗日数乘法和KKT条件以后，剩余的就是一些基本的求导操作，和一些减少运算的小技巧，如在判断 $\alpha$ 的变化方向的时候就不考虑公式 4.1 中第二行的式子等。建议大家都手推推，毕竟这个算法是目前面试中出现概率比较高的算法。到这里为止 SVM 算法还是作为一种二分类算法，当咱们的专栏进行到接近尾声的时候，我会给大家介绍几种把二分类变成多分类的集成算法思路。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[使用Github创建自己的小博客]]></title>
      <url>/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/2018/08/12/%E4%BD%BF%E7%94%A8Github%E5%88%9B%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%B0%8F%E5%8D%9A%E5%AE%A2/</url>
      <content type="text"><![CDATA[							使用Github创建自己的小博客	懒人攻略只有四步：	找到自己喜欢的别人的博客的Github地址，一般为username.github.io结尾。	Fork一份对方的源码，之后把仓库名改为YourGithubName.github.io	在_config.yaml中更改个人信息，同时把_posts中的文章都删了，注意别人的文章格式，之后仿照对方的格式写即可。	给你Fork的原作者写封邮件表达感谢！说不定就这么勾搭了一个大佬也不一定呢。完成了四步后，浏览器输入YourGithubName.github.io就能在晚上看到自己的博客啦。折腾攻略本这不重新造轮子的原则，附上我参考的大佬们的文章。	搭建篇：		简书上chaosinmotion 的 Github Pages + Jekyll 独立博客一小时快速搭建&amp;上线指南 	添加评论系统：		Github上knightcai的 为博客添加 Gitalk 评论插件 		特别一提，如果出现Validation Error是因为博客标题的名字编码后太长了，参考这个Issue中mr-wind的使用 id: decodeURI(location.pathname) 解决方案。		注：md5的方案可能更好，偷懒起见我没有用。	阅读量统计：		wanghao的 为NexT主题添加文章阅读量统计功能 ，这个文章用的是leandCloud。	搜索服务：		使用Algolia，不过自带的LocalSearch比较简单。文章有配置说明。	主题：		Next系列。官网有安装手册。	CopyRight:		在目录下搜索copyright，找到那个html文件进行修改就好了。效果是文章下面的红竖杠中的内容。	小彩蛋：		史蒂芬小恐龙，他的js文件在这里！之后就任君发挥啦，Happy Coding。	最后题外话		所有的配置基本上都可以在_config.yaml中设置，同时在博客中\代表的就是根目录，这样子你自己在配置其他的功能的时候就可以轻松愉悦的配置。值得一提的是css文件和js文件都在assets文件夹中，自己DIY的时候最好不要打乱目录结构。]]></content>
      <categories>
        
          <category> 软件使用 </category>
        
      </categories>
      <tags>
        
          <tag> GithubPage </tag>
        
          <tag> 博客 </tag>
        
          <tag> 教程 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[决策树优化策略]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/10/%E5%86%B3%E7%AD%96%E6%A0%91%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/</url>
      <content type="text"><![CDATA[							决策树优化策略	1、剪枝优化是什么？决策树的剪枝是决策树算法中最基本、最有用的一种优化方案，分为以下两类：	前置剪枝：在构建决策树的过程中，提前停止。这种策略无法得到比较好的结果	后置剪枝：在决策树构建好后，然后开始剪裁，一般使用两种方案。a）用单一叶子结点代替整个子树，也节点的分类采用子树中最主要的分类。b）将一个子树完全替代另一个子树。后置剪枝的主要问题是存在计算效率问题，存在一定的浪费情况。后置剪枝后置剪枝的核心思想其实就是交叉验证，其通过对完全树进行剪枝，一直剪到只剩下树根，这样子便得到许多树，随后通过使用数据集分别对他们验证，然后根据结果选择最优树。2、决策树剪枝过程while 生成的决策树不为1个节点:	计算所有内部非叶子节点的剪枝系数;	选择最小剪枝系数的节点:		if 有多个最小剪枝系数节点:			选择包含数据项多的节点删除		else:			删除节点		将剪枝后的树存入之后用的决策树集for 决策树 in 决策树集:	用数据集验证决策树，得到最优剪枝后的决策树其中用于验证决策树的损失函数如下公式 1.1：$$loss = \sum_{t=1}^{leaf} \frac{D_t}{D}H(t)\ \ \  公式1.1$$那么我们剪枝需要把所有的可能都剪一边么，显然不能。这里就引入了剪枝系数来判别每次剪枝选择哪个节点：首先我们明确，剪枝系数的目的为，平衡准确度和树的节点数量之间的关系。所以很自然的想到我们常用的处理手法，在损失函数中引入叶子结点的变量，得到公式1.2。注：这种思路我们在LR算法中也用了，生成了Ridge和LASSO$$loss_{\alpha} = loss + \alpha*leaf\ \ \ \ 公式1.2$$假定剪枝前的损失函数为$loss(R)$，剪枝后的损失函数为$loss(r)$，由于我们是想让剪枝前后的准确率尽量不变，所以让剪枝前后的损失函数相等，化简得公式1.3，即剪枝系数。注：多次剪枝后为根节点，所以$r=1$。$$\alpha = \frac{loss(r)-loss(R)}{R_{leaf}-1}\ \ \ \ 	公式1.3$$那么这个系数怎么用呢，答案就是由于我们想尽量减去的叶子结点多点，又同时保持准确度，故剪枝系数越小越好。3、结语我们可以看到，到了这里算法开始就有了集成学习的特点了，算法开始从简单的单一的算法进行进化和融合，最终像搭积木一样慢慢完成了后期特别复杂的算法。BTW，这里使用的算法其实大部分代码实现（不是使用别人写好的函数），可以在 《机器学习实战》 中找到。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[决策树]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/09/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      <content type="text"><![CDATA[							决策树&amp;ID3,C4.6,CART	1、 前言之前我们已经说了，机器学习的从线性回归，概率这个出发点发展的算法。这次我们讲从第三个出发点，使用信息熵的算法，决策树。2、 信息熵首先我们来介绍什么是信息熵，信息熵是1948年，香农引入信息熵。一个系统越是有序， 信息熵就越低，一个系统越是混乱，信息熵就越高，所以信息熵被认为是一个系统有序程度的度量。举个例子，太阳从东边升起这个规律人人都知道，所以信息熵低，而GAN算法是怎么推导的知道的人就不多，所以它的信息熵高。注：一个事件发生的概率大，那么它含有的信息少。一言已概之就是：信息熵就是用来描述系统信息量的不确定度。其公式如下：$$H(x) = - \sum_{i=1}^m p_i log_2(p_i)$$条件熵的定义为： 给定条件X的情况下，所有不同x值情况下Y的信息熵的平均值叫做条件熵。$$H(Y|X) = \sum_{j=1}P(X = v_j)H(Y|X = v_j)$$$$H(Y|X) = H(X,Y)-H(X)$$3、 纵览决策树算法在了解了这个算法的关键评判标准后，我们来看下决策树是什么，决策树 ( Decision Tree ) 是在已知各种情况发生概率的基础上，通过构建决策树来进行分析的一种方式，是一种直观应用概率分析的一种图解法。决策树是一种树形结构， 其中每个内部节点表示一个属性的测试，每个分支表示一个测试输出，每个叶节点代表一种类别。换句话说，决策树的使用是一种模拟了简单的人类思考过程的思路。通过许多if...else...进行判断最后得到一个结论。3.1、 决策树构建过程构建步骤如下:	将所有的特征看成一个一个的节点;	遍历每个特征的每一种分割方式，找到最好的分割点;将数据划分为不同的子节点 $N_1, N_2,...,N_m$。计算划分之后所有子节点的纯度信息。	对第二步产生的分割，选择出最优的特征以及最优的划分方式。得出最终的子节点: $N_1,N_2,...,N_m $ 	对子节点分别继续执行2-3步，直到每个最终的子节点都足够纯。注：这里的纯度指的是每个字节点的类别尽量相同。注意构建过程中的选择最优特征的步骤决定了后期算法的不同3.2、划分方式的选择在上述 3.1 中提到了两个关键性的事情，叫做划分方式和选择最优特征，这里我们就要讨论的是划分方式。众所周知，数据分为离散的和连续的，显然我们对他们的处理有些不同。如果属性是离散值，且要求是二叉树，我们就可以按照一般的逻辑方式，按照属于此子集和不属于此子集分成两个分支。如果没有要求是二叉树则一个属性就是一个分支。如果是属性为连续值，则可以确定一个值作为分裂点split_point，按照&gt;split_point和&lt;=split_point生成两个分支。3.3、 决策树分割属性选择之前我们说了划分方式，那么我们如何选择最优的特征呢。答案是比较纯度。首先决策树算法是一种“贪心”算法策略，只考虑在当前数据特征情况下的最好分割方式，且不能进行回溯操作。而对于整体的数据集而言，通过查看每个特征属性划分后，纯度的变化进行比较，选择能让数据集变得更纯的特征属性进行分割。之后重复上述步骤直到满足条件。注：题外话，虽然我们很少需要自己造轮子，但是还是需要知道树的结构是符合递归规律的，一般而言树的构建都可以使用递归算法那么纯度是什么，纯度其实就是一种判断决策树是否向着正确方向前进的判断。粗鄙的类比，就是母猪配种，选择最合适的方式将不同种的猪分开，尽量保证每波猪都是纯种的。纯度的判断标准不同也决定了之后的算法的名称不同，其标准如下三种：	基尼系数：$Gini = 1 - \sum_{i=1}^nP(i)^2$					信息熵：$-\sum_{i=1}^n P(i)log_2(P(i))$			误差率：$Error = 1 - max_{i=1}^n \{P(i)\}$		注 1：这里我说的是算法名称不同，其实更多的想指代他们是一个系列的算法，和LR与Lasso和Ridge的关系一样注 2：如上公式都体现了纯度值越小信息量越大这个理念上面是基础的一些系数，在剪枝和判断的时候需要一个种体现变化的系数，于是出现了如下公式来作为C4.5和ID3的判别标准。简单的理解为，这个公式表达了以A属性划分后，信息量增加的量，或者说指代的是纯度变纯了多少。$$Gain = \Delta = H(D)-H(D|A)$$3.4、 停止条件决策树构建的过程是不断递归的过程，就像 (是) while 循环一样，必须有跳出循环的条件。以下是两个停止条件。	每个字节点只有一种类型时停止条件。（容易过拟合）	节点中记录数小于某个阀值的时候，或者迭代次数达到给定值的时候停止构建。3.3、 决策树的评估$$loss = \sum_{t=1}^{leaf} \frac{|D_t|}{D}H(t)$$其中$H(t)$前的参数$\frac{D_t}{D}$主要的目的其实是给信息熵加权值，代表着节点中的样本点越多它越重要。4、 算法对比其实到这里决策树的核心就介绍完了，现在来看实际中的算法应用，也是面试种可能（不太可能）问到的算法，即ID3，C4.5，CART。其中CART最重要，会在之后的GBDT算法中，代表着那个DecisionTree。4.1 、ID3算法ID3算法是决策树的一个经典的构造算法，每次迭代选择分割属性的方式为，使用信息增益作为评判标准。优点为：决策树构建速度快，实现简单。缺点为：首先，计算依赖于特征数目较多的特征，而属性值最多的属性并不一定最优。其次，ID3算法不是递增算法，是单变量决策树，对于特征属性之间的关系不会考虑，抗噪性差。最后由于它的数据要扔到内存中，所以只适合小规模数据集。4.2、C4.5算法在ID3算法的基础上，进行算法优化提出的一种算法 ( C4.5 ) 。其使用信息增益率来取代ID3算法中的信息增益，同时在树的构造过程中会进行剪枝操作进行优化。能够自动完成对连续属性的离散化处理。C4.5算法在选中分割属性的时候选择信息增益率最大的属性。信息增益率公式如下：$$Gain\_ratio(A) = \frac{Gain(A)}{H(A)}$$优点：产生的规则易于理解，同时准确率较高且实现简单缺点：由于采用了剪枝优化，所以对数据集需要进行多次顺序扫描和排序，所以效率较低 ，和ID3一样同样需要将数据放在内存，故只适合小规模数据集。注：这里的能够处理连续值和剪枝优化都算是后期加的，只是Sklearn中没有给ID3赋予这个功能。他们的核心差别就在是增益率还是增益。剪枝优化会在决策树优化中讲CART好了，轮到了这个决策树中最重要的算法了，它使用基尼系数作为数据纯度的量化指标来构建的决策树。CART拆开是，Classification And Regression Tree，中文是分类回归树。这么叫的原因是它可以用来做分类和回归两类问题。值得注意的是：CART构建是二叉树其GINI增益公式如下：$$Gain = \Delta = Gini(D) - Gini(D|A)$$注：GINI系数的计算不牵扯信息熵运算中的对数运算，故速度比较快总结	ID3和C4.5基本上是一回事，所以他们都是单变量决策树，都只使用在小规模数据集	C4.5算是ID3的优化，所以当属性取值较多的时候，可以考虑C4.5而不是ID3	决策树的树是存在内存中的，所以一般只适用于小数据量。		注：一般你要是看到了类似B+树的结构，一般不是完全在内存中	CART是最常用的，尤其是后期集成算法GBDT中用的就是CART。CART是二叉树，ID3和C4.5不一定是。最后这掌的重点在于知道决策树的生成规律，而三种算法的区别仅仅只是对于树形成节点的规则不同而已，ID3使用信息增益、 C4.5使用信息增益率、CART使用基尼系数。这一章依旧是一个轻松愉悦的章节，内容非常easy。之后我们会开始进入基础算法之后的升级版就困难不少。BTW，没想到有这么多人关注专栏，再次感谢大家。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[《滚雪球》- 爱丽丝·查理芒格]]></title>
      <url>/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/2018/08/08/%E6%BB%9A%E9%9B%AA%E7%90%83-%E7%88%B1%E4%B8%BD%E4%B8%9D-%E6%9F%A5%E7%90%86%E8%8A%92%E6%A0%BC/</url>
      <content type="text"><![CDATA[							《滚雪球》 - 爱丽丝·查理芒格	读书笔记在巴菲特看来，真正富有的人生应该是这样的：做一份自己喜欢的工作，找到兴趣相投的朋友。只要能做到这些，你的人生也一样是成功的。正如巴菲特的总结，做一个自己能感到自己价值的工作，找到能互相认可的人也许才是人生的最大意义。在努力的做自己的喜欢的工作的时候才能更容因进入”专注“的境界。而兴趣相投的朋友则会让你的生活变得丰富，人说到底还是群居的动物，社交是必要的也是维持正常心理所必须要的要素。同时他们之间也是互通的，一个好的社交保持了好的积极的心态，保持了良好的且多元的信息社区，促进了工作的进步，工作的进步获得了回报，在财力和心理上形成正向激励，达成”飞轮效应“，进步越来越开实现复利增长。巴菲特有三宝，“内部积分卡”，“专注”，“复利”内部积分卡指的是，自己的行为有自己的评价标准，自己来定义自己是什么样的人，而不是由外部来定义自己，这样做到之后就会达到一种非常好的内心自洽。正如熊太行老师讲的那样，其实有时候内心自洽是一个强大者的开端，能让我们不去盲目的做一些违背自我的决定。“异于常人”的专注，其实很多时候是别人不能复制你成功的最大的壁垒。有着异于常人的专注的巴菲特能够通过专注找到“地上的烟蒂”，而缺了专注的行业其他人即便知道了方法也不能发现“烟蒂”。复利，在滚雪球中，复利的魅力用于体现在投资上，每次都能在之前的基础上以一个固定的比例进行增长，之后会越涨越快一发不可收拾。这点在吴军的《Google方法论》和《硅谷来信》，以及吴伯凡老师也多次提及，不过名词略有不同，吴军老师称之为指数增长，吴伯凡老师称之为飞轮效应。都在强调可叠加的魅力。如果放在生活中，我们应该常常反思，我们现在做的工作是不是可以叠加的，是不是在以大利益行动，是不是能成为未来的自己工作学习的基础。人生就像滚雪球，最重要的就是发现湿雪和长长的山坡这句话特别经典，也被很多人视为人生格言。我的感悟是，湿雪不难找到，但是有耐心和勇气去用人生这一个有限的时间，去选择一个长而不急的山坡不是每个人都能做到的。很多人看到别人在急坡中一时的成功，便忍不住放弃自己的计划，跟随别人，最终摔得人仰马翻。随后重复上述过程，直到到达山底最终一无所获。最佳的策略也许是认准一个“湿雪”较多的路径，随着不陡不缓的山坡，不急不躁，把自己的雪球越滚越大。个人总结今年开始，随着读的书越来越多，发现很多时候抛开大佬们成功的表象背后，总有一些惊人的相似的地方。首先是兴趣和专注，吴军说“努力只能让你成为行业的前20%，而兴趣决定了你是否能走完最后的10%”，自己不知道从什么时候起养成了一种选择困难症，虽然确定了计算机机器学习这个大方向，但是却没有一个具体的目标，导致近一个月来学习重心的摇摆不定，在机器学习，爬虫和区块链中摇摆不定。虽然他们学习的进度都还不错，爬虫接了北京高教所得项目，区块链得到了Hackathon竞赛的奖，机器学习算是初步入门正在踏入深度学习的领域，但是真真切切的感受到了自己能力的天花板，即“我没有能力去同时专精所有的方向”，方向仍需做减法。其次是“复利”，可叠加性的增长最有意思的是，往往这种复利型的进步开始的时候很困难，很累很苦，需要一个很强的内心去坚持，但随着飞轮开始转动一切就会变得理所当然。这点有一点小小的体会吧，这点体现在VIM的配置上面，开始的时候很艰难，各种快捷键都不知道是什么，觉得无比难用。不过，在了解到真的很多大佬是真的使用VIM或者类似的我认为超级难用的编辑器作为生产工具的时候，觉得也许应该坚持下来，不过没想到真的VIM在日后成为了我主要的生产工具。开始的时候只是配置了代码高亮，后来渐渐加入了代码补全，再后来补充了各种各样插件并学习了更多的快捷键，最后甚至自己能编一些脚本来实现自己想要的功能。那么它给我带来了什么“复利增长呢”，减少了不必要的分心，所有的学习需要的工具大多都能通过统一的途径获得，操作上不需要太多的改动，从论文的书写到代码的规范，同时由于打开很快的特性，能让我在有想法的时候就快速的写代码来测试，这些收获让我觉得之前的小努力都是值得的。同样的，我也相信算法，统计学和离散数学，包括博弈论，这些很多难啃又不会有立竿见影成效的东西最终会成为自己职业生涯复利增长的第一步。最后是内心自洽，个人自身的感受是，如果内心不能够自洽的话，很多精力都在花费在平复情绪上进行了没必要的经历开支，甚至“因为别人都这么做所以我也要这么做的”作出欠思考的行动，或者因为“情谊”做出了完全违背自己大利益的行动。行事内心要一把尺子，这把尺子要拿稳了。气场和魄力的起点便是内心自洽，如果自己都不能坚信自己的决定，又谈何让别人相信你的决定呢？]]></content>
      <categories>
        
          <category> 读书笔记 </category>
        
      </categories>
      <tags>
        
          <tag> Reading </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Logistic回归&SoftMax回归]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/Logistic%E5%9B%9E%E5%BD%92&SoftMax%E5%9B%9E%E5%BD%92/</url>
      <content type="text"><![CDATA[							Logistic回归&SoftMax回归	序言 之前的文章中我们介绍了普通最小二乘线性回归算法，并进行了较为详细的推导，并通过分析其过拟合的问题，推导出了另外三个算法，Ridge回归算法，LASSO回归算法，以及弹性网络。并简要的分析了他们的优缺点。今天我们来接着介绍算法。为什么说是算法而不是回归算法呢，是因为在研究了逻辑回归和Softmax回归算法以后，惊讶的发现这两个算法是分类算法，所以这个回归算法下的说法就不是很严谨了。Logistic回归在回归算法上中我们介绍了，线性回归算法。我个人是这么拆分的，线性-回归-算法，回归指的整体的算法是回归算法而不是分类算法，线性指的是在算法回归中，假定输入输出之间关系函数是$y = kx + b$这个线性方程。那么再看看Logistic回归，显然这里肯定就是换了另一个种类的方程咯。对的，不过在逻辑回归中这里有一点不太一样，它的输出只有0和1，它假定输出 $y = 1$的概率$P$，自然 $y = 0$的概率就是 $1-P$，而逻辑回归中假定的方程就是这个$P$。现在我们来看看这个方程是什么，如下公式1.1所示。这个公式没有接触过的朋友可能不太好想这是一个什么函数，但是结合着我们高数的极限知识，我们肯定知道这个函数在$+\infty $的时候去趋近于1，在$-\infty$的时候趋近于0，而且是快速收敛的。建议百度sigmoid函数看看这个函数的图（Logistic函数就是sigmoid函数）。	$p=h_\theta(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}} $		公式1.1之前在线性回归算法中我们知道了求最佳$\theta$的流程就是先写出他的似然函数（这个公式表示了预测正确的概率），然后求最大似然估计（想办法让这个预测正确的概率最大），最终通过求最大似然估计的结果，得到一种调整$\theta$的最佳方案。这个逻辑回归的似然函数为公式1.3(由公式1.2易得)。	$L(y|x;\theta)=(h_\theta(x))^y(1-h_\theta(x))^{1-y}$	公式1.2	$L(\vec y|x;\theta)=\prod_{i=1}^{m}(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}$					公式1.3之后对这个似然函数进行求导，我们都学过导数，在学导数的时候都知道，导数代表着值变化的趋势和速度。这里我们通过公式1.3对求对数，然后再对 $\theta_j $求导得到导数（公式1.4），这个导数就代表了针对$\theta_j $的正确预测的概率的变化趋势。如果让 $\theta$加上这个导数就可以保证让这个公式变大，直至最大为止。所以逻辑回归的调参如公式1.5，公式1.6所示，那么为什么是两个，在调参章节中会说明。	$\frac{\partial \ell(\theta)} {\partial \theta_j} = \sum_{i=1}^m(y^{(i)} - h_\theta(x^{(i)}))x_j$ 公式1.4	$\theta_j = \theta_j + \alpha \sum_{i=1}^m(y^{(i)} - h_\theta(x^{(i)}))x_j$	公式1.5		$\theta_j = \theta_j + \alpha (y^{(i)} - h_\theta(x^{(i)}))x_j $公式1.6好的，到这里逻辑回归的调参我们就知道了，特别的说明的是，这里的 $alpha$就是传说中的学习速率，而这个参数我们要注意的是，它不能太大（会错过最大值而不能收敛），也不能太小（会收敛到局部最小值）。那么我们有了调参，这里肯定也有一个损失函数来表示现在预测的怎么样吧，这里的思路很简单，你不是似然函数是越大越好么，那么我把你来个倒数不就好了么，最简单的做法就是给求对数之后的公式1.3，添加一个负号。所以它的损失函数如公式1.7。$loss(y^{(i)},\hat y^{(i)}) = -\ell(\theta) = \sum_{i=1}^m ln(1+e^{(1-2y^{(i)})\theta^T x^{(i)}}) $	公式1.7最后，想说从那个 只能为1或者0就可以看出逻辑回归虽然名字带了回归两个字，但是其实是一个分类算法。而接下来的SoftMax回归算法则是逻辑回归算法的一种拓展，这个在下一节里说。SoftMax回归在逻辑回归中，最终的分类结果，只有两类。这显然不是适用于很多其他的情况。所以SoftMax对逻辑回归进行了一般化，适用于K分类的问题。针对K分类的问题，我们的小伙伴 $\theta$参数就不在是一个向量了，我们设第K类的参数为向量$\theta_k$， 则有n个属性的参数就成了一个二维矩阵$\theta_{k*n}$。在Softmax回归中，我们设预测对第k类的概率为公式2.1。$p(y=k|x;\theta)=\frac{e^{\theta_k^T x}}{\sum_{i=1}^K e^{\theta_i^T x}} $, $k=1,2 ...,K $公式2.1剩下的分析同逻辑回归一样就不赘述了。机器学习调参我们在之前的学习中，了解到机器学习在迭代的过程就是不断的调整$/theta$参数的过程。有些是算法自己就调整了，有些是需要我们的人工的来调整的，这里就要引入超参这个概念了。什么事超参呢，超参就是不能通过算法自动调整的参数，比如Ridige回归和LASSO回归的 $\lambda$，弹性网络中的 $\alpha$。除了这些，在Logistic回归这一章节中，我们发现了调参函数有两个，但是并没有说明为什么。在这里将进行详细介绍。在Logistic和Softmax回归中我们用到的调参方式，只要你稍微了解过深度学习就一定听过，这种调参方式就是大名鼎鼎的梯度下降算法。而这两个公式，公式1.5是批量梯度下降算法（BGD），公式1.6是随机梯度下降算法（SGD）。通过公式1.6我们可以看出，每次迭代SGD调整一个$\theta_j$只需要和其中一条属性的比，而BGD每次迭代每调整一个$\theta_j$需要和所有属性的比较，所以SGD迭代速度快。那么SGD每次迭代考虑的属性少会不会没有BGD准呢，这是不一定的。梯度下降算法就像大雾天气下山，我们只能看清眼前的一小部分，并以此为依据下山，我们很有可能最后在山的上的一个小坑里出不来，陷入局部最优解的问题。SGD在全局餐在多个相对最优解的情况下，SGD很有可能跳出某些局部最优解，所以不一定会比BGD坏。而BGD一定能够得到一个局部最优解（在线性回归中一定是得到一个全局最优解）。不过由于SGD少考虑一些情况，所以有随机性，因而最终结果可能会比BGD差，一般情况下我们会优先使用SGD。注：个人的简单理解是，SGD每次只会往某一个坐标轴方向走一步，而BGD则是结合所有坐标轴的情况，往一个空间内的一个方向走一步。所以理论上BGD很“理性”。SGD和BGD出现的优缺点的情况是不是很熟悉，是不是很像Ridge回归和LASSSO回归的抉择，最终出现了弹性网络。那么是不是也有一个类似梯度下降算法的“弹性网络”呢，答案显然是有的，那就是MBGD，我不全不考虑完不就好了嘛。MBGD中每次拿b个样本的平均梯度作为更新方向，这里的b一般为10。这样子就既保证了速度，也一定程度上保证了准确度。模型效果判断最后，我们模型也训练好了，那么怎么来判定我的模型是不是合乎标准的，就像吴军老师在Google方法论说的一样，在工程中不是只有对错，只有相对的好和相对的不好，这个模型是否符合项目的需要也是有几个标准的，在训练的时候需要注意最终目标需要达到的标准是什么。常用的有MSE（公式4.1）、RMSE（公式4.2）、$R^2$（公式4.3）。在看公式前先说明TSS和RSS的概念，用在算$R^2$上。TSS(Total SUm of Squares)：总平方和TTS，样本之间的差异性。是伪方差的m倍。RSS：是预测值和样本值之间的差异，是MSE的m倍。$$MSE=\frac{1}{m}\sum_{i=1}^m(y_i - \hat y_i)^2\ \ \ 公式4.1$$$$RMSE=\sqrt{MSE} \ \ \ 公式4.2$$$$R^2 = 1 - \frac{RSS}{TSS} = 1-\frac{\sum_{i=1}^m(y_i-\hat y_i)^2}{\sum_{i=1}^m(y_i-\overline y)^2}\ \ \ 公式4.3$$				通过看公式我们可以得到以下的结论。MSE：误差平方和，越趋近于0越拟合。RMSE：就是对MSE开根号，所以和MSE的判别一样。$R^2$：值域为，最优解是1，若预测值恒为样本期望则为0除了这些，还有一个叫做混淆矩阵的东西，也是评价模型的一种手段，可以之后搜索看看。结语这些算法算是机器学习早期的故事，我们可以看到，算法的出现非常符合人类思维发展模式。算法是由具象到抽象的，开始的时候，说到分类我们很容易想到一刀切的方式，于是出现了线性回归，与此同时我们又想出了用概率表示的方式于是出现了逻辑回归。当香农提出了信息熵之后，又出现了信息熵来表示分类是否合适的算法思路。算法也是又简单到复杂的，之后随着线性回归算法的使用，我们发现出现了过拟合，于是我们用正则项来解决，于是出现了LASSO和Ridge算法。之后为了让这个“一刀切”更好，出现了SVM。而概率的那条路就走的更远一点，在考虑了特征之间的关系后，出现了贝叶斯网络，更进一步在考虑到了隐变量之后出现了HMM，慢慢的也能看见现在的神经网络的雏形。最后，个人觉得算法是一种工具，如果不能灵活使用的话，充其量只能算一种思辨游戏。祝大家HappyCoding。]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[线性回归算法]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/</url>
      <content type="text"><![CDATA[							回归算法上	​在序章中我们提到了，机器学习的本质就是一个分类器，对给出的数据进行有价值的分类。​具体的机器学习算法的分类分为，监督学习和无监督学习两种。而在监督渡学习中，我们以分类的类别是否是离散的，分为两种分类方式，分别是分类和回归。即，分类后是有一定的，像水果的分类，苹果，梨，橘子等等这样确定的分类的是分类，而分类后的预测结果是一个连续的数值则是回归。在这篇文章中，我们说的回归算法便是监督算法中的回归算法。最小二乘参数&amp;损失函数​还记得我们最开始说的，机器学习的实质就是分类么，即得到输入$x$后，通过一个训练好的关系$f(x)$，输出一个$\hat y$ ，如果你的模型好的话，$\hat y$ 和真实值$y$会非常接近，有着非常好的预测结果。在这一个章节中，将会从数学层面来讲一讲这个是如何做到的。首先我们用大白话，整体的了解下这是一个什么样子过程。首先，我们需要先确定个目标，打比方说我要做一锅好吃的菜，我刚开始拿到一个方子，买来了菜切好了菜，按照方子做了，即选了算法，拿到训练数据后，机器学习第一次迭代。之后，尝了一尝，觉得这个菜不和我胃口，即和已有数据标签对比，然后调整盐量，菜的切法之后，即发现结果不理想，以某种方式调整参数，再做一次，做完之后再尝，再调整，即再次迭代，最终研究出了自己喜欢的菜适合自己的配方，即符合要求的准确率停止训练。​看这个过程是不是简单的说就是，不断的调整方法，直到完成目标任务，就和小婴儿学习一样。那么过程现在知道了，那如何让我们的小婴儿计算机来学习呢。首先，我们想，最简单的方程是什么呢，很小我们就知道了$y = kx + b$ 这个直线公式，我们现在就用它来作为输入$x$和输出$y$之间的关系，所以引入下面的公式2.1。我是这么理解的，每一个输入 $x$ 都对输出 $y$ 有不同的作用效果，所以我们给输入 $x$ 前面写一个系数来代表它的作用强度，这个系数就是$k$ ，也就是下面公式中的 $\theta$ ， 那么后面的$\epsilon$ 是什么呢。我的理解是，你看，我们现在是做一个$y$ 的预测，从实际出发，我们很难找到完美的$\hat y$ 可以完全等于训练集中$x$ 所对应的 $y$ ，这时候误差是必定存在的，所以引入误差$\epsilon$，为我们通过模型预测的值$\hat y$ 和已知值$y$的差，如公式2.2所示。除此之外，我们可以把$\epsilon$ 看作现实中众多随机现象引起的误差，而这个误差一般符合高斯分布（参考中心极限定理），这个在之后的推导中也会用到。实际问题中，很多随机现象可以看做众多因素的独立影响的综合反应，往往服从正态分布。​$$y^{(i)} = \theta^T*x^{(i)}\ \ \ 公式2.1$$$$y^{(i)}- \theta^T*x^{(i)}= \epsilon^{(i)}\ \ \ 公式2.2$$​误差、误差，顾名思义，我们要让误差最小，由于$\epsilon$符合高斯分布（最大似然估计），所以$\epsilon$ 的概率应该符合公式2.3。然后用公式2.2进行等式代换得到公式2.4。那么这个公式2.4怎么理解呢，这里输入$x$是固定的，我们只能调整$\theta$来使输出$\hat y$来接近样本给出的$y$。而公式2.4的意思就是，在输入$x$的情况下，输出正确$y$的概率。$$p(\epsilon^{(i)}) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(\epsilon)^2}{2 \sigma^2}}\ \ \ 公式2.3$$$$p(y^{(i)}|x^{(i)};\theta) =\frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(y^{(i)}- \theta^T*x^{(i)})^2}{2 \sigma^2}}\ \ \ 公式2.4$$	​接下来我们要引入最大似然估计，小伙伴你们没有听错，就是考研数学中概率论的那个最大似然估计（居然真的用上了）。由于每个输入都是相互独立的，所以整体预测对的概率密度，可以通过每个样本预测对的概率密度相乘得到。于是我们得到了下面的公式2.5。是不是很熟悉，我们现在做的是改变$theta$使得概率最大，就和考研的时候学的一样，我们对公式2.5先求对数，然后求导就可以算出来我们要的$theta$的。$$L(\theta) = \prod_{i = 1}^mp(y^{(i)}|x^{(i)};\theta)\ \ \ 公式2.5$$​在这里有一点小小的变化，为了方便计算，我们对公式2.5求对数以后，我们得到了公式2.6。观察公式2.6我们很快的发现。$m \log \frac{1}{\sigma \sqrt{2\pi}}$和$m \log \frac{1}{\sigma \sqrt{2\pi}}$都是常数，和$\theta$相关的只有后面那部分。所以我们求导光求导后面的那块就好了。然后就可以得到一个$\theta$和输入和输出的关系公式2.7，机器就是这么求出最优解的，但是矩阵的求逆是很复杂的，这里会耗费大量的计算量。$$\ell(\theta) = m \log \frac{1}{\sigma \sqrt{2\pi}} - \frac{1}{\sigma^2}*\frac{1}{2}\sum^m_{i =1}(y^{(i)}-\theta ^{T}x^{(i)})^2 \ \ \ 公式2.6$$$$\theta = (X^TX)^{-1}X^TY \ \ \ 公式2.7$$​最后，我们在公式2.6中看到一个很有意思的公式，这个只要是了解过损失函数的人都是眼熟的。这个公式就是$-\frac{1}{2}\sum^m_{i =1}(y^{(i)}-\theta ^{T}x^{(i)})^2$，回想下损失函数的作用是什么，是一个求$\theta$的一个关键函数，它代表着预测的是不是准确，然后根据这个函数来调整我们通过输入$x$生成$y$的函数$h(x)$。所以我们可以写出如下公式2.8，而这个正是常用损失函数中的平方和损失函数。$$loss = J(\theta) = \frac{1}{2}\sum^m_{i =1}(h_{\theta}(x^{(i)})-y^{(i)})^2 \ \ \ 公式2.8$$​实际中我们有很多损失函数，如0-1损失函数，感知损失函数，平方和损失函数，绝对值损失函数，对数损失函数。3、多项式扩展​现在我们对整体的流程也有了了解，这里讨论下，在之前讨论中输入输出关系$f(x)$的一些遗留问题。之前我们说我们的目的就是找到这么一个$f(x)$，但是这个关系不会凭空出现，所以我们预测了一个关系$h(x)$，在预测的时候我们给每个样本属性$x$前都乘上了一个系数$\theta$，但是这么做有一个前提就是，这些属性之间是相互没有关联的，而这恰恰与实际完全不符。解决这个问题的正是，对函数$h(x)$进行多项式扩展，多项式扩展后出现了属性之间相乘的形式，自然就表示了属性间的相关性，预测的准确率也就大大提升了。4、什么是过拟合&amp;过拟合问题的解决​在我的理解中，即便是机器学习也是按照人指的方向进行数学问题的求解操作。在这个机器学习中，我们一定会找到一个通过样本来看预测效果非常非常好的结果，但是这个效果真的好么。如下图，我们可以看到，每一个样本都是符合的，但是很显然这个曲线是不对的。​这是什么原因导致的呢，在通过输出$\theta​$值，我们发现，这是由于某些$\theta​$值过大导致的。所以我们由此可以想到解决方案就是，用一个添加项来迫使$theta​$不至于过大。在这里我们引入正则项（norm），即L1-norm，L2-norm。通过公式我们可以看出，我们要让损失函数很小，加入了正则想项后，势必$\theta​$不会变得太大。​L2-norm：$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i}) - y^{(i)})^2 + \lambda\sum^n_{j=1} \theta_j^2 $$\ \ \ \lambda > 0$L1-norm：$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i}) - y^{(i)})^2 + \lambda\sum^n_{j=1} |\theta_j| \ \ \ \lambda > 0$​当我们使用L2-norm的线性回归模型就是Ridge回归（岭回归模型），而我们使用了L1-norm 的模型则是LASSO回归。接下来我们分析下这两个的性能问题。​L2-norm中，由于对于各个维度的参数缩放是在一个圆内缩放的，几乎不可能导致有维度参数变为0的情况，那么也就不会产生稀疏解；而L1-norm是在一个方形内的，则很容易产生稀疏解。实际应用中，数据的维度中是存在噪音和冗余的，稀疏的解可以找到有用的维度并且减少冗余，提高回归预测的准确性和鲁棒性（减少了过度拟合），而L1-norm则可以达到最终解的稀疏性的要求。​所以，Ridge模型有较高的准确性和鲁棒性，而LASSO模型更快，更能晒出稀疏解。那么如果我们两个属性都要兼备怎么办呢。接下来就引入了弹性网络ElasitcNet算法。其实就是很暴力的同时引入了L1-norm和L2-norm，然后用$p$来代表哪个多点，具体公式如下。$$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i} - y^{(i)}))^2 + \lambda(p\sum^n_{j=1} \theta_j^2 +(1-p)\sum^n_{j=1} |\theta_j| )\ \ \ \lambda > 0 \&\& p \in [0,1]$$]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[机器学习序章]]></title>
      <url>/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%8F%E7%AB%A0/</url>
      <content type="text"><![CDATA[							机器学习系列（序章）	序言机器学习&amp;人工智能&amp;深度学习，这三个是现在经常听到的词语。一旦提到了这些都会给人一种高大上的感觉，感觉会是一种很难学会的技术。表示在下血本（突然脑抽）的情况下，剁手买了1w多的数据挖掘的网课，目前正在学习它，希望能在学习完成后揭开机器学习的面纱，争取让每个读我的博客的人都能对机器学习有一个较为全面的概念。目前的更新顺序为课程的顺序，在整体学完之后，会按自己的理解进行一个汇总。什么是机器学习首先先上官方的卡内基梅隆大学的教授TomMitchell的定义。A program can be said to learn from experience E with respect to some class of tasks T and performance measure P , If its performance at tasks in T, as measured by P, improves with experience E.对于某给定的任务T，在合理的性能度量方案P的前提下，某计算机程序可以自主学习任务T的经验E；随着提供合适、优质、大量的经验E，该程序对于任务T的性能逐步提高。看起来很官方的说法对吧，接下来粗略的说明是怎么回事。一句话版本：抓了一把混着豆子的米（数据），根据你对豆子和米的特征的认识（已有经验），把豆子和米分开分别装在两个袋子里（分类），随后验收的人看你是否真的把米和豆子分开了（性能度量）。数学版本：X*P=Y，Y是分类的类别，X是一个数据，我们找的是矩阵P能使所有的数据X都能对应到相迎的分类Y。简单来说，机器学习就是分类器，通过学习已有的数据，得到一个数据和类别的关系，再用这个关系来对未来未分类的数据进行预测，这就是我理解的机器学习。 机器学习&amp;人工智能&amp;深度学习有什么区别说到这里，有些学过深度学习的人肯定就会疑惑这个和机器学习好像一样啊，深度学习也是把图片分类啊。是的，深度学习准确的来说算是机器学习的一部分，而机器学习和深度学习又可以被人工智能所包含。只不过深度学习在图像识别和语音识别的方便有着突出的优势，而机器学习在数据挖掘，统计学习和自然语言处理方面已经有了很大的发展。它的工作流程是什么样子数据收集=&gt;数据预处理(数据清洗)=&gt;特征提取=&gt;模型构建=&gt;模型测试评估=&gt;上线=&gt;迭代数据收集和数据清洗：可以理解为，做饭前的买菜（为模型提供训练用的有效数据，去除显而易见的无效数据）特征提取：可以理解为，炒菜前的切菜，切的越好，炒完越好吃（即从数据中选出可能能代表数据特征的属性）模型构建：可以理解为炒菜，用切好的菜，以一定的顺序进行翻炒（选择合适的算法来训练模型）。模型测试评估：试吃，如果不好吃，则反思是不是切的不好，菜买的不对，或者炒的顺序不对（测试用例看是否符合标准，如果不对责重复前面的步骤）。特别的说，训练的部分，其实就是以当前的权值运算出来的结果和已知结果对比，然后根据差距来修改权值，如此往复，使预测结果和已知结果无限接近。算法的分类和选择机器学习分为如下几个分类：	有监督学习：也就是训练用的数据是有标签的，在训练前是人工分好类的。再用训练过后的模型，对未来收到的数据进行分类，来达到预测的目的。	无监督学习：和有监督学习相比，训练的数据是没有分类的，在无监督学习中，就是通过学习，把这些为分类的数据进行分类，来推断出数据的一些内在结构。	半监督学习：训练的数据包含少量的含有标签的数据，通过这些数据来训练和分类。顾名思义就是无监督和有监督的结合。然后从算法的角度来看，又可以分为如下三种：	分类：标签是整形的，是一个一个独立的离散的。分类标识的时候使用int型。	回归：标签是浮点型，分类是连续的而不是离散的。分类表示用float的型。	聚类：1，2都是有监督学习，而3则是无监督学习。最后附上一个算法的选择图：（图很清楚只需要一点的英文水平就能看懂）classification:分类 regression:回归 clustering:聚类 dimensionality reduction：降维度公开数据获取渠道	UCI Machine Learning Repository （新手推荐这个，有标签）	Amazon Public-datasets	Kaggle	KDnuggets	Sougou语料库	天池	DC竞赛]]></content>
      <categories>
        
          <category> 机器学习 </category>
        
      </categories>
      <tags>
        
          <tag> MachineLearning </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
