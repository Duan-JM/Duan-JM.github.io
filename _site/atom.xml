<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-08-11T12:05:56+08:00</updated><id>http://localhost:4000/</id><title type="html">Pre-Demo-Field</title><subtitle>Coding Life Coding Fun</subtitle><author><name>DeamoV</name></author><entry><title type="html">决策树优化策略</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/10/%E5%86%B3%E7%AD%96%E6%A0%91%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/" rel="alternate" type="text/html" title="决策树优化策略" /><published>2018-08-10T00:00:00+08:00</published><updated>2018-08-10T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/10/%E5%86%B3%E7%AD%96%E6%A0%91%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/10/%E5%86%B3%E7%AD%96%E6%A0%91%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;title&gt;决策树优化策略&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;剪枝优化&lt;/h2&gt;
&lt;p&gt;决策树的剪枝是决策树算法中最基本、最有用的一种优化方案，分为以下两类：&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;strong&gt;前置剪枝：&lt;/strong&gt;在构建决策树的过程中，提前停止。&lt;strong&gt;这种策略无法得到比较好的结果&lt;/strong&gt;&lt;/li&gt;
	&lt;li&gt;&lt;strong&gt;后置剪枝：&lt;/strong&gt;在决策树构建好后，然后开始剪裁，一般使用两种方案。a）用单一叶子结点代替整个子树，也节点的分类采用子树中最主要的分类。b）将一个子树完全替代另一个子树。后置剪枝的主要问题是存在计算效率问题，存在一定的浪费情况。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;后置剪枝&lt;/h3&gt;

&lt;p&gt;后置剪枝的核心思想其实就是交叉验证，其通过对完全树进行剪枝，一直剪到只剩下树根，这样子便得到许多树，然后通过使用数据集分别对他们验证，然后根据结果选择最优树。&lt;/p&gt;

&lt;h3&gt;决策树剪枝过程&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;code-highlighted code-python&quot;&gt;&lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;while&lt;/span&gt; 生成的决策树不为1个节点:
	计算所有内部非叶子节点的剪枝系数;
	选择最小剪枝系数的节点:
		&lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;if&lt;/span&gt; 有多个最小剪枝系数节点:
			选择包含数据项多的节点删除
		&lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;else&lt;/span&gt;:
			删除节点
		将剪枝后的树存入之后用的决策树集
&lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;for&lt;/span&gt; 决策树 &lt;span class=&quot;syntax-all syntax-keyword&quot;&gt;in&lt;/span&gt; 决策树集:
	用数据集验证决策树，得到最优剪枝后的决策树
	&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其最后用于验证决策树的损失函数如下公式1.1：&lt;/p&gt;

$$
loss = \sum_{t=1}^{leaf} \frac{D_t}{D}H(t)\ \ \  公式1.1
$$
&lt;p&gt;剪枝系数的引入：&lt;/p&gt;

&lt;p&gt;剪枝系数的目的为，&lt;strong&gt;平衡准确度和树的节点数量之间的关系&lt;/strong&gt;。所以很自然的想到我们常用的处理手法，在损失函数中引入叶子结点的变量，得到公式1.2。&lt;/p&gt;

$$
loss_{\alpha} = loss + \alpha*leaf\ \ \ \ 公式1.2
$$
&lt;p&gt;设剪枝前的损失函数为$loss(R)$，剪枝后的损失函数为$loss(r)$，由于我们是想让剪枝前后的准确率尽量不变，所以让剪枝前后的损失函数相等，化简得公式1.3，即剪枝系数。&lt;strong&gt;注：剪枝后为根节点，所以$r=1$&lt;/strong&gt;。&lt;/p&gt;

$$
\alpha = \frac{loss(r)-loss(R)}{R_{leaf}-1}\ \ \ \ 	公式1.3
$$
&lt;p&gt;最后，由于我们想尽量减去的叶子结点多点，又同时保持准确度，故剪枝系数越小越好。&lt;/p&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="MachineLearning" /><summary type="html">决策树优化策略 剪枝优化 决策树的剪枝是决策树算法中最基本、最有用的一种优化方案，分为以下两类： 前置剪枝：在构建决策树的过程中，提前停止。这种策略无法得到比较好的结果 后置剪枝：在决策树构建好后，然后开始剪裁，一般使用两种方案。a）用单一叶子结点代替整个子树，也节点的分类采用子树中最主要的分类。b）将一个子树完全替代另一个子树。后置剪枝的主要问题是存在计算效率问题，存在一定的浪费情况。</summary></entry><entry><title type="html">决策树</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/09/%E5%86%B3%E7%AD%96%E6%A0%91/" rel="alternate" type="text/html" title="决策树" /><published>2018-08-09T00:00:00+08:00</published><updated>2018-08-09T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/09/%E5%86%B3%E7%AD%96%E6%A0%91</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/09/%E5%86%B3%E7%AD%96%E6%A0%91/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;title&gt;决策树&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;h3&gt;信息熵&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;信息量:&lt;/strong&gt;指的是一个样本/事件所蕴含的信息，如果一个事件的概率越大，那么就 可以认为该事件所蕴含的信息越少。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息熵:&lt;/strong&gt;一个系统越是有序， 信息熵就越低，一个系统越是混乱，信息熵就越高，所以 信息熵被认为是一个系统有序程度的度量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息熵就是用来描述系统信息量的不确定度。&lt;/strong&gt;&lt;/p&gt;

$$
H(x) = - \sum_{i=1}^m p_i log_2(p_i)
$$
&lt;p&gt;&lt;strong&gt;条件熵：&lt;/strong&gt; 给定条件X的情况下，所有不同x值情况下Y的信息熵的平均值叫做条件熵。&lt;/p&gt;

$$
H(Y|X) = \sum_{j=1}P(X = v_j)H(Y|X = v_j)
$$
$$
H(Y|X) = H(X,Y)-H(X)
$$
&lt;h3&gt;决策树定义&lt;/h3&gt;

&lt;p&gt;决策树(Decision Tree)是在已知各种情况发生概率的基础上，通过构建决策树来 进行分析的一种方式，是一种直观应用概率分析的一种图解法。决策树是一种预测模型，代表的是对象属性与对象值之间的映射关系。决策树是一种树形结构， 其中每个内部节点表示一个属性的测试，每个分支表示一个测试输出，每个叶节 点代表一种类别;决策树是一种非常常用的有监督的分类算法。&lt;/p&gt;

&lt;h3&gt;构建过程&lt;/h3&gt;

&lt;p&gt;构建步骤如下:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;将所有的特征看成一个一个的节点;&lt;/li&gt;
	&lt;li&gt;遍历每个特征的每一种分割方式，找到最好的分割点;将数据划分为不同的子节点，eg: N1、 N2....Nm;计算划分之后所有子节点的&amp;#39;纯度&amp;#39;信息;&lt;/li&gt;
	&lt;li&gt;对第二步产生的分割，选择出最优的特征以及最优的划分方式;得出最终的子节点: N1、N2....Nm 4. 对子节点N1、N2....Nm分别继续执行2-3步，直到每个最终的子节点都足够&amp;#39;纯&amp;#39;。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;特征属性类型&lt;/h3&gt;

&lt;p&gt;根据特征属性的类型不同，在构建决策树的时候，采用不同的方式，具体如下: &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt; 属性是离散值，而且不要求生成的是二叉决策树，此时一个属性就是一个分支&lt;/li&gt;
	&lt;li&gt; 属性是离散值，而且要求生成的是二叉决策树，此时使用属性划分的子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支&lt;/li&gt;
	&lt;li&gt;属性是连续值，可以确定一个值作为分裂点split_point，按照&amp;gt;split_point和&amp;lt;=split_point生成两个分支&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;决策树分割属性选择&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;决策树算法是一种“贪心”算法策略，只考虑在当前数据特征情况下的最好分割方式，不能进行回溯操作。&lt;/li&gt;
	&lt;li&gt;对于整体的数据集而言，按照所有的特征属性进行划分操作，对所有划分操作的结果集的“纯度”进行比较，选择“纯度”越高的特征属性作为当前需要分割的数据集进行分割操作，持续迭代，直到得到最终结果。决策树是通过“纯度”来选择分割特征属性点的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;量化纯度&lt;/h3&gt;

&lt;p&gt;基尼系数：$Gini = 1 - \sum_{i=1}^nP(i)^2$&lt;/p&gt;

&lt;p&gt;信息熵：$-\sum_{i=1}^n P(i)log_2(P(i))$&lt;/p&gt;

&lt;p&gt;误差率：$Error = 1 - max_{i=1}^n \{P(i)\}$&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;上面是基础的一些系数，在剪枝和判断的时候需要一个种体现变化的系数。&lt;/p&gt;

$$
Gain = \Delta = H(D)-H(D|A)
$$
&lt;p&gt;可以这么理解，是否决策树以A为节点划分后，信息量增加了。也可以间接体现决策树越往下发生该事件的概率越小信息量越大。&lt;/p&gt;

&lt;h3&gt;停止条件&lt;/h3&gt;

&lt;p&gt;决策树构建的过程是以恶递归的过程，以下是两个停止条件。&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;每个字节点只有一种类型时停止条件。（容易过拟合）&lt;/li&gt;
	&lt;li&gt;节点中记录数小于某个阀值的时候，或者迭代次数达到给定值的时候停止构建。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;决策树的评估&lt;/h3&gt;

$$
loss = \sum_{t=1}^{leaf} \frac{|D_t|}{D}H(t)
$$
&lt;p&gt;其中$H(t)$前的参数$\frac{D_t}{d}$主要的目的其实是给信息熵加权值。&lt;/p&gt;

&lt;h3&gt;算法对比&lt;/h3&gt;

&lt;h4&gt;ID3算法优缺点&lt;/h4&gt;

&lt;p&gt;ID3算法是决策树的一个经典的构造算法，内部使用&lt;strong&gt;信息熵&lt;/strong&gt;以及&lt;strong&gt;信息增益&lt;/strong&gt;来进行 构建;每次迭代选择信息增益最大的特征属性作为分割属性。&lt;/p&gt;

&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;决策树构建速度快，实现简单。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;计算依赖于特征数目较多的特征，而属性值最多的属性并不一定最优&lt;/li&gt;
	&lt;li&gt;ID3算法不是递增算法 ID3算法是单变量决策树，对于特征属性之间的关系不会考虑 抗噪性差&lt;/li&gt;
	&lt;li&gt;只适合小规模数据集，需要将数据放到内存中&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;C4.5&lt;/h4&gt;

&lt;p&gt;在ID3算法的基础上，进行算法优化提出的一种算法(C4.5)。其使用&lt;strong&gt;信息增益率&lt;/strong&gt;来取代ID3算法中的信息增益，在树的构造过程中&lt;strong&gt;会进行剪枝操作进行优化&lt;/strong&gt;。能够自动完成对连续属性的离散化处理。C4.5算法在选中分割属性的时候选择信息增益率最大的属性。信息增益率公式如下：&lt;/p&gt;

$$
Gain\_ratio(A) = \frac{Gain(A)}{H(A)}
$$
&lt;p&gt;优点：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;产生的规则易于理解&lt;/li&gt;
	&lt;li&gt;准确率较高实现简单&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;对数据集需要进行多次顺序扫描和排序，所以效率较低 &lt;/li&gt;
	&lt;li&gt;只适合小规模数据集，需要将数据放到内存中&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;CART&lt;/h4&gt;

&lt;p&gt;使用基尼系数作为数据纯度的量化指标来构建的决策树算法就叫做 CART(Classification And Regression Tree，分类回归树)算法。CART算法使用GINI增益作为分割属性选择的标准，选择GINI增益最大的作为当前数据集的分割属性。可用于分类和回归两类问题。&lt;strong&gt;注意的是：CART构建是二叉树，同时GINI系数的计算不牵扯对数运算比较快&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;GINI增益公式如下：&lt;/p&gt;

$$
Gain = \Delta = Gini(D) - Gini(D|A)
$$
&lt;h4&gt;总结&lt;/h4&gt;

&lt;ul&gt;
	&lt;li&gt;ID3和C4.5算法均只适合在小规模数据集上使用&lt;/li&gt;
	&lt;li&gt;ID3和C4.5算法都是单变量决策树&lt;/li&gt;
	&lt;li&gt;当属性值取值比较多的时候，最好考虑C4.5算法，ID3得出的效果会比较差&lt;/li&gt;
	&lt;li&gt;决策树分类一般情况只适合小数据量的情况(数据可以放内存)&lt;/li&gt;
	&lt;li&gt;CART算法是三种算法中最常用的一种决策树构建算法。&lt;/li&gt;
	&lt;li&gt;CART算法构建的一定是二叉树，ID3和C4.5构建的不一定是二叉树。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;三种算法的区别仅仅只是对于当前树的评价标准不同而已，ID3使用信息增益、 C4.5使用信息增益率、CART使用基尼系数。&lt;/p&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="MachineLearning" /><summary type="html">决策树 信息熵 信息量:指的是一个样本/事件所蕴含的信息，如果一个事件的概率越大，那么就 可以认为该事件所蕴含的信息越少。</summary></entry><entry><title type="html">《滚雪球》- 爱丽丝·查理芒格</title><link href="http://localhost:4000/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/2018/08/08/%E6%BB%9A%E9%9B%AA%E7%90%83-%E7%88%B1%E4%B8%BD%E4%B8%9D-%E6%9F%A5%E7%90%86%E8%8A%92%E6%A0%BC/" rel="alternate" type="text/html" title="《滚雪球》- 爱丽丝·查理芒格" /><published>2018-08-08T00:00:00+08:00</published><updated>2018-08-08T00:00:00+08:00</updated><id>http://localhost:4000/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/2018/08/08/%E3%80%8A%E6%BB%9A%E9%9B%AA%E7%90%83-%E7%88%B1%E4%B8%BD%E4%B8%9D%C2%B7%E6%9F%A5%E7%90%86%E8%8A%92%E6%A0%BC%E3%80%8B</id><content type="html" xml:base="http://localhost:4000/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/2018/08/08/%E6%BB%9A%E9%9B%AA%E7%90%83-%E7%88%B1%E4%B8%BD%E4%B8%9D-%E6%9F%A5%E7%90%86%E8%8A%92%E6%A0%BC/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;title&gt;《滚雪球》 - 爱丽丝·查理芒格&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;读书笔记&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在巴菲特看来，真正富有的人生应该是这样的：做一份自己喜欢的工作，找到兴趣相投的朋友。只要能做到这些，你的人生也一样是成功的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;正如巴菲特的总结，做一个自己能感到自己价值的工作，找到能互相认可的人也许才是人生的最大意义。在努力的做自己的喜欢的工作的时候才能更容因进入”专注“的境界。而兴趣相投的朋友则会让你的生活变得丰富，人说到底还是群居的动物，社交是必要的也是维持正常心理所必须要的要素。&lt;/p&gt;

&lt;p&gt;同时他们之间也是互通的，一个好的社交保持了好的积极的心态，保持了良好的且多元的信息社区，促进了工作的进步，工作的进步获得了回报，在财力和心理上形成正向激励，达成”飞轮效应“，进步越来越开实现复利增长。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;巴菲特有三宝，“内部积分卡”，“专注”，“复利”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;内部积分卡指的是，自己的行为有自己的评价标准，自己来定义自己是什么样的人，而不是由外部来定义自己，这样做到之后就会达到一种非常好的内心自洽。正如熊太行老师讲的那样，其实有时候内心自洽是一个强大者的开端，能让我们不去盲目的做一些违背自我的决定。&lt;/p&gt;

&lt;p&gt;“异于常人”的专注，其实很多时候是别人不能复制你成功的最大的壁垒。有着异于常人的专注的巴菲特能够通过专注找到“地上的烟蒂”，而缺了专注的行业其他人即便知道了方法也不能发现“烟蒂”。&lt;/p&gt;

&lt;p&gt;复利，在滚雪球中，复利的魅力用于体现在投资上，每次都能在之前的基础上以一个固定的比例进行增长，之后会越涨越快一发不可收拾。这点在吴军的《Google方法论》和《硅谷来信》，以及吴伯凡老师也多次提及，不过名词略有不同，吴军老师称之为指数增长，吴伯凡老师称之为飞轮效应。都在强调可叠加的魅力。如果放在生活中，我们应该常常反思，我们现在做的工作是不是可以叠加的，是不是在以大利益行动，是不是能成为未来的自己工作学习的基础。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;人生就像滚雪球，最重要的就是发现湿雪和长长的山坡&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这句话特别经典，也被很多人视为人生格言。我的感悟是，湿雪不难找到，但是有耐心和勇气去用人生这一个有限的时间，去选择一个长而不急的山坡不是每个人都能做到的。很多人看到别人在急坡中一时的成功，便忍不住放弃自己的计划，跟随别人，最终摔得人仰马翻。随后重复上述过程，直到到达山底最终一无所获。最佳的策略也许是认准一个“湿雪”较多的路径，随着不陡不缓的山坡，不急不躁，把自己的雪球越滚越大。&lt;/p&gt;

&lt;h2&gt;个人总结&lt;/h2&gt;

&lt;p&gt;今年开始，随着读的书越来越多，发现很多时候抛开大佬们成功的表象背后，总有一些惊人的相似的地方。&lt;/p&gt;

&lt;p&gt;首先是兴趣和专注，吴军说“努力只能让你成为行业的前20%，而兴趣决定了你是否能走完最后的10%”，自己不知道从什么时候起养成了一种选择困难症，虽然确定了计算机机器学习这个大方向，但是却没有一个具体的目标，导致近一个月来学习重心的摇摆不定，在机器学习，爬虫和区块链中摇摆不定。虽然他们学习的进度都还不错，爬虫接了北京高教所得项目，区块链得到了Hackathon竞赛的奖，机器学习算是初步入门正在踏入深度学习的领域，但是真真切切的感受到了自己能力的天花板，即“我没有能力去同时专精所有的方向”，方向仍需做减法。&lt;/p&gt;

&lt;p&gt;其次是“复利”，可叠加性的增长最有意思的是，往往这种复利型的进步开始的时候很困难，很累很苦，需要一个很强的内心去坚持，但随着飞轮开始转动一切就会变得理所当然。这点有一点小小的体会吧，这点体现在VIM的配置上面，开始的时候很艰难，各种快捷键都不知道是什么，觉得无比难用。不过，在了解到真的很多大佬是真的使用VIM或者类似的我认为超级难用的编辑器作为生产工具的时候，觉得也许应该坚持下来，不过没想到真的VIM在日后成为了我主要的生产工具。开始的时候只是配置了代码高亮，后来渐渐加入了代码补全，再后来补充了各种各样插件并学习了更多的快捷键，最后甚至自己能编一些脚本来实现自己想要的功能。那么它给我带来了什么“复利增长呢”，减少了不必要的分心，所有的学习需要的工具大多都能通过统一的途径获得，操作上不需要太多的改动，从论文的书写到代码的规范，同时由于打开很快的特性，能让我在有想法的时候就快速的写代码来测试，这些收获让我觉得之前的小努力都是值得的。同样的，我也相信算法，统计学和离散数学，包括博弈论，这些很多难啃又不会有立竿见影成效的东西最终会成为自己职业生涯复利增长的第一步。&lt;/p&gt;

&lt;p&gt;最后是内心自洽，个人自身的感受是，如果内心不能够自洽的话，很多精力都在花费在平复情绪上进行了没必要的经历开支，甚至“因为别人都这么做所以我也要这么做的”作出欠思考的行动，或者因为“情谊”做出了完全违背自己大利益的行动。行事内心要一把尺子，这把尺子要拿稳了。气场和魄力的起点便是内心自洽，如果自己都不能坚信自己的决定，又谈何让别人相信你的决定呢？&lt;/p&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="Reading" /><summary type="html">《滚雪球》 - 爱丽丝·查理芒格 读书笔记 在巴菲特看来，真正富有的人生应该是这样的：做一份自己喜欢的工作，找到兴趣相投的朋友。只要能做到这些，你的人生也一样是成功的。</summary></entry><entry><title type="html">回归算法下</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8B/" rel="alternate" type="text/html" title="回归算法下" /><published>2018-08-07T00:00:00+08:00</published><updated>2018-08-07T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8B</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8B/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;title&gt;回归算法下&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;序言&lt;/h2&gt;
&lt;p&gt; 在机器学习02（回归算法上）中我们介绍了普通最小二乘线性回归算法，并进行了较为详细的推导，并通过分析其过拟合的问题，推导出了另外三个算法，Ridge回归算法，LASSO回归算法，以及弹性网络。并简要的分析了他们的优缺点。今天我们来接着介绍算法。为什么说是算法而不是回归算法呢，是因为在研究了逻辑回归和Softmax回归算法以后，惊讶的发现这两个算法是分类算法，所以这个回归算法下的说法就不是很严谨了。&lt;/p&gt;

&lt;h2&gt;Logistic回归&lt;/h2&gt;

&lt;p&gt;在回归算法上中我们介绍了，线性回归算法。我个人是这么拆分的，线性-回归-算法，回归指的整体的算法是回归算法而不是分类算法，线性指的是在算法回归中，假定输入输出之间关系函数是$y = kx + b$这个线性方程。&lt;/p&gt;

&lt;p&gt;那么再看看Logistic回归，显然这里肯定就是换了另一个种类的方程咯。对的，不过在逻辑回归中这里有一点不太一样，它的输出只有0和1，它假定输出 $y = 1$的概率$P$，自然 $y = 0$的概率就是 $1-P$，而逻辑回归中假定的方程就是这个$P$。&lt;/p&gt;

&lt;p&gt;现在我们来看看这个方程是什么，如下公式1.1所示。这个公式没有接触过的朋友可能不太好想这是一个什么函数，但是结合着我们高数的极限知识，我们肯定知道这个函数在$+\infty $的时候去趋近于1，在$-\infty$的时候趋近于0，而且是快速收敛的。建议百度sigmoid函数看看这个函数的图（Logistic函数就是sigmoid函数）。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;$p=h_\theta(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}} $		公式1.1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之前在线性回归算法中我们知道了求最佳$\theta$的流程就是先写出他的似然函数（这个公式表示了预测正确的概率），然后求最大似然估计（想办法让这个预测正确的概率最大），最终通过求最大似然估计的结果，得到一种调整$\theta$的最佳方案。这个逻辑回归的似然函数为公式1.3(由公式1.2易得)。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;$L(y|x;\theta)=(h_\theta(x))^y(1-h_\theta(x))^{1-y}$	公式1.2&lt;/li&gt;
	&lt;li&gt;$L(\vec y|x;\theta)=\prod_{i=1}^{m}(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}$					公式1.3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之后对这个似然函数进行求导，我们都学过导数，在学导数的时候都知道，导数代表着值变化的趋势和速度。这里我们通过公式1.3对求对数，然后再对 $\theta_j $求导得到导数（公式1.4），这个导数就代表了针对$\theta_j $的正确预测的概率的变化趋势。如果让 $\theta$加上这个导数就可以保证让这个公式变大，直至最大为止。所以逻辑回归的调参如公式1.5，公式1.6所示，那么为什么是两个，在调参章节中会说明。&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;$\frac{\partial \ell(\theta)} {\partial \theta_j} = \sum_{i=1}^m(y^{(i)} - h_\theta(x^{(i)}))x_j$ 公式1.4&lt;/li&gt;
	&lt;li&gt;$\theta_j = \theta_j + \alpha \sum_{i=1}^m(y^{(i)} - h_\theta(x^{(i)}))x_j$	公式1.5	&lt;/li&gt;
	&lt;li&gt;$\theta_j = \theta_j + \alpha (y^{(i)} - h_\theta(x^{(i)}))x_j $公式1.6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;好的，到这里逻辑回归的调参我们就知道了，特别的说明的是，这里的 $alpha$就是传说中的学习速率，而这个参数我们要注意的是，它不能太大（会错过最大值而不能收敛），也不能太小（会收敛到局部最小值）。&lt;/p&gt;

&lt;p&gt;那么我们有了调参，这里肯定也有一个损失函数来表示现在预测的怎么样吧，这里的思路很简单，你不是似然函数是越大越好么，那么我把你来个倒数不就好了么，最简单的做法就是给求对数之后的公式1.3，添加一个负号。所以它的损失函数如公式1.7。&lt;/p&gt;

$loss(y^{(i)},\hat y^{(i)}) = -\ell(\theta) = \sum_{i=1}^m ln(1+e^{(1-2y^{(i)})\theta^T x^{(i)}}) $	公式1.7
&lt;p&gt;最后，想说从那个 只能为1或者0就可以看出逻辑回归虽然名字带了回归两个字，但是其实是一个分类算法。而接下来的SoftMax回归算法则是逻辑回归算法的一种拓展，这个在下一节里说。&lt;/p&gt;

&lt;h2&gt;SoftMax回归&lt;/h2&gt;

&lt;p&gt;在逻辑回归中，最终的分类结果，只有两类。这显然不是适用于很多其他的情况。所以SoftMax对逻辑回归进行了一般化，适用于K分类的问题。&lt;/p&gt;

&lt;p&gt;针对K分类的问题，我们的小伙伴 $\theta$参数就不在是一个向量了，我们设第K类的参数为向量$\theta_k$， 则有n个属性的参数就成了一个二维矩阵$\theta_{k*n}$。&lt;/p&gt;

&lt;p&gt;在Softmax回归中，我们设预测对第k类的概率为公式2.1。&lt;/p&gt;

&lt;p&gt;$p(y=k|x;\theta)=\frac{e^{\theta_k^T x}}{\sum_{i=1}^K e^{\theta_i^T x}} $, $k=1,2 ...,K $公式2.1&lt;/p&gt;

&lt;p&gt;剩下的分析同逻辑回归一样就不赘述了。&lt;/p&gt;

&lt;h2&gt;机器学习调参&lt;/h2&gt;

&lt;p&gt;我们在之前的学习中，了解到机器学习在迭代的过程就是不断的调整$/theta$参数的过程。有些是算法自己就调整了，有些是需要我们的人工的来调整的，这里就要引入超参这个概念了。什么事超参呢，超参就是不能通过算法自动调整的参数，比如Ridige回归和LASSO回归的 $\lambda$，弹性网络中的 $\alpha$。&lt;/p&gt;

&lt;p&gt;除了这些，在Logistic回归这一章节中，我们发现了调参函数有两个，但是并没有说明为什么。在这里将进行详细介绍。在Logistic和Softmax回归中我们用到的调参方式，只要你稍微了解过深度学习就一定听过，这种调参方式就是大名鼎鼎的梯度下降算法。而这两个公式，公式1.5是批量梯度下降算法（BGD），公式1.6是随机梯度下降算法（SGD）。&lt;/p&gt;

&lt;p&gt;通过公式1.6我们可以看出，每次迭代SGD调整一个$\theta_j$只需要和其中一条属性的比，而BGD每次迭代每调整一个$\theta_j$需要和所有属性的比较，所以SGD迭代速度快。&lt;/p&gt;

&lt;p&gt;那么SGD每次迭代考虑的属性少会不会没有BGD准呢，这是不一定的。梯度下降算法就像大雾天气下山，我们只能看清眼前的一小部分，并以此为依据下山，我们很有可能最后在山的上的一个小坑里出不来，陷入局部最优解的问题。SGD在全局餐在多个相对最优解的情况下，SGD很有可能跳出某些局部最优解，所以不一定会比BGD坏。而BGD一定能够得到一个局部最优解（在线性回归中一定是得到一个全局最优解）。不过由于SGD少考虑一些情况，所以有随机性，因而最终结果可能会比BGD差，一般情况下我们会优先使用SGD。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;个人的简单理解是，SGD每次只会往某一个坐标轴方向走一步，而BGD则是结合所有坐标轴的情况，往一个空间内的一个方向走一步。所以理论上BGD很“理性”。&lt;/p&gt;

&lt;p&gt;SGD和BGD出现的优缺点的情况是不是很熟悉，是不是很像Ridge回归和LASSSO回归的抉择，最终出现了弹性网络。那么是不是也有一个类似梯度下降算法的“弹性网络”呢，答案显然是有的，那就是MBGD，我不全不考虑完不就好了嘛。MBGD中每次拿b个样本的平均梯度作为更新方向，这里的b一般为10。这样子就既保证了速度，也一定程度上保证了准确度。&lt;/p&gt;

&lt;h2&gt;模型效果判断&lt;/h2&gt;

&lt;p&gt;最后，我们模型也训练好了，那么怎么来判定我的模型是不是合乎标准的，就像吴军老师在Google方法论说的一样，在工程中不是只有对错，只有相对的好和相对的不好，这个模型是否符合项目的需要也是有几个标准的，在训练的时候需要注意最终目标需要达到的标准是什么。常用的有MSE（公式4.1）、RMSE（公式4.2）、$R^2$（公式4.3）。&lt;/p&gt;

&lt;p&gt;在看公式前先说明TSS和RSS的概念，用在算$R^2$上。&lt;/p&gt;

&lt;p&gt;TSS(Total SUm of Squares)：总平方和TTS，样本之间的差异性。是伪方差的m倍。RSS：是预测值和样本值之间的差异，是MSE的m倍。&lt;/p&gt;

$$
MSE=\frac{1}{m}\sum_{i=1}^m(y_i - \hat y_i)^2\ \ \ 公式4.1
$$
$$
RMSE=\sqrt{MSE} \ \ \ 公式4.2
$$
$$
R^2 = 1 - \frac{RSS}{TSS} = 1-\frac{\sum_{i=1}^m(y_i-\hat y_i)^2}{\sum_{i=1}^m(y_i-\overline y)^2}\ \ \ 公式4.3
$$				
&lt;p&gt;通过看公式我们可以得到以下的结论。&lt;/p&gt;

&lt;p&gt;MSE：误差平方和，越趋近于0越拟合。&lt;/p&gt;

&lt;p&gt;RMSE：就是对MSE开根号，所以和MSE的判别一样。&lt;/p&gt;

&lt;p&gt;$R^2$：值域为，最优解是1，若预测值恒为样本期望则为0&lt;/p&gt;

&lt;p&gt;除了这些，还有一个叫做混淆矩阵的东西，也是评价模型的一种手段，可以之后搜索看看。&lt;/p&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="MachineLearning" /><summary type="html">回归算法下 序言 在机器学习02（回归算法上）中我们介绍了普通最小二乘线性回归算法，并进行了较为详细的推导，并通过分析其过拟合的问题，推导出了另外三个算法，Ridge回归算法，LASSO回归算法，以及弹性网络。并简要的分析了他们的优缺点。今天我们来接着介绍算法。为什么说是算法而不是回归算法呢，是因为在研究了逻辑回归和Softmax回归算法以后，惊讶的发现这两个算法是分类算法，所以这个回归算法下的说法就不是很严谨了。</summary></entry><entry><title type="html">回归算法上</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8A/" rel="alternate" type="text/html" title="回归算法上" /><published>2018-08-07T00:00:00+08:00</published><updated>2018-08-07T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8A</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/07/%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E4%B8%8A/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;title&gt;回归算法上&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;​在序章中我们提到了，机器学习的本质就是一个分类器，对给出的数据进行有价值的分类。&lt;/p&gt;
&lt;p&gt;​具体的机器学习算法的分类分为，监督学习和无监督学习两种。而在监督渡学习中，我们以分类的类别是否是离散的，分为两种分类方式，分别是&lt;strong&gt;&lt;em&gt;分类&lt;/em&gt;&lt;/strong&gt;和&lt;strong&gt;&lt;em&gt;回归&lt;/em&gt;&lt;/strong&gt;。即，分类后是有一定的，像水果的分类，苹果，梨，橘子等等这样确定的分类的是&lt;strong&gt;&lt;em&gt;分类&lt;/em&gt;&lt;/strong&gt;，而分类后的预测结果是一个连续的数值则是&lt;strong&gt;&lt;em&gt;回归&lt;/em&gt;&lt;/strong&gt;。在这篇文章中，我们说的回归算法便是监督算法中的回归算法。&lt;/p&gt;

&lt;h2&gt;最小二乘参数&amp;amp;损失函数&lt;/h2&gt;

&lt;p&gt;​还记得我们最开始说的，机器学习的实质就是分类么，即得到输入$x$后，通过一个训练好的关系$f(x)$，输出一个$\hat y$ ，如果你的模型好的话，$\hat y$ 和真实值$y$会非常接近，有着非常好的预测结果。在这一个章节中，将会从数学层面来讲一讲这个是如何做到的。&lt;/p&gt;

&lt;p&gt;首先我们用大白话，整体的了解下这是一个什么样子过程。首先，我们需要先确定个目标，打比方说我要做一锅好吃的菜，我刚开始拿到一个方子，买来了菜切好了菜，按照方子做了，即&lt;strong&gt;选了算法，拿到训练数据后，机器学习第一次迭代&lt;/strong&gt;。之后，尝了一尝，觉得这个菜不和我胃口，即和已有数据标签对比，然后调整盐量，菜的切法之后，即&lt;strong&gt;发现结果不理想，以某种方式调整参数&lt;/strong&gt;，再做一次，做完之后再尝，再调整，即&lt;strong&gt;再次迭代&lt;/strong&gt;，最终研究出了自己喜欢的菜适合自己的配方，即&lt;strong&gt;符合要求的准确率停止训练&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;​看这个过程是不是简单的说就是，不断的调整方法，直到完成目标任务，就和小婴儿学习一样。那么过程现在知道了，那如何让我们的小婴儿计算机来学习呢。首先，我们想，最简单的方程是什么呢，很小我们就知道了$y = kx + b$ 这个直线公式，我们现在就用它来作为输入$x$和输出$y$之间的关系，所以引入下面的公式2.1。我是这么理解的，每一个输入 $x$ 都对输出 $y$ 有不同的作用效果，所以我们给输入 $x$ 前面写一个系数来代表它的作用强度，这个系数就是$k$ ，也就是下面公式中的 $\theta$ ， 那么后面的$\epsilon$ 是什么呢。我的理解是，你看，我们现在是做一个$y$ 的预测，从实际出发，我们很难找到完美的$\hat y$ 可以完全等于训练集中$x$ 所对应的 $y$ ，这时候误差是必定存在的，所以引入误差$\epsilon$，为我们通过模型预测的值$\hat y$ 和已知值$y$的差，如公式2.2所示。除此之外，我们可以把$\epsilon$ 看作现实中众多随机现象引起的误差，而这个误差一般符合&lt;strong&gt;高斯分布&lt;/strong&gt;（参考中心极限定理），这个在之后的推导中也会用到。&lt;strong&gt;&lt;em&gt;实际问题中，很多随机现象可以看做众多因素的独立影响的综合反应，往往服从正态分布。&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

​$$
y^{(i)} = \theta^T*x^{(i)}\ \ \ 公式2.1
$$
$$
y^{(i)}- \theta^T*x^{(i)}= \epsilon^{(i)}\ \ \ 公式2.2
$$
&lt;p&gt;​误差、误差，顾名思义，我们要让误差最小，由于$\epsilon$符合高斯分布（最大似然估计），所以$\epsilon$ 的概率应该符合&lt;strong&gt;公式2.3&lt;/strong&gt;。然后用&lt;strong&gt;公式2.2&lt;/strong&gt;进行等式代换得到&lt;strong&gt;公式2.4&lt;/strong&gt;。那么这个&lt;strong&gt;公式2.4&lt;/strong&gt;怎么理解呢，这里输入$x$是固定的，我们只能调整$\theta$来使输出$\hat y$来接近样本给出的$y$。而&lt;strong&gt;公式2.4&lt;/strong&gt;的意思就是，在输入$x$的情况下，输出正确$y$的概率。&lt;/p&gt;

$$
p(\epsilon^{(i)}) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(\epsilon)^2}{2 \sigma^2}}\ \ \ 公式2.3
$$
$$
p(y^{(i)}|x^{(i)};\theta) =\frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{(y^{(i)}- \theta^T*x^{(i)})^2}{2 \sigma^2}}\ \ \ 公式2.4
$$	
&lt;p&gt;​接下来我们要引入&lt;strong&gt;最大似然估计&lt;/strong&gt;，小伙伴你们没有听错，就是考研数学中概率论的那个最大似然估计（居然真的用上了）。由于每个输入都是相互独立的，所以整体预测对的概率密度，可以通过每个样本预测对的概率密度相乘得到。于是我们得到了下面的&lt;strong&gt;公式2.5&lt;/strong&gt;。是不是很熟悉，我们现在做的是改变$theta$使得概率最大，就和考研的时候学的一样，我们对公式2.5&lt;strong&gt;先求对数，然后求导&lt;/strong&gt;就可以算出来我们要的$theta$的。&lt;/p&gt;

$$
L(\theta) = \prod_{i = 1}^mp(y^{(i)}|x^{(i)};\theta)\ \ \ 公式2.5
$$
&lt;p&gt;​在这里有一点小小的变化，为了方便计算，我们对公式2.5求对数以后，我们得到了&lt;strong&gt;公式2.6&lt;/strong&gt;。观察公式2.6我们很快的发现。$m \log \frac{1}{\sigma \sqrt{2\pi}}$和$m \log \frac{1}{\sigma \sqrt{2\pi}}$都是常数，和$\theta$相关的只有后面那部分。所以我们求导光求导后面的那块就好了。然后就可以得到一个$\theta$和输入和输出的关系&lt;strong&gt;公式2.7&lt;/strong&gt;，机器就是这么求出最优解的，但是矩阵的求逆是很复杂的，这里会耗费大量的计算量。&lt;/p&gt;

$$
\ell(\theta) = m \log \frac{1}{\sigma \sqrt{2\pi}} - \frac{1}{\sigma^2}*\frac{1}{2}\sum^m_{i =1}(y^{(i)}-\theta ^{T}x^{(i)})^2 \ \ \ 公式2.6
$$
$$
\theta = (X^TX)^{-1}X^TY \ \ \ 公式2.7
$$
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;​最后，我们在公式2.6中看到一个很有意思的公式，这个只要是了解过损失函数的人都是眼熟的。这个公式就是$-\frac{1}{2}\sum^m_{i =1}(y^{(i)}-\theta ^{T}x^{(i)})^2$，回想下损失函数的作用是什么，是一个求$\theta$的一个关键函数，它代表着预测的是不是准确，然后根据这个函数来调整我们通过输入$x$生成$y$的函数$h(x)$。所以我们可以写出如下&lt;strong&gt;公式2.8&lt;/strong&gt;，而这个正是常用损失函数中的平方和损失函数。&lt;/p&gt;

$$
loss = J(\theta) = \frac{1}{2}\sum^m_{i =1}(h_{\theta}(x^{(i)})-y^{(i)})^2 \ \ \ 公式2.8
$$
&lt;p&gt;​实际中我们有很多损失函数，如&lt;strong&gt;0-1损失函数&lt;/strong&gt;，&lt;strong&gt;感知损失函数&lt;/strong&gt;，&lt;strong&gt;平方和损失函数&lt;/strong&gt;，&lt;strong&gt;绝对值损失函数&lt;/strong&gt;，&lt;strong&gt;对数损失函数&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;3、多项式扩展&lt;/h2&gt;

&lt;p&gt;​现在我们对整体的流程也有了了解，这里讨论下，在之前讨论中输入输出关系$f(x)$的一些遗留问题。之前我们说我们的目的就是找到这么一个$f(x)$，但是这个关系不会凭空出现，所以我们预测了一个关系$h(x)$，在预测的时候我们给每个样本属性$x$前都乘上了一个系数$\theta$，但是这么做有一个前提就是，这些属性之间是相互没有关联的，而这恰恰与实际完全不符。解决这个问题的正是，对函数$h(x)$进行多项式扩展，多项式扩展后出现了属性之间相乘的形式，自然就表示了属性间的相关性，预测的准确率也就大大提升了。&lt;/p&gt;

&lt;h2&gt;4、什么是过拟合&amp;amp;过拟合问题的解决&lt;/h2&gt;

&lt;p&gt;​在我的理解中，即便是机器学习也是按照人指的方向进行数学问题的求解操作。在这个机器学习中，我们一定会找到一个通过样本来看预测效果非常非常好的结果，但是这个效果真的好么。如下图，我们可以看到，每一个样本都是符合的，但是很显然这个曲线是不对的。&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws2.sinaimg.cn/large/0069RVTdly1fu17r45kqxj31e00uugqk.jpg&quot;/&gt;&lt;/figure&gt;

&lt;p&gt;​这是什么原因导致的呢，在通过输出$\theta​$值，我们发现，这是由于某些$\theta​$值过大导致的。所以我们由此可以想到解决方案就是，用一个添加项来迫使$theta​$不至于过大。在这里我们引入正则项（norm），即&lt;strong&gt;L1-norm&lt;/strong&gt;，&lt;strong&gt;L2-norm&lt;/strong&gt;。通过公式我们可以看出，我们要让损失函数很小，加入了正则想项后，势必$\theta​$不会变得太大。&lt;/p&gt;

&lt;p&gt;​&lt;strong&gt;L2-norm：&lt;/strong&gt;$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i}) - y^{(i)})^2 + \lambda\sum^n_{j=1} \theta_j^2 $$\ \ \ \lambda &gt; 0$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;L1-norm：&lt;/strong&gt;$J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i}) - y^{(i)})^2 + \lambda\sum^n_{j=1} |\theta_j| \ \ \ \lambda &gt; 0$&lt;/p&gt;

&lt;p&gt;​当我们使用L2-norm的线性回归模型就是&lt;strong&gt;Ridge回归（岭回归模型）&lt;/strong&gt;，而我们使用了L1-norm 的模型则是&lt;strong&gt;LASSO回归&lt;/strong&gt;。接下来我们分析下这两个的性能问题。&lt;/p&gt;

&lt;p&gt;​L2-norm中，由于对于各个维度的&lt;strong&gt;参数缩放是在一个圆内缩放&lt;/strong&gt;的，几乎不可能导致有维度参数变为0的情况，那么也就不会产生稀疏解；而L1-norm是&lt;strong&gt;在一个方形内的&lt;/strong&gt;，则很容易产生稀疏解。实际应用中，数据的维度中是存在噪音和冗余的，稀疏的解可以找到有用的维度并且减少冗余，提高回归预测的准确性和鲁棒性（减少了过度拟合），而L1-norm则可以达到最终解的稀疏性的要求。&lt;/p&gt;

&lt;p&gt;​所以，Ridge模型有较高的准确性和鲁棒性，而LASSO模型更快，更能晒出稀疏解。那么如果我们两个属性都要兼备怎么办呢。接下来就引入了弹性网络&lt;strong&gt;&lt;em&gt;ElasitcNet&lt;/em&gt;&lt;/strong&gt;算法。其实就是很暴力的同时引入了L1-norm和L2-norm，然后用$p$来代表哪个多点，具体公式如下。&lt;/p&gt;

$$
J(\theta) = \frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{i} - y^{(i)}))^2 + \lambda(p\sum^n_{j=1} \theta_j^2 +(1-p)\sum^n_{j=1} |\theta_j| )\ \ \ \lambda &gt; 0 \&amp;\&amp; p \in [0,1]
$$
&lt;script type=&quot;text/x-mathjax-config&quot;&gt;MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});&lt;/script&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="MachineLearning" /><summary type="html">回归算法上 ​在序章中我们提到了，机器学习的本质就是一个分类器，对给出的数据进行有价值的分类。 ​具体的机器学习算法的分类分为，监督学习和无监督学习两种。而在监督渡学习中，我们以分类的类别是否是离散的，分为两种分类方式，分别是分类和回归。即，分类后是有一定的，像水果的分类，苹果，梨，橘子等等这样确定的分类的是分类，而分类后的预测结果是一个连续的数值则是回归。在这篇文章中，我们说的回归算法便是监督算法中的回归算法。</summary></entry><entry><title type="html">机器学习序章</title><link href="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%8F%E7%AB%A0/" rel="alternate" type="text/html" title="机器学习序章" /><published>2018-08-05T00:00:00+08:00</published><updated>2018-08-05T00:00:00+08:00</updated><id>http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%8F%E7%AB%A0</id><content type="html" xml:base="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2018/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%8F%E7%AB%A0/">&lt;!DOCTYPE html&gt;
&lt;html&gt;
	&lt;head&gt;
		&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
		&lt;meta charset=&quot;utf-8&quot; /&gt;
		&lt;title&gt;机器学习系列（序章）&lt;/title&gt;
	&lt;/head&gt;
&lt;body&gt;
&lt;h3&gt;序言&lt;/h3&gt;
&lt;p&gt;机器学习&amp;amp;人工智能&amp;amp;深度学习，这三个是现在经常听到的词语。一旦提到了这些都会给人一种高大上的感觉，感觉会是一种很难学会的技术。表示在下血本（突然脑抽）的情况下，剁手买了1w多的数据挖掘的网课，目前正在学习它，希望能在学习完成后揭开机器学习的面纱，争取让每个读我的博客的人都能对机器学习有一个较为全面的概念。&lt;/p&gt;

&lt;p&gt;目前的更新顺序为课程的顺序，在整体学完之后，会按自己的理解进行一个汇总。&lt;/p&gt;

&lt;h3&gt;什么是机器学习&lt;/h3&gt;

&lt;p&gt;首先先上官方的卡内基梅隆大学的教授TomMitchell的定义。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A program can be said to learn from experience E with respect to some class of tasks T and performance measure P , If its performance at tasks in T, as measured by P, improves with experience E.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
&lt;p&gt;对于某给定的任务T，在合理的性能度量方案P的前提下，某计算机程序可以自主学习任务T的经验E；随着提供合适、优质、大量的经验E，该程序对于任务T的性能逐步提高。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;看起来很官方的说法对吧，接下来粗略的说明是怎么回事。&lt;/p&gt;

&lt;p&gt;一句话版本：抓了一把混着豆子的米（数据），根据你对豆子和米的特征的认识（已有经验），把豆子和米分开分别装在两个袋子里（分类），随后验收的人看你是否真的把米和豆子分开了（性能度量）。&lt;/p&gt;

&lt;p&gt;数学版本：X*P=Y，Y是分类的类别，X是一个数据，我们找的是矩阵P能使所有的数据X都能对应到相迎的分类Y。&lt;/p&gt;

&lt;p&gt;简单来说，机器学习就是分类器，通过学习已有的数据，得到一个数据和类别的关系，再用这个关系来对未来未分类的数据进行预测，这就是我理解的机器学习。&lt;/p&gt;

&lt;h3&gt; 机器学习&amp;amp;人工智能&amp;amp;深度学习有什么区别&lt;/h3&gt;

&lt;p&gt;说到这里，有些学过深度学习的人肯定就会疑惑这个和机器学习好像一样啊，深度学习也是把图片分类啊。是的，深度学习准确的来说算是机器学习的一部分，而机器学习和深度学习又可以被人工智能所包含。只不过深度学习在图像识别和语音识别的方便有着突出的优势，而机器学习在数据挖掘，统计学习和自然语言处理方面已经有了很大的发展。&lt;/p&gt;

&lt;h3&gt;它的工作流程是什么样子&lt;/h3&gt;

&lt;p&gt;数据收集=&amp;gt;数据预处理(数据清洗)=&amp;gt;特征提取=&amp;gt;模型构建=&amp;gt;模型测试评估=&amp;gt;上线=&amp;gt;迭代&lt;/p&gt;

&lt;p&gt;数据收集和数据清洗：可以理解为，做饭前的买菜（为模型提供训练用的有效数据，去除显而易见的无效数据）&lt;/p&gt;

&lt;p&gt;特征提取：可以理解为，炒菜前的切菜，切的越好，炒完越好吃（即从数据中选出可能能代表数据特征的属性）&lt;/p&gt;

&lt;p&gt;模型构建：可以理解为炒菜，用切好的菜，以一定的顺序进行翻炒（选择合适的算法来训练模型）。&lt;/p&gt;

&lt;p&gt;模型测试评估：试吃，如果不好吃，则反思是不是切的不好，菜买的不对，或者炒的顺序不对（测试用例看是否符合标准，如果不对责重复前面的步骤）。&lt;/p&gt;

&lt;p&gt;特别的说，训练的部分，其实就是以当前的权值运算出来的结果和已知结果对比，然后根据差距来修改权值，如此往复，使预测结果和已知结果无限接近。&lt;/p&gt;

&lt;h3&gt;算法的分类和选择&lt;/h3&gt;

&lt;p&gt;机器学习分为如下几个分类：&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;有监督学习：也就是训练用的数据是有标签的，在训练前是人工分好类的。再用训练过后的模型，对未来收到的数据进行分类，来达到预测的目的。&lt;/li&gt;
	&lt;li&gt;无监督学习：和有监督学习相比，训练的数据是没有分类的，在无监督学习中，就是通过学习，把这些为分类的数据进行分类，来推断出数据的一些内在结构。&lt;/li&gt;
	&lt;li&gt;半监督学习：训练的数据包含少量的含有标签的数据，通过这些数据来训练和分类。顾名思义就是无监督和有监督的结合。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;然后从算法的角度来看，又可以分为如下三种：&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;分类：标签是整形的，是一个一个独立的离散的。分类标识的时候使用int型。&lt;/li&gt;
	&lt;li&gt;回归：标签是浮点型，分类是连续的而不是离散的。分类表示用float的型。&lt;/li&gt;
	&lt;li&gt;聚类：1，2都是有监督学习，而3则是无监督学习。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后附上一个算法的选择图：（图很清楚只需要一点的英文水平就能看懂）&lt;/p&gt;

&lt;p&gt;classification:分类 &lt;/p&gt;

&lt;p&gt;regression:回归 &lt;/p&gt;

&lt;p&gt;clustering:聚类 &lt;/p&gt;

&lt;p&gt;dimensionality reduction：降纬度&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;https://ws4.sinaimg.cn/large/0069RVTdly1fu0edeeakkj30jg0axdkl.jpg&quot;/&gt;&lt;/figure&gt;

&lt;h3&gt;公开数据获取渠道&lt;/h3&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets.html&quot;&gt;UCI Machine Learning Repository&lt;/a&gt; （新手推荐这个，有标签）&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/cn/public-datasets/%20&quot;&gt;Amazon Public-datasets&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://www.kaggle.com/competitions%20&quot;&gt;Kaggle&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.kdnuggets.com/datasets/index.html%20&quot;&gt;KDnuggets&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.sogou.com/labs/resource/list_pingce.php&quot;&gt;Sougou语料库&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://tianchi.aliyun.com/datalab/index.htm%20&quot;&gt;天池&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://www.pkbigdata.com/common/cmptIndex.html&quot;&gt;DC竞赛&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/body&gt;
&lt;/html&gt;</content><author><name>DeamoV</name></author><category term="MachineLearning" /><summary type="html">机器学习系列（序章） 序言 机器学习&amp;amp;人工智能&amp;amp;深度学习，这三个是现在经常听到的词语。一旦提到了这些都会给人一种高大上的感觉，感觉会是一种很难学会的技术。表示在下血本（突然脑抽）的情况下，剁手买了1w多的数据挖掘的网课，目前正在学习它，希望能在学习完成后揭开机器学习的面纱，争取让每个读我的博客的人都能对机器学习有一个较为全面的概念。</summary></entry></feed>